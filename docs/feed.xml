<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hujin Blog</title>
    <description>Hujin，Openstack &amp; SDN &amp; Kubernetes Lover，Software Engineer，| 与你一起发现更大的世界</description>
    <link>http://0.0.0.0:4000/blog/</link>
    <atom:link href="http://0.0.0.0:4000/blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 10 Apr 2023 03:32:33 +0000</pubDate>
    <lastBuildDate>Mon, 10 Apr 2023 03:32:33 +0000</lastBuildDate>
    <generator>Jekyll v4.2.2</generator>
    
      <item>
        <title>Docker容器的网络命名空间为什么不可见？</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;因为做过openstack的虚拟网络，习惯使用netns去管理linux的网络命名空间，也一直理解容器网络应该是类似的。
但是实际在使用时（runtime使用docker）发现每个非hostnetwork的容器创建后并不会查看到一个network namespace(通过ip netns ls查看)；
在使用的runtime是containerd的时候呢，这个namespace又出现了，有点迷糊了，今天就专门看了这里面的原因&lt;/p&gt;

&lt;h2 id=&quot;容器网络命名空间以及问题&quot;&gt;容器网络命名空间以及问题&lt;/h2&gt;
&lt;p&gt;我们将研究Docker容器的网络名称空间文件的问题。具体来说，我们将了解为什么ip netns ls命令看不到网络名称空间文件。
Docker容器的最基础层是Linux cgroup和名称空间机制。这两种机制协同工作，在Docker容器中提供我们所利用的进程和资源隔离。
其中cgroups限制一个进程可以使用的资源，名称空间控制进程间资源的可见性。命名空间中一个类型就是网络命名空间(network namespace)。&lt;/p&gt;

&lt;p&gt;network namespace实质上虚拟化并隔离了进程的网络堆栈。也就是说不同的进程可以有自己独特的防火墙配置、私有IP地址和路由规则。
通过网络命名空间，我们可以为每个Docker容器提供一个与主机网络隔离的网络堆栈。&lt;/p&gt;

&lt;p&gt;在Linux中，管理网络名称空间的主要工具之一是ip netns。这个命令行工具是ip工具的扩展。它允许我们在不同的网络名称空间上执行ip兼容的命令。&lt;/p&gt;

&lt;p&gt;每当我们创建Docker容器时，守护进程都会为容器进程创建名称空间对应文件。然后，它会将这些文件放在目录/proc/{pid}/ns下，其中pid是容器的进程id。&lt;/p&gt;

&lt;p&gt;让我们看一个例子:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;$ sudo docker run --rm -d ubuntu:latest sleep infinity
2545fdac9b41e463a29b4a61c201b789d567f88d54b6973bdcca9e69ba35ba92
$ sudo docker inspect -f &apos;&apos; 2545fdac9b41e463a29b4a61c201b789d567f88d54b6973bdcca9e69ba35ba92
3357
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在上面的命令中，首先创建一个运行ubuntu:latest映像的Docker容器。然后，我们通过运行sleep infinity来保持容器运行。
最后，我们运行docker inspect命令来获取容器的进程id。&lt;/p&gt;

&lt;p&gt;现在，查看/proc/3357/ns目录，我们可以看到创建了所有不同种类的名称空间:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;$ sudo ls -la /proc/3357/ns
total 0
dr-x--x--x 2 root root 0 Feb  5 04:24 .
dr-xr-xr-x 9 root root 0 Feb  5 04:24 ..
lrwxrwxrwx 1 root root 0 Feb  5 04:25 cgroup -&amp;gt; &apos;cgroup:[4026531835]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:25 ipc -&amp;gt; &apos;ipc:[4026532720]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:25 mnt -&amp;gt; &apos;mnt:[4026532718]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:24 net -&amp;gt; &apos;net:[4026532723]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:25 pid -&amp;gt; &apos;pid:[4026532721]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:25 pid_for_children -&amp;gt; &apos;pid:[4026532721]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:25 time -&amp;gt; &apos;time:[4026531834]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:25 time_for_children -&amp;gt; &apos;time:[4026531834]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:25 user -&amp;gt; &apos;user:[4026531837]&apos;
lrwxrwxrwx 1 root root 0 Feb  5 04:25 uts -&amp;gt; &apos;uts:[4026532719]&apos;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;从名称空间对应文件列表中，我们可以看到这个进程的net文件的存在。因为net文件对应于一个Linux网络名称空间，所以理论上我们现在可以列出所有network namespace，
然而事实并非如此。现在运行ip netns ls将显示0个结果:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;$ ip netns ls
$
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;作为对比让我们手动创建一个网络名称空间。然后，验证它是否在我们运行ip netns时出现:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;$ sudo ip netns add netA
$ ip netns ls
netA
$
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;正如我们所看到的，它按照预期显示netA。那么为什么不显示docker run创建的network namespace呢？&lt;/p&gt;

&lt;h2 id=&quot;不可见的原因丢失的文件引用&quot;&gt;不可见的原因：丢失的文件引用&lt;/h2&gt;

&lt;p&gt;为了理解这个问题，我们需要知道ip netns ls命令其实是在/var/run/netns目录中查找网络名称空间文件。但是，Docker守护进程在创建后并不会在/var/run/netns目录中创建网络名称空间文件的引用。
因此，ip netns ls无法解析网络命名空间文件。&lt;/p&gt;

&lt;p&gt;解决这种不一致现象的方法是在/var/run/netns目录中为net文件创建一个文件引用。具体来说，我们可以将net名称空间文件绑定挂载到我们在/var/run/netns目录中创建的一个空文件上。&lt;/p&gt;

&lt;p&gt;首先，我们在目录中创建一个空文件，并用名称空间文件所关联的容器id来命名它:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;$ mkdir -p /var/run/netns
$ touch /var/run/netns/$container_id
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;其中$container_id是一个环境变量，是创建的Docker容器的id&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;随后，我们可以运行mount -o bind命令来绑定挂载net文件:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;$ mount -o bind /proc/3357/ns/net /var/run/netns/$container_id
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;3357是上面获取的容器的pid&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;现在，再次运行相同的ip netns ls命令，我们就能看到docker容器的网络命名空间了:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;$ ip netns ls
ip netns ls
2545fdac9b41e463a29b4a61c201b789d567f88d54b6973bdcca9e69ba35ba92
netA
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;建立了对网络名称空间文件的文件引用，我们就可以使用ip netns exec运行任何ip命令。例如，我们可以使用ip addr list命令查看网络命名空间上的接口:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;$ ip netns exec $container_id ip addr list
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
inet 127.0.0.1/8 scope host lo
valid_lft forever preferred_lft forever
4: eth0@if5: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default
link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
valid_lft forever preferred_lft forever
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;containerd中如何实现网络命名空间的挂载的&quot;&gt;containerd中如何实现网络命名空间的挂载的&lt;/h2&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 ~]# kubectl cluster-info dump |grep containerRuntimeVersion
&quot;f:containerRuntimeVersion&quot;: {},
&quot;containerRuntimeVersion&quot;: &quot;containerd://1.6.6&quot;,
&quot;f:containerRuntimeVersion&quot;: {},
&quot;containerRuntimeVersion&quot;: &quot;containerd://1.6.6&quot;,
&quot;f:containerRuntimeVersion&quot;: {},
&quot;containerRuntimeVersion&quot;: &quot;containerd://1.6.6&quot;,
[root@node1 ~]# ip netns
cni-028380d7-7dcf-44f5-35a4-607654492671 (id: 1)
cni-c37c9aee-54d5-baf1-a606-1c1865b83f6e (id: 0)
cni-63d627ff-481c-20ac-7abe-42ce95db7d28 (id: 21)
cni-1e075915-b90a-e7db-936d-569b71f45c2b (id: 20)
cni-61035ce0-1910-0de3-d59e-837321c2e5e4 (id: 19)
cni-05895113-0f27-8966-8db3-fb45bdd196fe (id: 18)
cni-ac9ba39f-68a4-4fb4-3c14-9d0b893d5687 (id: 17)
cni-ed0a2a49-bd79-775e-b2b1-70b0a662466b (id: 16)
cni-27ad6830-a146-ec01-425c-b6e846cb0207 (id: 15)
cni-cac98bd4-2a73-014f-5ef3-fe634ecdb9b6 (id: 14)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;前面背景中提到的问题原因找到了，但是我们发现在使用containerd作为runtime时，是可以通过ip netns查看到容器的网络命名空间的，这是怎么做的呢？
这里可以简单看下containerd的代码就清楚了:&lt;/p&gt;

&lt;p&gt;containerd/pkg/cri/sbserver/sandbox_run.go&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;// RunPodSandbox creates and starts a pod-level sandbox. Runtimes should ensure
// the sandbox is in ready state.
func (c *criService) RunPodSandbox(ctx context.Context, r *runtime.RunPodSandboxRequest) (_ *runtime.RunPodSandboxResponse, retErr error) {
    ...

    // Create initial internal sandbox object.
    sandbox := sandboxstore.NewSandbox(
        sandboxstore.Metadata{
            ID:             id,
            Name:           name,
            Config:         config,
            RuntimeHandler: r.GetRuntimeHandler(),
        },
        sandboxstore.Status{
            State: sandboxstore.StateUnknown,
        },
    )

    if _, err := c.client.SandboxStore().Create(ctx, sandboxInfo); err != nil {
        return nil, fmt.Errorf(&quot;failed to save sandbox metadata: %w&quot;, err)
    }
    ...

    // Setup the network namespace if host networking wasn&apos;t requested.
    if !hostNetwork(config) {
        netStart := time.Now()
        // If it is not in host network namespace then create a namespace and set the sandbox
        // handle. NetNSPath in sandbox metadata and NetNS is non empty only for non host network
        // namespaces. If the pod is in host network namespace then both are empty and should not
        // be used.
        var netnsMountDir = &quot;/var/run/netns&quot;
        if c.config.NetNSMountsUnderStateDir {
            netnsMountDir = filepath.Join(c.config.StateDir, &quot;netns&quot;)
        }
        sandbox.NetNS, err = netns.NewNetNS(netnsMountDir)
        if err != nil {
            return nil, fmt.Errorf(&quot;failed to create network namespace for sandbox %q: %w&quot;, id, err)
        }
        // Update network namespace in the store, which is used to generate the container&apos;s spec
        sandbox.NetNSPath = sandbox.NetNS.GetPath()
        ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到在创建容器时会创建一个sandbox容器用来共享网络命名空间，那就认为只有这个容器会对应一个网络命名空间，这里我们重点看NewNetNS方法的调用，最终调用newNS方法&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func newNS(baseDir string, pid uint32) (nsPath string, err error) {
    b := make([]byte, 16)

    _, err = rand.Read(b)
    if err != nil {
        return &quot;&quot;, fmt.Errorf(&quot;failed to generate random netns name: %w&quot;, err)
    }

    // Create the directory for mounting network namespaces
    // This needs to be a shared mountpoint in case it is mounted in to
    // other namespaces (containers)
    if err := os.MkdirAll(baseDir, 0755); err != nil {
        return &quot;&quot;, err
    }

    // create an empty file at the mount point and fail if it already exists
    nsName := fmt.Sprintf(&quot;cni-%x-%x-%x-%x-%x&quot;, b[0:4], b[4:6], b[6:8], b[8:10], b[10:])
    nsPath = path.Join(baseDir, nsName)
    mountPointFd, err := os.OpenFile(nsPath, os.O_RDWR|os.O_CREATE|os.O_EXCL, 0666)
    if err != nil {
        return &quot;&quot;, err
    }
    mountPointFd.Close()

    defer func() {
        // Ensure the mount point is cleaned up on errors
        if err != nil {
            os.RemoveAll(nsPath)
        }
    }()

    if pid != 0 {
        procNsPath := getNetNSPathFromPID(pid)
        // bind mount the netns onto the mount point. This causes the namespace
        // to persist, even when there are no threads in the ns.
        if err = unix.Mount(procNsPath, nsPath, &quot;none&quot;, unix.MS_BIND, &quot;&quot;); err != nil {
            return &quot;&quot;, fmt.Errorf(&quot;failed to bind mount ns src: %v at %s: %w&quot;, procNsPath, nsPath, err)
        }
        return nsPath, nil
    }

    var wg sync.WaitGroup
    wg.Add(1)

    // do namespace work in a dedicated goroutine, so that we can safely
    // Lock/Unlock OSThread without upsetting the lock/unlock state of
    // the caller of this function
    go (func() {
        defer wg.Done()
        runtime.LockOSThread()
        // Don&apos;t unlock. By not unlocking, golang will kill the OS thread when the
        // goroutine is done (for go1.10+)

        var origNS cnins.NetNS
        origNS, err = cnins.GetNS(getCurrentThreadNetNSPath())
        if err != nil {
            return
        }
        defer origNS.Close()

        // create a new netns on the current thread
        err = unix.Unshare(unix.CLONE_NEWNET)
        if err != nil {
            return
        }

        // Put this thread back to the orig ns, since it might get reused (pre go1.10)
        defer origNS.Set()

        // bind mount the netns from the current thread (from /proc) onto the
        // mount point. This causes the namespace to persist, even when there
        // are no threads in the ns.
        err = unix.Mount(getCurrentThreadNetNSPath(), nsPath, &quot;none&quot;, unix.MS_BIND, &quot;&quot;)
        if err != nil {
            err = fmt.Errorf(&quot;failed to bind mount ns at %s: %w&quot;, nsPath, err)
        }
    })()
    wg.Wait()

    if err != nil {
        return &quot;&quot;, fmt.Errorf(&quot;failed to create namespace: %w&quot;, err)
    }

    return nsPath, nil
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里baseDir是/var/run/netns，nsName是随机生成的36位字符串， pid是0&lt;/li&gt;
  &lt;li&gt;getCurrentThreadNetNSPath方法直接返回的是容器的网络命名空间路径：/proc/{pid}/task/{pid}/ns/net&lt;/li&gt;
  &lt;li&gt;最终将proc中网络命名空间mount到nsPath对应位置，和上面我们手动操作的情况类似&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;本次我们从简单介绍Linux名称空间和cgroup开始。然后演示了当我们运行ip netns ls时，docker run创建的网络名称空间文件不显示的问题。
随后解释了这是因为文件引用不是在/var/run/netns创建的，而ip netns ls命令只在这个目录中查找网络名称空间。&lt;/p&gt;

&lt;p&gt;随后，我们以一个简单的修正结束了本文，即将文件绑定挂载到/var/run/netns，这样就可以通过ip netns ls找到它。
最后通过查看containerd的代码发现它也是采用类似方式自动将文件mount到/var/run/netns目录下的，这样就比较方便的通过ip netns来管理容器的网络命名空间了，
这里有个不太方便的地方是查询容器和这个network namespace的对应关系，从代码里也看到是随机生成的uuid&lt;/p&gt;
</description>
        <pubDate>Thu, 06 Apr 2023 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2023/04/06/netns/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2023/04/06/netns/</guid>
        
        <category>docker</category>
        
        <category>netns</category>
        
        
      </item>
    
      <item>
        <title>Neuvector源码分析之 文件管理</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;进程规则、文件规则、网络规则、dlp、waf都是在监控组下的功能。本次我们通过源码的方式来深入了解文件规则是如何实现的。
文件规则支持用户自定义关注的文件、目录，设置规则的学习或者保护模式，相应的如果容器访问到了指定的文件，且文件规则设置保护模式，则对文件的写会产生告警。&lt;/p&gt;

&lt;h2 id=&quot;架构图&quot;&gt;架构图&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_file0.png&quot; alt=&quot;neuvector file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们从几个维度来看neuvector的文件管理功能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;页面/接口用户下发的文件规则如何让每个节点的Agent服务感知的&lt;/li&gt;
  &lt;li&gt;文件规则如何和容器关联起来的，Agent中是如何处理的&lt;/li&gt;
  &lt;li&gt;对文件执行读写操作后Agent如何感知&lt;/li&gt;
  &lt;li&gt;fanotify/inotify怎么处理文件的操作的&lt;/li&gt;
  &lt;li&gt;文件管理怎么体现学习模式下学习&lt;/li&gt;
  &lt;li&gt;文件操作告警信息怎么采集的，告警的规则是什么&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面我们带着这几个问题，来看看源码，我们先看第一个问题。&lt;/p&gt;

&lt;h2 id=&quot;源码&quot;&gt;源码&lt;/h2&gt;

&lt;h3 id=&quot;下发的文件规则如何到达每个节点的agent服务&quot;&gt;下发的文件规则如何到达每个节点的Agent服务&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_file1.png&quot; alt=&quot;neuvector file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们先看看界面新增文件规则的流程：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;获取group对象，获取group中profile和rule两组数据&lt;/li&gt;
  &lt;li&gt;profile是文件规则，rule是文件规则中应用规则&lt;/li&gt;
  &lt;li&gt;将新增数据和已有数据合并，然后保存到数据库&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;handlerFileMonitorConfig：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func handlerFileMonitorConfig(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {
    ...
    // Check if we can config the profile. Only need authorize group
    grp, err := cacher.GetGroupBrief(group, false, acc)
    if err != nil {
        restRespNotFoundLogAccessDenied(w, login, err)
        return
    }

    if grp.Kind != share.GroupKindContainer {
        // &quot;nodes&quot; : share.GroupKindNode
        log.WithFields(log.Fields{&quot;group&quot;: group, &quot;kind&quot;: grp.Kind}).Error(&quot;Get profile failed!&quot;)
        restRespError(w, http.StatusBadRequest, api.RESTErrObjectNotFound)
        return
    }

    var profChanged bool
    profConf, profRev := clusHelper.GetFileMonitorProfile(group)
    ruleConf, ruleRev := clusHelper.GetFileAccessRule(group)

    ...
    // validate add
    if config.AddFilters != nil {
        for _, filter := range config.AddFilters {
            path := filter.Filter
            filter.Filter = filepath.Clean(filter.Filter)
            if filter.Filter == &quot;.&quot; || filter.Filter == &quot;/&quot; {
                restRespErrorMessage(w, http.StatusBadRequest, api.RESTErrInvalidRequest,
                    fmt.Sprintf(&quot;Unsupported filter: %s[%s]&quot;, path, filter.Filter))
                return
            }

            // append the &quot;/&quot; back
            if path[len(path)-1:] == &quot;/&quot; {
                filter.Filter += &quot;/&quot;
            }

            base, regex, ok := parseFileFilter(filter.Filter)
            if !ok {
                restRespErrorMessage(w, http.StatusBadRequest, api.RESTErrInvalidRequest,
                    fmt.Sprintf(&quot;Unsupported filter: %s&quot;, filter.Filter))
                return
            }

            for i, cfilter := range profConf.Filters {
                if cfilter.Filter == filter.Filter {
                    // conflict, delete predefined
                    if !cfilter.CustomerAdd {
                        profConf.Filters = append(profConf.Filters[:i], profConf.Filters[i+1:]...)
                        // replace the rule below
                        idx := utils.FilterIndexKey(cfilter.Path, cfilter.Regex)
                        delete(ruleConf.Filters, idx)
                        break
                    } else {
                        restRespErrorMessage(w, http.StatusBadRequest, api.RESTErrInvalidRequest,
                            fmt.Sprintf(&quot;duplicate filter: %s&quot;, filter.Filter))
                        return
                    }
                }
            }
            flt := share.CLUSFileMonitorFilter{
                Filter:      filter.Filter,
                Path:        base,
                Regex:       regex,
                Recursive:   filter.Recursive,
                CustomerAdd: true,
            }
            if fileAccessOptionSet.Contains(filter.Behavior) {
                flt.Behavior = filter.Behavior
            } else {
                restRespErrorMessage(w, http.StatusBadRequest, api.RESTErrInvalidRequest, &quot;Invalid File access option&quot;)
                return
            }

            profConf.Filters = append(profConf.Filters, flt)
            // add rule
            idx := utils.FilterIndexKey(flt.Path, flt.Regex)
            capps := make([]string, len(filter.Apps))
            for j, app := range filter.Apps {
                capps[j] = app
            }
            frule := &amp;amp;share.CLUSFileAccessFilterRule{
                Apps:        capps,
                CreatedAt:   tm,
                UpdatedAt:   tm,
                Behavior:    flt.Behavior,
                CustomerAdd: true,
            }
            ruleConf.Filters[idx] = frule
            profChanged = true
        }
    }

    ...

    if profChanged {
        // Write to cluster
        if err := clusHelper.PutFileMonitorProfile(group, profConf, profRev); err != nil {
            log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Write cluster fail&quot;)
            restRespError(w, http.StatusInternalServerError, api.RESTErrFailWriteCluster)
            return
        }
    }
    // Write access rule
    if err := clusHelper.PutFileAccessRule(group, ruleConf, ruleRev); err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Write cluster fail&quot;)
        restRespError(w, http.StatusInternalServerError, api.RESTErrFailWriteCluster)
        return
    }

    ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看看数据怎么保存的，这里有个小坑：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;默认数据保存在/object/config/file_monitor/&lt;group-name&gt;下面&lt;/group-name&gt;&lt;/li&gt;
  &lt;li&gt;在保存数据前还有一个DuplicateNetworkKey操作，会将数据保存一份到/node/[node-id]/common/profile/file/&lt;group-name&gt;下面&lt;/group-name&gt;&lt;/li&gt;
  &lt;li&gt;后面那个保存位置的数据会被每个enforcer watch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PutFileMonitorProfile:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (m clusterHelper) PutFileMonitorProfile(name string, conf *share.CLUSFileMonitorProfile, rev uint64) error {
    key := share.CLUSFileMonitorKey(name)
    value, _ := json.Marshal(conf)
    m.DuplicateNetworkKey(key, value)
    return cluster.PutRev(key, value, rev)
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面看了controller中数据保存流程，下面来看看enforcer中数据watch流程&lt;/p&gt;

&lt;p&gt;和其他功能类似，肯定有个地方在watch这个数据变化，然后执行一些操作,这里先看file_monitor部分的逻辑（access_rule是类似的）&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func profileDerivedProc(nType cluster.ClusterNotifyType, key string, value []byte) {
    which := share.CLUSNetworkKey2Subject(key)
    value, _ = utils.UnzipDataIfValid(value)
    // log.WithFields(log.Fields{&quot;key&quot;: key}).Debug(&quot;GRP:&quot;)
    switch which {
    case share.ProfileGroup:                     // group
        systemConfigGroup(nType, key, value)
    case share.ProfileProcess:                   // process
        profileConfigGroup(nType, key, value)
    case share.ProfileFileMonitor:               // file
        systemConfigFileMonitor(nType, key, value)  
    case share.ProfileFileAccess:                // fileAccess
        systemConfigFileAccessRule(nType, key, value)
    case share.ProfileScript:                    // script, 这个在数据库里没找到
        systemConfigScript(nType, key, value)
    default:
        log.WithFields(log.Fields{&quot;derived&quot;: which}).Debug(&quot;Miss handler&quot;)
    }
}

func systemConfigFileMonitor(nType cluster.ClusterNotifyType, key string, value []byte) {
  switch nType {
  case cluster.ClusterNotifyAdd, cluster.ClusterNotifyModify:
      ...
      updateGroupProfileCache(nType, name, profile)   // 这里重点看下这个函数
  case cluster.ClusterNotifyDelete: // required no group member that means no belonged containers, either
  }   }
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;文件规则和监控组容器关联&quot;&gt;文件规则和监控组、容器关联&lt;/h3&gt;

&lt;p&gt;用户规则创建后保存到数据库，enforcer watch到数据变化会更新本地内存数据&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;对比内存数据，不一致则更新&lt;/li&gt;
  &lt;li&gt;targets是当前group中容器id列表&lt;/li&gt;
  &lt;li&gt;可以看到grpNotifyFile是当前节点所有容器id的集合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;updateGroupProfileCache:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func updateGroupProfileCache(nType cluster.ClusterNotifyType, name string, obj interface{}) bool {
    ...
    targets := utils.NewSet()
    switch obj.(type) {
    ...
    case share.CLUSFileMonitorProfile:
        file := obj.(share.CLUSFileMonitorProfile)
        if file.Mode != grpCache.file.Mode || len(grpCache.file.Filters) == 0 || reflect.DeepEqual(file.Filters, grpCache.file.Filters) == false {
            for i, _ := range file.Filters {
                file.Filters[i].DerivedGroup = name // late filled-up to save kv storages
            }
            grpCache.file = &amp;amp;file
            targets = grpCache.members.Clone()
            if targets.Cardinality() &amp;gt; 0 {
                fileUpdated = true
            }
        }
    ...

    if fileUpdated {
        grpNotifyFile = grpNotifyFile.Union(targets)
    }

    targets.Clear()
    targets = nil
    return true
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看到这里有点好奇，group和容器是怎么关联上的，也就是上面代码中grpCache.members在哪里维护的：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在enforcer中监听runtime事件时，会监听容器的创建事件，对应的回调函数有个groupWorkloadJoin&lt;/li&gt;
  &lt;li&gt;在groupWorkloadJoin中根据workload的learnedGroupName获取对应的系统组，然后加入&lt;/li&gt;
  &lt;li&gt;用户自定义组根据Criteria和domain来识别是否包含此workload&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;registerEventHandlers&amp;amp;groupWorkloadJoin:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func registerEventHandlers() {
    ...
    evhdls.Register(EV_WORKLOAD_START, []eventHandlerFunc{
        groupWorkloadJoin,
        scanWorkloadAdd,
    })
    ...


func groupWorkloadJoin(id string, param interface{}) {
    ...
    if cache, ok := groupCacheMap[wlc.learnedGroupName]; !ok || isDummyGroupCache(cache) {
        ...
    } else {
        if !cache.members.Contains(wl.ID) {
            wlc.groups.Add(wlc.learnedGroupName)
            cache.members.Add(wl.ID)
            memberUpdated = true
            log.WithFields(log.Fields{&quot;group&quot;: wlc.learnedGroupName}).Debug(&quot;Join group&quot;)
        }
    }

    // Join user defined group
    for _, cache := range groupCacheMap {
        if cache.group.CfgType == share.Learned {
            continue
        }

        if share.IsGroupMember(cache.group, wlc.workload) {
            if !cache.members.Contains(wl.ID) {
                wlc.groups.Add(cache.group.Name)
                cache.members.Add(wl.ID)
                memberUpdated = true
                log.WithFields(log.Fields{&quot;group&quot;: cache.group.Name}).Debug(&quot;Join group&quot;)
            }
    ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;到这里我们可以看到内存中的数据一直在实时更新，监控组和容器的关系也建立好了，文件规则也更新到了指定组对象了，如何使用这些数据呢，我们继续往下看&lt;/p&gt;

&lt;h3 id=&quot;定时更新fanotify关注的容器文件&quot;&gt;定时更新fanotify关注的容器文件&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_file2.png&quot; alt=&quot;neuvector file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;enforcer中创建了一个定时任务，每隔5s执行一次，遍历所有容器，将内存中的文件规则应用到的fanotify中&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func fileMemberChanges(members utils.Set) {
    log.WithFields(log.Fields{&quot;count&quot;: members.Cardinality()}).Debug(&quot;GRP:&quot;)
    for cid := range members.Iter() {
        ...
        c, ok := gInfo.activeContainers[id]
        gInfoRUnlock()
        if ok {
            applyFileGroupProfile(c)
        } ...
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在applyFileGroupProfile中涉及三个主要流程：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;calculateFileGroupProfile： 根据用户创建的文件规则筛选出所有相关file，根据监控组模式设置file的mask属性&lt;/li&gt;
  &lt;li&gt;更新容器matchRules：将计算到的file/access规则添加到workload对象中（纯数据转换处理逻辑）&lt;/li&gt;
  &lt;li&gt;StartWatch：将file添加到fanotify中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;calculateFileGroupProfile就是获取内存中group的file和access规则，
getFileMonitorProfile会加载数据库中的数据，如果内存不存在指定的group信息时&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func calculateFileGroupProfile(id, svc string) (*share.CLUSFileMonitorProfile, *share.CLUSFileAccessRule, bool) {
    log.WithFields(log.Fields{&quot;id&quot;: id, &quot;svc&quot;: svc}).Debug(&quot;GRP: &quot;)

    file := &amp;amp;share.CLUSFileMonitorProfile{
        Filters:    make([]share.CLUSFileMonitorFilter, 0),
        FiltersCRD: make([]share.CLUSFileMonitorFilter, 0),
    }
    ...
    for _, grpCache := range grpProfileCacheMap {
        if grpCache.members.Contains(id) {
            file.Filters = append(file.Filters, grpCache.file.Filters...)
            file.FiltersCRD = append(file.FiltersCRD, grpCache.file.FiltersCRD...)
            mergeFileAccessProfile(access, grpCache.access)
        }
    }
    grpCacheLock.Unlock()

    // log.WithFields(log.Fields{&quot;filter&quot;: file.Filters}).Debug(&quot;GRP:&quot;)
    ok, svc_file := getFileMonitorProfile(svc)
    if !ok {
        log.WithFields(log.Fields{&quot;id&quot;: id, &quot;svc&quot;: svc}).Debug(&quot;GRP: no file profile&quot;)
        return nil, nil, false
    }

    // basic information
    file.Group = svc_file.Group
    file.Mode = svc_file.Mode

    // merge regular files
    file.Filters = append(file.Filters, svc_file.Filters...)
    file.Filters = mergeFileMonitorProfile(file.Filters)
    ...
    return file, access, true
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们重点看下StartWatch方法&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (w *FileWatch) StartWatch(id string, rootPid int, conf *FsmonConfig, capBlock, bNeuvectorSvc bool) {
    ...
    dirs, files := w.getCoreFile(id, rootPid, conf.Profile)

    w.fanotifier.SetMode(rootPid, access, perm, capBlock, bNeuvectorSvc)

    w.addCoreFile(id, dirs, files)

    w.fanotifier.StartMonitor(rootPid)
    ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;getCoreFile: 会根据用户下发的文件规则（path可能带*）会获取所有相关的目录和文件路径&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (w *FileWatch) getCoreFile(cid string, pid int, profile *share.CLUSFileMonitorProfile) (map[string]*osutil.FileInfoExt, []*osutil.FileInfoExt) {
    dirList := make(map[string]*osutil.FileInfoExt)
    singleFiles := make([]*osutil.FileInfoExt, 0)

    // get files and dirs from all filters
    for _, filter := range profile.Filters {
        flt := &amp;amp;filterRegex{path: filterIndexKey(filter)}
        flt.regex, _ = regexp.Compile(fmt.Sprintf(&quot;^%s$&quot;, flt.path))
        bBlockAccess := filter.Behavior == share.FileAccessBehaviorBlock
        bUserAdded := filter.CustomerAdd
        if strings.Contains(filter.Path, &quot;*&quot;) {
            subDirs := w.getSubDirList(pid, filter.Path, cid)
            for _, sub := range subDirs {
                singles := w.getDirAndFileList(pid, sub, filter.Regex, cid, flt, filter.Recursive, bBlockAccess, bUserAdded, dirList)
                singleFiles = append(singleFiles, singles...)
            }
        } else {
            singles := w.getDirAndFileList(pid, filter.Path, filter.Regex, cid, flt, filter.Recursive, bBlockAccess, bUserAdded, dirList)
            singleFiles = append(singleFiles, singles...)
        }
    }

    ...
    return dirList, singleFiles
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;SetMode：内存中创建rootFd对象，需要注意一点如果监控组是保护模式会设置permControl为true，这个在后面处理文件事件会用到&lt;/p&gt;

&lt;p&gt;addCoreFile&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;向fanotify注册需要关注的文件列表，以及设置文件mask，以addFile为例&lt;/li&gt;
  &lt;li&gt;这里如果监控path是包管理路径会额外再调用inotify来监控&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;addCoreFile&amp;amp;addFile:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (w *FileWatch) addCoreFile(cid string, dirList map[string]*osutil.FileInfoExt, singleFiles []*osutil.FileInfoExt) {
    // add files
    for _, finfo := range singleFiles {
        // need to move the cross link files to dirs
        di, ok := dirList[filepath.Dir(finfo.Path)]
        if ok &amp;amp;&amp;amp; !isRunTimeAddedFile(finfo.Path) {
            finfo.Filter = di.Filter
            di.Children = append(di.Children, finfo)
        } else {
            finfo.ContainerId = cid
            w.addFile(finfo)
        }
    }

    // add directories
    ...
} 


func (w *FileWatch) addFile(finfo *osutil.FileInfoExt) {
    w.fanotifier.AddMonitorFile(finfo.Path, finfo.Filter, finfo.Protect, finfo.UserAdded, w.cbNotify, finfo)
    if _, path := global.SYS.ParseContainerFilePath(finfo.Path); packageFile.Contains(path) {
        w.inotifier.AddMonitorFile(finfo.Path, w.cbNotify, finfo)
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fanotify的addFile&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;path形如：/host/proc/17490/root/usr/bin，解析到容器的pid和操作的文件路径&lt;/li&gt;
  &lt;li&gt;fn.roots[rootPid]得到容器的root fd&lt;/li&gt;
  &lt;li&gt;这里注意mask的取值逻辑：userAdded/protect基本都符合可以忽略，permControl表示监控组是保护模式，configPerm正常是true，可以理解成监控组保护模式下默认给文件设置mask是FAN_OPEN_PERM，其他情况都是FAN_OPEN，这个需要结合后面fanotify事件的处理流程一起看&lt;/li&gt;
  &lt;li&gt;这样就将所有需要监听的文件权限、路径、容器id等所有相关的元数据都处理好了，后面就是实际应用到fanotify中了&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;addFile&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (fn *FaNotify) addFile(path string, filter interface{}, protect, isDir, userAdded bool, files map[string]interface{}, cb NotifyCallback, params interface{}) bool {
    ...
    rootPid, rPath, err := ParseMonitorPath(path)
    ...
    r, ok := fn.roots[rootPid]
    ...

    var mask uint64 = faMarkMask
    if userAdded || protect { // user-defined or protected: including access control
        if r.permControl { // protect mode
            if fn.configPerm { // system-wise : access control is available
                mask |= FAN_OPEN_PERM
            } else {
                mask |= FAN_OPEN
            }
        } else {
            mask |= FAN_OPEN
        }
    }

    var file *IFile
    if isDir {
        ...

    } else {
        if _, ok = r.paths[rPath]; ok {
            return false
        }
        file = &amp;amp;IFile{
            path:    path,
            mask:    mask,
            params:  params,
            cb:      cb,
            filter:  filter.(*filterRegex),
            protect: protect,         // access control
            learnt:  r.accessMonitor, // discover mode
            userAdd: userAdded,
        }

        r.paths[rPath] = file
    }
...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fa.StartMonitor真正将文件规则应用到fanotify&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;这里的Mark是调用fanotify，给出需要监控的文件路径、文件事件、权限&lt;/li&gt;
  &lt;li&gt;addHostNetworkFilesCopiedFiles是将hostnetwork的容器中一些通用的文件（/etc/hosts /etc/resolv.conf）进行监控&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;StartMonitor:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (fn *FaNotify) StartMonitor(rootPid int) bool {
    ...
    r, ok := fn.roots[rootPid]
    ...

    ppath := fmt.Sprintf(procRootMountPoint, rootPid)
    for dir, mask := range r.dirMonitorMap {
        path := ppath + dir
        if err := fn.fa.Mark(faMarkAddFlags, mask, unix.AT_FDCWD, path); err != nil {
            log.WithFields(log.Fields{&quot;path&quot;: path, &quot;error&quot;: err}).Error(&quot;FMON:&quot;)
        } else {
            mLog.WithFields(log.Fields{&quot;path&quot;: path, &quot;mask&quot;: fmt.Sprintf(&quot;0x%08x&quot;, mask)}).Debug(&quot;FMON:&quot;)
        }
    }

    //
    fn.addHostNetworkFilesCopiedFiles(r)
    return ok
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;到这里已经将用户下发的文件规则，关联到group，关联到具体的容器（workload）中，同时也将用户规则进行重计算，得到一个完整的文件集合，
将需要关注（监控）的文件以及事件等细节都告诉了fanotify和inotify，下面就看看实际watch到文件事件后如何处理了&lt;/p&gt;

&lt;h3 id=&quot;文件操作的感知&quot;&gt;文件操作的感知&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_file3.png&quot; alt=&quot;neuvector file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面直接调用fn.fa.Mark去告诉fanotify需要关注的文件，但是这个对象哪里来的？&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;NewFaNotify: 初始化fanotify&lt;/li&gt;
  &lt;li&gt;NewInotify: 初始化inotify&lt;/li&gt;
  &lt;li&gt;MonitorFileEvents：监听来自fanotify和inotify的文件事件并处理&lt;/li&gt;
  &lt;li&gt;fw.loop：这个后面我们讲&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NewFileWatcher:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func NewFileWatcher(config *FileMonitorConfig) (*FileWatch, error) {
    ...

    n, err := NewFaNotify(config.EndChan, config.PidLookup, global.SYS)
    if err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Open fanotify fail&quot;)
        return nil, err
    }
    ni, err := NewInotify()
    if err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Open inotify fail&quot;)
        return nil, err
    }

    go n.MonitorFileEvents()
    go ni.MonitorFileEvents()

    fw := &amp;amp;FileWatch{
        aufs:       config.IsAufs,
        fanotifier: n,
        inotifier:  ni,
        fileEvents: make(map[string]*fileMod),
        groups:     make(map[int]*groupInfo),
        sendrpt:    config.SendReport,
        sendRule:   config.SendAccessRule,
        estRuleSrc: config.EstRule,
        walkerTask: config.WalkerTask,
    }
    go fw.loop()
    ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;文件事件处理：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在获取到文件事件后，获取事件中进程pid、容器的root fd、文件mask&lt;/li&gt;
  &lt;li&gt;这里如果文件fmask是FAN_OPEN_PERM，则perm是1。前面提过如果监控组是保护模式，则会设置对应文件的mask是FAN_OPEN_PERM&lt;/li&gt;
  &lt;li&gt;resp：用来给fanotify回复的结果，计算方式见下文的流程图&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;handleEvents:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (fn *FaNotify) handleEvents() error {
    for {
        ev, err := fn.fa.GetEvent()
        ...
        pid := int(ev.Pid)
        fd := int(ev.File.Fd())
        fmask := uint64(ev.Mask)
        perm := (fmask &amp;amp; (FAN_OPEN_PERM | FAN_ACCESS_PERM)) &amp;gt; 0
        ...
        resp, mask, ifile, pInfo := fn.calculateResponse(pid, fd, fmask, perm)
        if perm {
            fn.fa.Response(ev, resp)
        }
        ev.File.Close()
        ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_file4.png&quot; alt=&quot;neuvector file&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;resp的值默认是true&lt;/li&gt;
  &lt;li&gt;如果文件规则是保护模式，且操作进程不在允许的应用中，则resp是false&lt;/li&gt;
  &lt;li&gt;将fmask转换成mask（一个操作会有多个事件，只有第一个事件中fmask是设置过的）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;calculateResponse:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (fn *FaNotify) calculateResponse(pid, fd int, fmask uint64, perm bool) (bool, uint32, *IFile, *ProcInfo) {
    ...

    ifile, _, mask := fn.lookupFile(r, linkPath, pInfo)
    if ifile == nil {
        return true, mask, nil, nil
    }

    // log.WithFields(log.Fields{&quot;protect&quot;: ifile.protect, &quot;perm&quot;: perm, &quot;path&quot;: linkPath, &quot;ifile&quot;: ifile, &quot;evMask&quot;: fmt.Sprintf(&quot;0x%08x&quot;, fmask)}).Debug(&quot;FMON:&quot;)

    // permition decision
    resp := true
    if ifile.protect { // always verify app for block-access
        resp = fn.lookupRule(r, ifile, pInfo, linkPath)
        // log.WithFields(log.Fields{&quot;resp&quot;: resp}).Debug(&quot;FMON:&quot;)
    }

    if (fmask &amp;amp; FAN_MODIFY) &amp;gt; 0 {
        mask |= syscall.IN_MODIFY
        log.WithFields(log.Fields{&quot;path&quot;: linkPath}).Info(&quot;FMON: modified&quot;)
    } else if (fmask &amp;amp; FAN_CLOSE_WRITE) &amp;gt; 0 {
        mask |= syscall.IN_CLOSE_WRITE
        log.WithFields(log.Fields{&quot;path&quot;: linkPath}).Info(&quot;FMON: cls_wr&quot;)
    } else {
        mask |= syscall.IN_ACCESS
            log.WithFields(log.Fields{&quot;path&quot;: linkPath}).Info(&quot;FMON: read&quot;)
        if fn.isFileException(false, linkPath, pInfo, mask) {
            resp = true
            mask &amp;amp;^= syscall.IN_ACCESS
        }
    }

    if perm &amp;amp;&amp;amp; !resp {
        pInfo.Deny = true
        log.WithFields(log.Fields{&quot;path&quot;: linkPath, &quot;app&quot;: pInfo.Path}).Debug(&quot;FMON: denied&quot;)
    }
    return resp, mask, ifile, pInfo
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;综合看一下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_file5.png&quot; alt=&quot;neuvector file&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;只有监控组是保护模式的时候perm才是true&lt;/li&gt;
  &lt;li&gt;perm是true的时候才会给fanotify发送response，其他时候都不会发送&lt;/li&gt;
  &lt;li&gt;只有文件规则是保护模式的时候resp才是false，其他时候都是true&lt;/li&gt;
  &lt;li&gt;换句话说：只有监控组是保护模式且文件规则是保护模式的时候fanotify才会阻断文件操作，其他都是允许&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;规则学习--告警信息上报&quot;&gt;规则学习 &amp;amp; 告警信息上报&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_file6.png&quot; alt=&quot;neuvector file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;前面看了文件事件处理流程，但是我们忽略了一个细节&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;这里有个change参数，用来判断文件是否被修改&lt;/li&gt;
  &lt;li&gt;当fmask是FAN_CLOSE_WRITE表示文件被修改&lt;/li&gt;
  &lt;li&gt;当文件规则是学习模式，或者保护模式下修改了文件 事件都需要report&lt;/li&gt;
  &lt;li&gt;文件被修改或者需要上报都需要调用回调函数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;handleEvents:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (fn *FaNotify) handleEvents() error {
    for {
        ev, err := fn.fa.GetEvent()
        ...
        change := (fmask &amp;amp; FAN_CLOSE_WRITE) &amp;gt; 0
        // log.WithFields(log.Fields{&quot;ifile&quot;: ifile, &quot;pInfo&quot;: pInfo, &quot;Resp&quot;: resp, &quot;Change&quot;: change, &quot;Perm&quot;: perm}).Debug(&quot;FMON:&quot;)

        var bReporting bool
        if ifile.learnt { // discover mode
            bReporting = ifile.userAdd // learn app for customer-added entry
        } else { // monitor or protect mode
            allowRead := resp &amp;amp;&amp;amp; !change
            bReporting = (allowRead == false) // allowed app by block_access
        }

        if bReporting || change { // report changed file
            ifile.cb(ifile.path, mask, ifile.params, pInfo)
        }
    }
    return nil
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;回调函数： 只是将事件更新或者保存到内存中，那事件在哪里处理的呢？&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (w *FileWatch) cbNotify(filePath string, mask uint32, params interface{}, pInfo *ProcInfo) {
    //ignore the container remove event. they are too many
    if (mask&amp;amp;syscall.IN_IGNORED) != 0 || (mask&amp;amp;syscall.IN_UNMOUNT) != 0 {
        w.inotifier.RemoveMonitorFile(filePath)
        return
    }

    w.mux.Lock()
    defer w.mux.Unlock()
    if fm, ok := w.fileEvents[filePath]; ok {
        fm.mask |= mask
        fm.delay = 0
        fm.pInfo = append(fm.pInfo, pInfo)
    } else {
        pi := make([]*ProcInfo, 1)
        pi[0] = pInfo
        w.fileEvents[filePath] = &amp;amp;fileMod{
            mask:  mask,
            delay: 0,
            finfo: params.(*osutil.FileInfoExt),
            pInfo: pi,
        }
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里在enforcer启动时创建了两个定时任务，分别用来处理事件和学习规则用:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;HandleWatchedFiles会根据路径类型（文件还是目录）调用对应的处理方法&lt;/li&gt;
  &lt;li&gt;reportLearningRules:后面细讲&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;HandleWatchedFiles:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (w *FileWatch) HandleWatchedFiles() {
    events := make(map[string]*fileMod)
    w.mux.Lock()
    for filePath, fmod := range w.fileEvents {
        events[filePath] = fmod
        delete(w.fileEvents, filePath)
    }
    w.mux.Unlock()

    for fullPath, fmod := range events {
        pid, path := global.SYS.ParseContainerFilePath(fullPath)
        //to avoid false alarm of /etc/hosts and /etc/resolv.conf, check whether the container is still exist
        //these two files has attribute changed when the container leave
        //this maybe miss some events file changed right before container leave. But for these kind of event,
        //it is not useful if the container already leave
        //	log.WithFields(log.Fields{&quot;pid&quot;: pid, &quot;path&quot;: path, &quot;pInfo&quot;: fmod.pInfo[0], &quot;fInfo&quot;: fmod.finfo}).Debug(&quot;FMON:&quot;)
        //	if fmod.pInfo != nil {
        //		log.WithFields(log.Fields{&quot;pInfo&quot;: fmod.pInfo[0]}).Debug(&quot;FMON:&quot;)
        //	}
        rootPath := global.SYS.ContainerProcFilePath(pid, &quot;&quot;)
        if _, err := os.Stat(rootPath); err == nil &amp;amp;&amp;amp; path != &quot;&quot; {
            var event uint32
            info, _ := os.Lstat(fullPath)
            if fmod.finfo.FileMode.IsDir() {
                event = w.handleDirEvents(fmod, info, fullPath, path, pid)
            } else {
                event = w.handleFileEvents(fmod, info, fullPath, pid)
            }
            if event != 0 {
                w.learnFromEvents(pid, fmod, path, event)
            }
        }
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里我们看看文件事件处理逻辑:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果用户删除文件规则后，会更新enforcer内存数据，也就是将fileinfo删除，这里的info就是nil了，也就需要让fanotify知道不再需要关注这些文件了，执行RemoveMonitorFile方法&lt;/li&gt;
  &lt;li&gt;这里的event是文件操作类型参数，不为空时调用learnFromEvents&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;handleFileEvents:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (w *FileWatch) handleFileEvents(fmod *fileMod, info os.FileInfo, fullPath string, pid int) uint32 {
    var event uint32
    if info != nil {
        if info.Mode() != fmod.finfo.FileMode {
            //attribute is changed
            event = fileEventAttr
            fmod.finfo.FileMode = info.Mode()
        }
        // check the hash existing and match
        // skip directory new file event, report later
        hash, err := osutil.GetFileHash(fullPath)
        if err != nil &amp;amp;&amp;amp; !osutil.HashZero(fmod.finfo.Hash) ||
            err == nil &amp;amp;&amp;amp; hash != fmod.finfo.Hash ||
            fmod.finfo.Size != info.Size() {
            event |= fileEventModified
            fmod.finfo.Hash = hash
        } else if (fmod.mask &amp;amp; syscall.IN_ACCESS) &amp;gt; 0 {
            event |= fileEventAccessed
        }
        if (fmod.finfo.FileMode &amp;amp; os.ModeSymlink) != 0 {
            //handle symlink
            rpath, err := osutil.GetContainerRealFilePath(pid, fullPath)
            if err == nil &amp;amp;&amp;amp; fmod.finfo.Link != rpath {
                event |= fileEventSymModified
            }
        }
        if (fmod.mask &amp;amp; inodeChangeMask) &amp;gt; 0 {
            w.removeFile(fullPath)
            w.addFile(fmod.finfo)
        }
    } else {
        //file is removed
        event = fileEventRemoved
        w.fanotifier.RemoveMonitorFile(fullPath)
    }
    return event
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;规则学习：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果监控组是学习模式，且进程访问的文件path匹配到文件规则，会将进程path保存到监控组的learnRules中（这个数据后面还有一个定时任务来处理）&lt;/li&gt;
  &lt;li&gt;通过最后的判断条件可以看出：非文件访问或者非学习模式下才发告警&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;learnFromEvents:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (w *FileWatch) learnFromEvents(rootPid int, fmod *fileMod, path string, event uint32) {
    ...
    grp, ok := w.groups[rootPid]
    mode := grp.mode
    if mode == share.PolicyModeLearn {
        flt := fmod.finfo.Filter.(*filterRegex)
        if applyRules, ok := grp.applyRules[flt.path]; ok {
            learnRules, ok := grp.learnRules[flt.path]
            if !ok {
                learnRules = utils.NewSet()
            }
            for _, pf := range fmod.pInfo {
                // only use the process name/path as profile
                if pf != nil &amp;amp;&amp;amp; pf.Path != &quot;&quot; {
                    if !applyRules.Contains(pf.Path) &amp;amp;&amp;amp; !learnRules.Contains(pf.Path) {
                        learnRules.Add(pf.Path)
                        log.WithFields(log.Fields{&quot;rule&quot;: pf.Path, &quot;filter&quot;: flt}).Debug(&quot;FMON:&quot;)
                    }
                }
            }
            // for inotify, cannot learn
            if learnRules.Cardinality() &amp;gt; 0 {
                grp.learnRules[flt.path] = learnRules
            }
        } else {
            log.WithFields(log.Fields{&quot;path&quot;: path}).Debug(&quot;FMON: no access rules&quot;)
        }
    }
    w.mux.Unlock()

    if event != fileEventAccessed ||
        (mode == share.PolicyModeEnforce || mode == share.PolicyModeEvaluate) {
        w.sendMsg(fmod.finfo.ContainerId, path, event, fmod.pInfo, mode)
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;规则学习&quot;&gt;规则学习&lt;/h3&gt;
&lt;p&gt;这里有个注意点，学习模式下文件管理和进程管理工作模式有点区别：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;进程管理会自动学习新的进程规则，并添加到数据库&lt;/li&gt;
  &lt;li&gt;文件管理的规则必须手动创建，只会自动学习应用并添加到对应的规则中（规则允许的应用属性）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在enforcer中还有一个定时任务，用来处理内存中学习到的文件应用数据&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (w *FileWatch) reportLearningRules() {
    learnRules := make([]*share.CLUSFileAccessRuleReq, 0)
    w.mux.Lock()
    for _, grp := range w.groups {
        if len(grp.learnRules) &amp;gt; 0 {
            for flt, rule := range grp.learnRules {
                for itr := range rule.Iter() {
                    prf := itr.(string)
                    rl := &amp;amp;share.CLUSFileAccessRuleReq{
                        GroupName: grp.profile.Group,
                        Filter:    flt,
                        Path:      prf,
                    }
                    learnRules = append(learnRules, rl)
                }
            }
            grp.learnRules = make(map[string]utils.Set)
        }
    }
    w.mux.Unlock()
    if len(learnRules) &amp;gt; 0 {
        w.sendRule(learnRules)
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到通过grpc调用ReportFileAccessRule将学习到的应用发送给controller&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func sendLearnedFileAccessRule(rules []*share.CLUSFileAccessRuleReq) error {
    log.WithFields(log.Fields{&quot;rules&quot;: len(rules)}).Debug(&quot;&quot;)
    client, err := getControllerServiceClient()
    if err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Failed to find ctrl client&quot;)
        return fmt.Errorf(&quot;Fail to find controller client&quot;)
    }

    ctx, cancel := context.WithTimeout(context.Background(), time.Second*3)
    defer cancel()

    ruleArray := &amp;amp;share.CLUSFileAccessRuleArray{
        Rules: rules,
    }

    _, err = client.ReportFileAccessRule(ctx, ruleArray)
    if err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Debug(&quot;Fail to report file rule to controller&quot;)
        return fmt.Errorf(&quot;Fail to report file rule to controller&quot;)
    }
    return nil
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在controller中有个定时任务来处理学习到的文件规则，有兴趣的可以再看下代码，最终就是调用PutFileAccessRule保存到数据库&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func FileReportBkgSvc() {
    for {
        if len(chanFileRules) &amp;gt; 0 {
            if kv.IsImporting() {
                for i := 0; i &amp;lt; len(chanFileRules); i++ {
                    &amp;lt;-chanFileRules
                }
            } else {
                if lock, _ := clusHelper.AcquireLock(share.CLUSLockPolicyKey, policyClusterLockWait); lock != nil {
                    for i := 0; i &amp;lt; len(chanFileRules) &amp;amp;&amp;amp; i &amp;lt; 16; i++ {
                        rules := &amp;lt;-chanFileRules
                        updateFileMonitorProfile(rules)
                    }
                    clusHelper.ReleaseLock(lock)
                }
            }
        } else {
            time.Sleep(time.Millisecond * 100) // yield
        }
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;我们从几位维度去看待文件管理这个功能，了解了文件规则如何下发到enforcer，enforcer如何监控当前节点所有容器的文件操作，文件事件如何处理，
文件学习如何实现。最终呈现在我们面前的文件管理是这样的：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;对象&lt;/th&gt;
      &lt;th&gt;模式&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;监控组&lt;/td&gt;
      &lt;td&gt;学习&lt;/td&gt;
      &lt;td&gt;学习&lt;/td&gt;
      &lt;td&gt;告警&lt;/td&gt;
      &lt;td&gt;告警&lt;/td&gt;
      &lt;td&gt;保护&lt;/td&gt;
      &lt;td&gt;保护&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;文件规则&lt;/td&gt;
      &lt;td&gt;告警&lt;/td&gt;
      &lt;td&gt;保护&lt;/td&gt;
      &lt;td&gt;告警&lt;/td&gt;
      &lt;td&gt;保护&lt;/td&gt;
      &lt;td&gt;告警&lt;/td&gt;
      &lt;td&gt;保护&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;读告警&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;写告警&lt;/td&gt;
      &lt;td&gt;是&lt;/td&gt;
      &lt;td&gt;是&lt;/td&gt;
      &lt;td&gt;是&lt;/td&gt;
      &lt;td&gt;是&lt;/td&gt;
      &lt;td&gt;是&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;阻断&amp;amp;告警&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;否&lt;/td&gt;
      &lt;td&gt;是&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;进程管理和文件管理的代码流程基本一致，可以参考来看&lt;/p&gt;

&lt;p&gt;以上是代码逻辑以及一些个人理解，有问题的地方可以及时微信联系我更正&lt;/p&gt;
</description>
        <pubDate>Tue, 14 Mar 2023 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2023/03/14/neuvector-file/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2023/03/14/neuvector-file/</guid>
        
        <category>neuvector</category>
        
        <category>文件管理</category>
        
        <category>fanotify</category>
        
        <category>inotify</category>
        
        
      </item>
    
      <item>
        <title>Calico单节点网络实现</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;最近有跟同事讨论calico的网络实现的话题，说calico 设计很巧妙，把 2-3层都给处理成了3层，想看看是如何实现的&lt;/p&gt;

&lt;h2 id=&quot;实现&quot;&gt;实现&lt;/h2&gt;
&lt;p&gt;查看官方文档，发现有几个解释，通过这几个解释我们实际看看Calico中如何实现将2-3层流量都处理成3层的&lt;/p&gt;

&lt;h3 id=&quot;问题一-为什么容器中有一条到16925411的路由规则&quot;&gt;问题一： 为什么容器中有一条到169.254.1.1的路由规则&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;Why does my container have a route to 169.254.1.1?

In a Calico network, each host acts as a gateway router for the workloads that it hosts. In container deployments, Calico uses 169.254.1.1 as the address for the Calico router. By using a link-local address, Calico saves precious IP addresses and avoids burdening the user with configuring a suitable address.
While the routing table may look a little odd to someone who is used to configuring LAN networking, using explicit routes rather than subnet-local gateways is fairly common in WAN networking.
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;简单翻译：在Calico网络中，每台主机都充当容器的网关（路由器）。在容器部署中，Calico使用169.254.1.1作为网关路由器的地址。
通过使用link-local地址，Calico节省了宝贵的IP地址，并避免了用户配置合适地址的负担。
虽然对于习惯于配置LAN网络的人来说，路由表可能看起来有点奇怪，但在WAN网络中，使用显式路由而不是子网本地网关是相当常见的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们看看容器中的网卡：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node2 ~]# docker exec -it d3d044626d12 sh
# ip a 
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: tunl0@NONE: &amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/ipip 0.0.0.0 brd 0.0.0.0
4: eth0@if55: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1480 qdisc noqueue state UP group default 
    link/ether d6:84:ed:49:d4:cf brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 11.244.104.3/32 brd 11.244.104.3 scope global eth0
       valid_lft forever preferred_lft forever
# ip r
default via 169.254.1.1 dev eth0 
169.254.1.1 dev eth0 scope link 
# exit
[root@node2 ~]# ip a |grep 55
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 655
36 qdisc noqueue state UNKNOWN group default qlen 1000
    inet 179.20.23.41/24 brd 179.20.23.255 scope global noprefixroute ens160
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
55: calic4eb42dc79d@if4: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1480 qdisc noqueue state UP group default
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;容器中有一张eth0网卡，ip是11.244.104.3，对应的另一端veth设备是calic4eb42dc79d&lt;/li&gt;
  &lt;li&gt;容器中只有两条路由规则，分别是默认路由和一条32位路由&lt;/li&gt;
  &lt;li&gt;下一跳是169.254.1.1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从上面容器内的情况可以看到，任何容器流量都是发送给169.254.1.1这个网关的，那么这个网关在哪里，同节点容器如何通信，跨节点容器如何通信呢？我们继续看第二个问题&lt;/p&gt;

&lt;h3 id=&quot;问题二为什么我们在host上没有找到ip地址是16925411的设备&quot;&gt;问题二：为什么我们在host上没有找到ip地址是169.254.1.1的设备？&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;Why can&apos;t I see the 169.254.1.1 address mentioned above on my host?

Calico tries hard to avoid interfering with any other configuration on the host. Rather than adding the gateway address to the host side of each workload interface, Calico sets the proxy_arp flag on the interface. This makes the host behave like a gateway, responding to ARPs for 169.254.1.1 without having to actually allocate the IP address to the interface.
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;简单翻译是：Calico努力避免干扰主机上的配置。Calico没有将网关地址添加到每个容器网卡的主机端，而是在主机端设备上设置proxy_arp标志。
这使得主机能像网关一样响应169.254.1.1的ARP，而不必实际将IP地址分配给接口。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;稍微解释下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Calico中容器网卡类型是veth，其中一端在容器内，另一端在主机上&lt;/li&gt;
  &lt;li&gt;这里通过设置主机端设备，开启proxy_arp，同时设置这个设备的mac地址固定为ee:ee:ee:ee:ee:ee&lt;/li&gt;
  &lt;li&gt;这样任意发送这个设备上的arp请求，该设备都会发送arp reply包，表示自己是网关，可以将后面的包发送给我，我给你们转发&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/arp.png&quot; alt=&quot;arp流程&quot; /&gt;&lt;/p&gt;

&lt;p&gt;实际在容器中查看：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node2 ~]# ip link show calic4eb42dc79d
55: calic4eb42dc79d@if4: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1480 qdisc noqueue state UP mode DEFAULT group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 7
[root@node2 ~]# sysctl -a  |grep calic4eb42dc79d |grep proxy_arp
net.ipv4.conf.calic4eb42dc79d.proxy_arp = 1
net.ipv4.conf.calic4eb42dc79d.proxy_arp_pvlan = 0
[root@node2 ~]# ip r |grep calic4eb42dc79d
11.244.104.3 dev calic4eb42dc79d scope link 
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;calic4eb42dc79d这个设备的mac地址是ee:ee:ee:ee:ee:ee&lt;/li&gt;
  &lt;li&gt;calic4eb42dc79d设备开启了arp代答功能，这样任意发送到这个设备上的arp，且目的mac地址是ee:ee:ee:ee:ee:ee的请求，都会返回arp reply&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里我们来抓包看看，先看看容器分布：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 ~]# kubectl get pods -owide |grep 11.244.104.3
sectest-app-influxdb-deployment-6df667cd75-bmkk5    1/1     Running     4          2d23h   11.244.104.3     node2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@node1 ~]# kubectl get pods -owide |grep 11.244.104.7
sectest-app-rabbitmq-deployment-545f49dd55-bp5tl    1/1     Running     4          2d23h   11.244.104.7     node2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@node1 ~]# kubectl get pods -owide |grep 11.244.135.31
sectest-app-haproxy-deployment-58bfd8b4b-29f79      1/1     Running     2          2d23h   11.244.135.31    node3   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;容器同节点通信抓包：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on calic4eb42dc79d, link-type EN10MB (Ethernet), capture size 262144 bytes
14:10:55.717915 d6:84:ed:49:d4:cf &amp;gt; ee:ee:ee:ee:ee:ee, ethertype ARP (0x0806), length 42: Request who-has 169.254.1.1 tell 11.244.104.3, length 28
14:10:55.717943 ee:ee:ee:ee:ee:ee &amp;gt; d6:84:ed:49:d4:cf, ethertype ARP (0x0806), length 42: Reply 169.254.1.1 is-at ee:ee:ee:ee:ee:ee, length 28
14:10:56.705970 d6:84:ed:49:d4:cf &amp;gt; ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 11.244.104.3 &amp;gt; 11.244.104.7: ICMP echo request, id 10, seq 7, length 64
14:10:56.706026 ee:ee:ee:ee:ee:ee &amp;gt; d6:84:ed:49:d4:cf, ethertype IPv4 (0x0800), length 98: 11.244.104.7 &amp;gt; 11.244.104.3: ICMP echo reply, id 10, seq 7, length 64
14:10:57.705969 d6:84:ed:49:d4:cf &amp;gt; ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 11.244.104.3 &amp;gt; 11.244.104.7: ICMP echo request, id 10, seq 8, length 64
14:10:57.706019 ee:ee:ee:ee:ee:ee &amp;gt; d6:84:ed:49:d4:cf, ethertype IPv4 (0x0800), length 98: 11.244.104.7 &amp;gt; 11.244.104.3: ICMP echo reply, id 10, seq 8, length 64
14:10:58.705990 d6:84:ed:49:d4:cf &amp;gt; ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 11.244.104.3 &amp;gt; 11.244.104.7: ICMP echo request, id 10, seq 9, length 64
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;容器跨节点通信抓包：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;14:10:08.101925 d6:84:ed:49:d4:cf &amp;gt; ee:ee:ee:ee:ee:ee, ethertype ARP (0x0806), length 42: Request who-has 169.254.1.1 tell 11.244.104.3, length 28
14:10:08.101948 ee:ee:ee:ee:ee:ee &amp;gt; d6:84:ed:49:d4:cf, ethertype ARP (0x0806), length 42: Reply 169.254.1.1 is-at ee:ee:ee:ee:ee:ee, length 28
14:10:09.093021 d6:84:ed:49:d4:cf &amp;gt; ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 11.244.104.3 &amp;gt; 11.244.135.31: ICMP echo request, id 9, seq 7, length 64
14:10:09.093406 ee:ee:ee:ee:ee:ee &amp;gt; d6:84:ed:49:d4:cf, ethertype IPv4 (0x0800), length 98: 11.244.135.31 &amp;gt; 11.244.104.3: ICMP echo reply, id 9, seq 7, length 64
14:10:10.093016 d6:84:ed:49:d4:cf &amp;gt; ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 11.244.104.3 &amp;gt; 11.244.135.31: ICMP echo request, id 9, seq 8, length 64
14:10:10.093386 ee:ee:ee:ee:ee:ee &amp;gt; d6:84:ed:49:d4:cf, ethertype IPv4 (0x0800), length 98: 11.244.135.31 &amp;gt; 11.244.104.3: ICMP echo reply, id 9, seq 8, length 64
14:10:11.093573 d6:84:ed:49:d4:cf &amp;gt; ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 11.244.104.3 &amp;gt; 11.244.135.31: ICMP echo request, id 9, seq 9, length 64
14:10:11.093910 ee:ee:ee:ee:ee:ee &amp;gt; d6:84:ed:49:d4:cf, ethertype IPv4 (0x0800), length 98: 11.244.135.31 &amp;gt; 11.244.104.3: ICMP echo reply, id 9, seq 9, length 64
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在arp请求169.254.1.1后，在主机中的veth设备会返回arp reply包，容器内部会生成一条neigh信息：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node2 ~]# docker exec -it d3d044626d12 sh
# ip neigh
169.254.1.1 dev eth0 lladdr ee:ee:ee:ee:ee:ee STALE
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;从抓包结果看二层通信和三层通信的结果都是类似的，都会先arp请求网关169.254.1.1，再将包转发到网关设备。也就是将二层和三层通信都通过三层进行转发&lt;/li&gt;
  &lt;li&gt;数据包到达主机上的veth设备（容器认为的网关）后，根据主机上的路由进行转发即可&lt;/li&gt;
  &lt;li&gt;主机路由是由bgp（bird）服务维护的&lt;/li&gt;
  &lt;li&gt;由于arp在host的veth就终结了（arp代答的功劳），这种实现有效屏蔽的arp广播，降低广播风暴的威胁&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 27 Feb 2023 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2023/02/27/calico-route/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2023/02/27/calico-route/</guid>
        
        <category>calico</category>
        
        
      </item>
    
      <item>
        <title>Kata容器网络实现</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;最近看到安全容器相关的文章，想着看看kata的网络实现&lt;/p&gt;

&lt;h2 id=&quot;架构图&quot;&gt;架构图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/kata1.png&quot; alt=&quot;kata调用流程&quot; /&gt;
在k8s中配置使用containerd作为runtime-endpoint实现，在containerd中配置runtime支持runc和kata&lt;/p&gt;

&lt;h2 id=&quot;实现&quot;&gt;实现&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/kata2.png&quot; alt=&quot;kata网络&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;默认情况下，containerd容器在创建sandbox的时候，创建对应的netns出来&lt;/li&gt;
  &lt;li&gt;在创建容器时，cni负责创建和配置容器网卡，也就是在对应的netns中创建和配置容器网卡&lt;/li&gt;
  &lt;li&gt;在创建kata容器时，kata-runtime会在容器中创建一个qemu虚拟机，使用tap0_kata网卡作为虚拟机的虚拟网卡&lt;/li&gt;
  &lt;li&gt;这里kata-runtime支持多种方式将流量从容器原本的veth设备mirror到虚拟机的tap设备上&lt;/li&gt;
  &lt;li&gt;支持的mirror方式有: macvtap none和tcfilter，默认使用tcfilter&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;源码&quot;&gt;源码&lt;/h2&gt;

&lt;p&gt;containerd代码：创建netns&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;// RunPodSandbox creates and starts a pod-level sandbox. Runtimes should ensure
// the sandbox is in ready state.
func (c *criService) RunPodSandbox(ctx context.Context, r *runtime.RunPodSandboxRequest) (_ *runtime.RunPodSandboxResponse, retErr error) {
    config := r.GetConfig()
    log.G(ctx).Debugf(&quot;Sandbox config %+v&quot;, config)
    ...
    if _, err := c.client.SandboxStore().Create(ctx, sandboxInfo); err != nil {
	    return nil, fmt.Errorf(&quot;failed to save sandbox metadata: %w&quot;, err)
    }
    ...
    if podNetwork {
        netStart := time.Now()
        // If it is not in host network namespace then create a namespace and set the sandbox
        // handle. NetNSPath in sandbox metadata and NetNS is non empty only for non host network
        // namespaces. If the pod is in host network namespace then both are empty and should not
        // be used.
        var netnsMountDir = &quot;/var/run/netns&quot;
        if c.config.NetNSMountsUnderStateDir {
            netnsMountDir = filepath.Join(c.config.StateDir, &quot;netns&quot;)
        }
        sandbox.NetNS, err = netns.NewNetNS(netnsMountDir)
        if err != nil {
            return nil, fmt.Errorf(&quot;failed to create network namespace for sandbox %q: %w&quot;, id, err)
        }
        // Update network namespace in the store, which is used to generate the container&apos;s spec
        sandbox.NetNSPath = sandbox.NetNS.GetPath()
       ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;kata-runtime代码：创建qemu虚拟机并attach网卡&lt;/p&gt;

&lt;p&gt;可以看到在创建完虚拟机后执行了AddEndpoints操作，也就是attach了网卡&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;// startVM starts the VM.
func (s *Sandbox) startVM(ctx context.Context, prestartHookFunc func(context.Context) error) (err error) {
    span, ctx := katatrace.Trace(ctx, s.Logger(), &quot;startVM&quot;, sandboxTracingTags, map[string]string{&quot;sandbox_id&quot;: s.id})
    defer span.End()

    s.Logger().Info(&quot;Starting VM&quot;)

    ...

    if err := s.network.Run(ctx, func() error {
        if s.factory != nil {
            vm, err := s.factory.GetVM(ctx, VMConfig{
                HypervisorType:   s.config.HypervisorType,
                HypervisorConfig: s.config.HypervisorConfig,
                AgentConfig:      s.config.AgentConfig,
            })
            if err != nil {
                return err
            }

            return vm.assignSandbox(s)
        }

        return s.hypervisor.StartVM(ctx, VmStartTimeout)
    }); err != nil {
        return err
    }

    ...

    // 1. Do not scan the netns if we want no network for the vmm.
    // 2. In case of vm factory, scan the netns to hotplug interfaces after vm is started.
    // 3. In case of prestartHookFunc, network config might have been changed. We need to
    //    rescan and handle the change.
    if !s.config.NetworkConfig.DisableNewNetwork &amp;amp;&amp;amp; (s.factory != nil || prestartHookFunc != nil) {
        if _, err := s.network.AddEndpoints(ctx, s, nil, true); err != nil {
            return err
        }
    }

    s.Logger().Info(&quot;VM started&quot;)

    ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;kata-runtime代码：attach网卡流程&lt;/p&gt;

&lt;p&gt;会在指定的network namespace中执行addSingleEndpoint方法&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;// Add adds all needed interfaces inside the network namespace.
func (n *LinuxNetwork) AddEndpoints(ctx context.Context, s *Sandbox, endpointsInfo []NetworkInfo, hotplug bool) ([]Endpoint, error) {
    span, ctx := n.trace(ctx, &quot;AddEndpoints&quot;)
    katatrace.AddTags(span, &quot;type&quot;, n.interworkingModel.GetModel())
    defer span.End()

    if endpointsInfo == nil {
        if err := n.addAllEndpoints(ctx, s, hotplug); err != nil {
            return nil, err
        }
    } else {
        for _, ep := range endpointsInfo {
            if err := doNetNS(n.netNSPath, func(_ ns.NetNS) error {
                if _, err := n.addSingleEndpoint(ctx, s, ep, hotplug); err != nil {
                    n.eps = nil
                    return err
                }

                return nil
            }); err != nil {
                return nil, err
            }
        }
    }
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;addSingleEndpoint&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;支持热挂载网卡&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;支持多种网卡类型，这里默认使用tuntap&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;网卡支持限速&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;支持多网卡（看到有单独的attach_interface接口）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (n *LinuxNetwork) addSingleEndpoint(ctx context.Context, s *Sandbox, netInfo NetworkInfo, hotplug bool) (Endpoint, error) {
    ...
        if socketPath != &quot;&quot; {
            networkLogger().WithField(&quot;interface&quot;, netInfo.Iface.Name).Info(&quot;VhostUser network interface found&quot;)
            endpoint, err = createVhostUserEndpoint(netInfo, socketPath)
        } else if netInfo.Iface.Type == &quot;macvlan&quot; {
            networkLogger().Infof(&quot;macvlan interface found&quot;)
            endpoint, err = createMacvlanNetworkEndpoint(idx, netInfo.Iface.Name, n.interworkingModel)
        } else if netInfo.Iface.Type == &quot;macvtap&quot; {
            networkLogger().Infof(&quot;macvtap interface found&quot;)
            endpoint, err = createMacvtapNetworkEndpoint(netInfo)
        } else if netInfo.Iface.Type == &quot;tap&quot; {
            networkLogger().Info(&quot;tap interface found&quot;)
            endpoint, err = createTapNetworkEndpoint(idx, netInfo.Iface.Name)
        } else if netInfo.Iface.Type == &quot;tuntap&quot; {
            if netInfo.Link != nil {
                switch netInfo.Link.(*netlink.Tuntap).Mode {
                case 0:
                    // mount /sys/class/net to get links
                    return nil, fmt.Errorf(&quot;Network device mode not determined correctly. Mount sysfs in caller&quot;)
                case 1:
                    return nil, fmt.Errorf(&quot;tun networking device not yet supported&quot;)
                case 2:
                    networkLogger().Info(&quot;tuntap tap interface found&quot;)
                    endpoint, err = createTuntapNetworkEndpoint(idx, netInfo.Iface.Name, netInfo.Iface.HardwareAddr, n.interworkingModel)
                default:
                    return nil, fmt.Errorf(&quot;tuntap network %v mode unsupported&quot;, netInfo.Link.(*netlink.Tuntap).Mode)
                }
            }
        } else if netInfo.Iface.Type == &quot;veth&quot; {
            networkLogger().Info(&quot;veth interface found&quot;)
            endpoint, err = createVethNetworkEndpoint(idx, netInfo.Iface.Name, n.interworkingModel)
        } else if netInfo.Iface.Type == &quot;ipvlan&quot; {
            networkLogger().Info(&quot;ipvlan interface found&quot;)
            endpoint, err = createIPVlanNetworkEndpoint(idx, netInfo.Iface.Name)
        } else {
            return nil, fmt.Errorf(&quot;Unsupported network interface: %s&quot;, netInfo.Iface.Type)
        }
    }
    ...
    networkLogger().WithField(&quot;endpoint-type&quot;, endpoint.Type()).WithField(&quot;hotplug&quot;, hotplug).Info(&quot;Attaching endpoint&quot;)
    if hotplug {
        if err := endpoint.HotAttach(ctx, s.hypervisor); err != nil {
            return nil, err
        }
    } else {
        if err := endpoint.Attach(ctx, s); err != nil {
            return nil, err
        }
    }
    ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;kata-runtime代码：引流实现&lt;/p&gt;

&lt;p&gt;创建网卡, 这里第一张网卡名称是tap0_kata，虚拟机内部是eth0&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func createTuntapNetworkEndpoint(idx int, ifName string, hwName net.HardwareAddr, internetworkingModel NetInterworkingModel) (*TuntapEndpoint, error) {
    ...

    netPair, err := createNetworkInterfacePair(idx, ifName, internetworkingModel)
    if err != nil {
        return nil, err
    }

    endpoint := &amp;amp;TuntapEndpoint{
        NetPair: netPair,
        TuntapInterface: TuntapInterface{
            Name: fmt.Sprintf(&quot;eth%d&quot;, idx),
            TAPIface: NetworkInterface{
                Name:     fmt.Sprintf(&quot;tap%d_kata&quot;, idx),
                HardAddr: fmt.Sprintf(&quot;%s&quot;, hwName), //nolint:gosimple
            },
        },
        EndpointType: TuntapEndpointType,
    }
    ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在attach方法中会调用xConnectVMNetwork，这里面会实现容器网络的引流&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;// Attach for tun/tap endpoint adds the tap interface to the hypervisor.
func (endpoint *TuntapEndpoint) Attach(ctx context.Context, s *Sandbox) error {
    span, ctx := tuntapTrace(ctx, &quot;Attach&quot;, endpoint)
    defer span.End()

    h := s.hypervisor
    if err := xConnectVMNetwork(ctx, endpoint, h); err != nil {
        networkLogger().WithError(err).Error(&quot;Error bridging virtual endpoint&quot;)
        return err
    }

    return h.AddDevice(ctx, endpoint, NetDev)
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;引流驱动有macvtap 和tcfilter，其中默认使用tcfilter&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func setupTCFiltering(ctx context.Context, endpoint Endpoint, queues int, disableVhostNet bool) error {
    ...
    if err := addQdiscIngress(tapAttrs.Index); err != nil {
        return err
    }

    if err := addQdiscIngress(attrs.Index); err != nil {
        return err
    }

    if err := addRedirectTCFilter(attrs.Index, tapAttrs.Index); err != nil {
        return err
    }

    if err := addRedirectTCFilter(tapAttrs.Index, attrs.Index); err != nil {
        return err
    }
...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;demo&quot;&gt;demo&lt;/h2&gt;

&lt;p&gt;kata部署可以参考网上的文章，这里通过创建一个kata容器，查看容器内的流量转发&lt;/p&gt;

&lt;p&gt;创建kata容器&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 kata]# cat nginx-kata.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-nginx-kata
spec:
  selector:
    matchLabels:
      run: my-nginx
  replicas: 1
  template:
    metadata:
      labels:
        run: my-nginx
    spec:
      runtimeClassName: kata
      containers:
      - name: my-nginx
        image: httpd:alpine
        ports:
        - containerPort: 80
      - name: my-redis
        image: redis
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看容器&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 kata]# kubectl get pods -owide
NAME                             READY   STATUS    RESTARTS   AGE   IP               NODE    NOMINATED NODE   READINESS GATES
my-nginx-kata-8675cd7c89-wzgr2   2/2     Running   0          45s   10.244.166.150   node1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看网络命名空间&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;看到在netns中有两张网卡，eth0和tap0_kata&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;eth0网卡是veth类型，类似普通容器的网卡&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;tap0_kata网卡是tap类型，启动qemu虚拟机时使用的虚拟网卡&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 kata]# ip netns exec cni-d27eff58-b9c9-a258-3a1e-a34528d9796f ip a
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: tunl0@NONE: &amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/ipip 0.0.0.0 brd 0.0.0.0
4: eth0@if29: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1430 qdisc noqueue state UP group default qlen 1000
    link/ether fe:68:1c:e3:47:da brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 10.244.166.150/32 brd 10.244.166.150 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::fc68:1cff:fee3:47da/64 scope link
       valid_lft forever preferred_lft forever
5: tap0_kata: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1430 qdisc mq state UNKNOWN group default qlen 1000
    link/ether 76:c7:1b:ab:30:64 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::74c7:1bff:feab:3064/64 scope link
       valid_lft forever preferred_lft forever
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;tc引流规则&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;对于eth0网卡的入口流量通过tc规则mirror到tap0_kata网卡上&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;对于tap0_kata的入口流量通过tc规则mirror到eth0网卡上&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;这样一个双向的流量通道就建立了&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 kata]# ip netns exec cni-d27eff58-b9c9-a258-3a1e-a34528d9796f tc -s qdisc show dev eth0
qdisc noqueue 0: root refcnt 2
 Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)
 backlog 0b 0p requeues 0
qdisc ingress ffff: parent ffff:fff1 ----------------
 Sent 480 bytes 5 pkt (dropped 0, overlimits 0 requeues 0)
 backlog 0b 0p requeues 0
 
[root@node1 kata]# ip netns exec cni-d27eff58-b9c9-a258-3a1e-a34528d9796f tc -s filter show dev eth0 ingress
filter protocol all pref 49152 u32
filter protocol all pref 49152 u32 fh 800: ht divisor 1
filter protocol all pref 49152 u32 fh 800::800 order 2048 key ht 800 bkt 0 terminal flowid ??? not_in_hw  (rule hit 5 success 5)
  match 00000000/00000000 at 0 (success 5 )
        action order 1: mirred (Egress Redirect to device tap0_kata) stolen
        index 1 ref 1 bind 1 installed 439 sec used 437 sec
        Action statistics:
        Sent 480 bytes 5 pkt (dropped 0, overlimits 0 requeues 0)
        backlog 0b 0p requeues 0
 
[root@node1 kata]# ip netns exec cni-d27eff58-b9c9-a258-3a1e-a34528d9796f tc -s filter show dev tap0_kata ingress
filter protocol all pref 49152 u32
filter protocol all pref 49152 u32 fh 800: ht divisor 1
filter protocol all pref 49152 u32 fh 800::800 order 2048 key ht 800 bkt 0 terminal flowid ??? not_in_hw  (rule hit 12 success 12)
  match 00000000/00000000 at 0 (success 12 )
        action order 1: mirred (Egress Redirect to device eth0) stolen
        index 2 ref 1 bind 1 installed 451 sec used 165 sec
        Action statistics:
        Sent 768 bytes 12 pkt (dropped 0, overlimits 0 requeues 0)
        backlog 0b 0p requeues 0
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;从上面的代码分析，大致了解了kata的流量路径，类似在一个普通容器基础上启动了一个qemu进程&lt;/li&gt;
  &lt;li&gt;通过tc mirror机制，将容器veth网卡流量镜像到tap网卡（通过macvtap子接口方式也类似）&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2023/02/15/kata-network/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2023/02/15/kata-network/</guid>
        
        <category>kata</category>
        
        
      </item>
    
      <item>
        <title>Neuvector源码分析之 合规性检测</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;Neuvector安全基线支持 CIS Benchmark 标准，可对容器、镜像、Register、主机、kubernetes 进行安全标准检查，多维度展现容器资产的基线合规情况并帮助建立容器运行环境下的最佳基线配置，减少攻击面
NeuVector 的合规性审核包括 CIS 基线测试、自定义检查、机密审核以及 PCI、GDPR 和其他法规的行业标准模板扫描。本文将通过源码的方式分析合规性检测的具体实现&lt;/p&gt;

&lt;h2 id=&quot;架构图&quot;&gt;架构图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_bench.png&quot; alt=&quot;neuvector bench&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从架构图中我们可以看到涉及两个模块，分别是:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;controller:负责提供API接口，保存业务数据&lt;/li&gt;
  &lt;li&gt;agent（enforce）：具体执行合规性检测的模块&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;源码&quot;&gt;源码&lt;/h2&gt;

&lt;p&gt;首先在rest.go中查看bench相关的接口，我们主要看下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;r.GET(&quot;/v1/bench/host/:id/docker&quot;, handlerDockerBench)
r.POST(&quot;/v1/bench/host/:id/docker&quot;, handlerDockerBenchRun)
r.GET(&quot;/v1/bench/host/:id/kubernetes&quot;, handlerKubeBench)
r.POST(&quot;/v1/bench/host/:id/kubernetes&quot;, handlerKubeBenchRun)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里我们通过docker合规性检测来了解具体的实现细节，在handlerDockerBenchRun方法中获取node id，并查询到这个node节点的agent信息，
方便后面的rpc调用&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func RunDockerBench(agentID string) error {
    client, err := findEnforcerServiceClient(agentID)
    if err != nil {
        return err
    }

    ctx, cancel := context.WithTimeout(context.Background(), defaultReqTimeout)
    defer cancel()

    _, err = client.RunDockerBench(ctx, &amp;amp;share.RPCVoid{})
    return err
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;切换到agent的代码中，我们看到RunDockerBench方法实际做的事情是调用了RerunDocker方法，在RerunDocker方法中执行的逻辑非常简单，就是reset
host timer和container timer, 同时设置下数据库中当前节点bench任务的状态为scheduled&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) RerunDocker() {
    log.Info(&quot;&quot;)

    if err := b.dockerCheckPrerequisites(); err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Cannot run Docker CIS benchmark&quot;)
        b.logBenchFailure(benchPlatDocker, share.BenchStatusNotSupport)
        b.putBenchReport(Host.ID, share.BenchDockerHost, nil, share.BenchStatusNotSupport)
    } else {
        b.hostTimer.Reset(hostTimerStart)
        b.conTimer.Reset(containerTimerStart)
        b.putBenchReport(Host.ID, share.BenchDockerHost, nil, share.BenchStatusScheduled)
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_bench2.png&quot; alt=&quot;neuvector bench&quot; /&gt;
通过上图我们发现，在agent启动时会启动一个后台任务BenchLoop，用来定时指定容器、host、k8s平台、自定义的合规性检测&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) BenchLoop() {
    var masterScript, workerScript, remediation string
    b.taskScanner = newTaskScanner(b, scanWorkerMax)
    //after the host bench, it will schedule a container bench automaticly even if no container
    for {
        select {
        case &amp;lt;-b.hostTimer.C:
            b.doDockerHostBench()

        case &amp;lt;-b.kubeTimer.C:
            ...

            b.doKubeBench(masterScript, workerScript, remediation)
        case &amp;lt;-b.conTimer.C:
            containers := b.cloneAllNewContainers()
            if Host.CapDockerBench {
                b.doDockerContainerBench(containers)
            } else {
                b.putBenchReport(Host.ID, share.BenchDockerContainer, nil, share.BenchStatusFinished)
            }

            ...
        case &amp;lt;-b.customConTimer.C:
            ...

            b.doContainerCustomCheck(wls)
        case &amp;lt;-b.customHostTimer.C:
            b.doHostCustomCheck()
        }
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里在reset container timer后，会立即触发定时任务的执行，也就是这里的doDockerContainerBench方法&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) doDockerContainerBench(containers map[string]string) error {
    b.putBenchReport(Host.ID, share.BenchDockerContainer, nil, share.BenchStatusRunning)
    if out, err := b.runDockerContainerBench(containers); err != nil {
        b.logBenchFailure(benchPlatDocker, share.BenchStatusDockerContainerFail)
        b.putBenchReport(Host.ID, share.BenchDockerContainer, nil, share.BenchStatusDockerContainerFail)
        return err
    } else {
        log.Info(&quot;Running benchmark checks done&quot;)

        list := b.getBenchMsg(out)
        b.assignDockerBenchMeta(list)

        b.putBenchReport(Host.ID, share.BenchDockerContainer, list, share.BenchStatusFinished)

        // Going through each container, write report and log
        ...
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里我们重点关注几个方法，分别是&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;runDockerContainerBench： 具体执行容器合规性检测，后面重点介绍&lt;/li&gt;
  &lt;li&gt;getBenchMsg：将执行结果格式化&lt;/li&gt;
  &lt;li&gt;assignDockerBenchMeta：执行结果格式化，主要是格式化合规项名称和profile&lt;/li&gt;
  &lt;li&gt;putBenchReport：将格式化后的结果保存到数据库中，等待获取结果的api调用时从数据库中获取&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面我们看看runDockerContainerBench方法：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) runDockerContainerBench(containers map[string]string) ([]byte, error) {
    ...

    if err := b.replaceDockerDaemonCmdline(srcContainerBenchSh, dstContainerBenchSh, cs); err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Replace container docker daemon cmdline error&quot;)
        return nil, fmt.Errorf(&quot;Replace container docker daemon cmdline error, error=%v&quot;, err)
    }

    args := []string{system.NSActRun, &quot;-f&quot;, dstContainerBenchSh, &quot;-m&quot;, global.SYS.GetMountNamespacePath(1)}
    var errb, outb bytes.Buffer

    log.WithFields(log.Fields{&quot;args&quot;: args}).Debug(&quot;Running bench script&quot;)
    cmd := exec.Command(system.ExecNSTool, args...)
    cmd.SysProcAttr = &amp;amp;syscall.SysProcAttr{Setsid: true}
    cmd.Stdout = &amp;amp;outb
    cmd.Stderr = &amp;amp;errb
    b.childCmd = cmd
    err := cmd.Start()
    ...
    return out, nil
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;该方法首先根据模板生成目标的cis检测脚本&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;模板位置：/usr/local/bin/container.tmpl，生成文件位置：/tmp/container.sh&lt;/li&gt;
  &lt;li&gt;根据模板生成脚本时传入当前节点所有容器的信息，脚本中会遍历$containers参数，执行检测任务&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;replaceDockerDaemonCmdline&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) replaceDockerDaemonCmdline(srcPath, dstPath string, containers []string) error {
    dat, err := ioutil.ReadFile(srcPath)
    if err != nil {
        return err
    }
    f, err := os.Create(dstPath)
    if err != nil {
        return err
    }
    defer f.Close()

    //containers only apply to container.sh, no effect to host.sh, because no &amp;lt;&amp;lt;&amp;lt;Containers&amp;gt;&amp;gt;&amp;gt; in it
    var containerLines string
    if len(containers) &amp;gt; 0 {
        containerLines = &quot;containers=\&quot;\n&quot; + strings.Join(containers, &quot;\n&quot;) + &quot;\&quot;\n&quot;
    } else {
        containerLines = &quot;containers=\&quot;\&quot;\n&quot;
    }
    r := DockerReplaceOpts{
        Replace_docker_daemon_opts: strings.Join(b.daemonOpts, &quot; &quot;),
        Replace_container_list:     containerLines,
    }
    t := template.New(&quot;bench&quot;)
    t.Delims(&quot;&amp;lt;&amp;lt;&amp;lt;&quot;, &quot;&amp;gt;&amp;gt;&amp;gt;&quot;)
    t.Parse(string(dat))

    if err = t.Execute(f, r); err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Executing template error&quot;)
        return err
    }
    return nil
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;生成玩cis检测脚本后，会调用nstool命令在host上执行检测命令：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;nstools run -f host.sh -m  /proc/1/ns/mnt -n /proc/1/ns/net
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里因为脚本会遍历节点上所有容器，通过docker命令执行检测操作，我们并不需要在容器内部执行，所以也不一定使用nstool工具，可以直接执行shell脚本&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;到了这里已经完成了某个节点上容器的合规性检测任务，我们看看执行返回的信息：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;...
[WARN] 4.1 - Ensure that a user for the container has been created (Automated)
[WARN]      * Running as root: k8s_busybox_busybox-hujin_default_7191a3da-4c51-467a-a004-db178d79e92a_1158

[WARN] 5.1 - Ensure that, if applicable, an AppArmor Profile is enabled (Automated)
[WARN]      * No AppArmorProfile Found: k8s_busybox_busybox-hujin_default_7191a3da-4c51-467a-a004-db178d79e92a_1158
[PASS] 5.2 - Ensure that, if applicable, SELinux security options are set (Automated)
[PASS] 5.3 - Ensure that Linux kernel capabilities are restricted within containers (Automated)
[PASS] 5.4 - Ensure that privileged containers are not used (Automated)
[PASS] 5.5 - Ensure sensitive host system directories are not mounted on containers (Automated)
[PASS] 5.6 - Ensure sshd is not run within containers (Automated)
[PASS] 5.7 - Ensure privileged ports are not mapped within containers (Automated)
[PASS] 5.8 - Ensure that only needed ports are open on the container (Manual)
[PASS] 5.9 - Ensure that the host&apos;s network namespace is not shared (Automated)
...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;容器的合规性检测功能，neuvector是集成了docker-bench-security项目，将该项目的检测脚本整理成了一个container.tmpl模板&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;后面会将执行结果进行格式化并保存到数据库，代码流程就讲了&lt;/p&gt;

&lt;p&gt;这里还需要稍微提一下法规和cis的关系，我们在获取合规性检测结果的时候，handlerDockerBench - getCISReportFromCluster - _getCISReportFromCluster - 
bench2REST - GetComplianceMeta方法会将合规项添加法规对应的tag标识，方便进行过滤&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func GetComplianceMeta() ([]api.RESTBenchMeta, map[string]api.RESTBenchMeta) {
    if complianceMetas == nil || complianceMetaMap == nil {
        ...
        for _, item := range docker_image_cis_items {
            all = append(all, api.RESTBenchMeta{RESTBenchCheck: item})
        }

        for i, _ := range all {
            item := &amp;amp;all[i]
            item.Tags = make([]string, 0)
            if compliancePCI.Contains(item.TestNum) {
                item.Tags = append(item.Tags, api.ComplianceTemplatePCI)
            }
            if complianceGDPR.Contains(item.TestNum) {
                item.Tags = append(item.Tags, api.ComplianceTemplateGDPR)
            }
            if complianceHIPAA.Contains(item.TestNum) {
                item.Tags = append(item.Tags, api.ComplianceTemplateHIPAA)
            }
            if complianceNIST.Contains(item.TestNum) {
                item.Tags = append(item.Tags, api.ComplianceTemplateNIST)
            }
            ...
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;支持的法规包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;PCI&lt;/li&gt;
  &lt;li&gt;GDPR&lt;/li&gt;
  &lt;li&gt;HIPAA&lt;/li&gt;
  &lt;li&gt;NIST&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;从上面的代码分析，我们看到neuvector支持对host/container/kubernetes平台的合规性检测，同时支持一些常见的法规，可以输出非常清晰的格式化结果并提供下载；
但我们也可以发现一些不足的地方，包括不支持其他runtime、不支持国内的法规等问题。
neuvector实际通过集成一个叫kubernetes-cis-benchmark的项目来实现基线扫描功能，此项目目前基本不维护了，导致支持的k8s版本一直停留在v1.18,且扫描出来的问题有些是不对的。
建议还是使用kube-bench来扫描，或者neuvector可以将kube-bench集成进来&lt;/p&gt;
</description>
        <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/09/21/neuvector-bench/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/09/21/neuvector-bench/</guid>
        
        <category>neuvector</category>
        
        <category>合规性检测</category>
        
        <category>compliance</category>
        
        
      </item>
    
      <item>
        <title>Calico BGP - Bird</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;Calico支持多种网络模式，包括vxlan/ipip/bgp，其中vxlan和ipip属于overlay类型，在嵌套部署模式比较通用，但网络性能相对bgp会低一些。这主要是由于bgp模式下没有数据报文的封包和解包操作&lt;/p&gt;

&lt;p&gt;本文会将calico中bgp相关的操作流程抽离，通过demo的方式来介绍calico中bgp网络的实现&lt;/p&gt;

&lt;h2 id=&quot;架构&quot;&gt;架构&lt;/h2&gt;
&lt;p&gt;calico架构
&lt;img src=&quot;/blog/img/calico.png&quot; alt=&quot;calico_bird&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Calico作为一种常用的Kubernetes网络插件，使用BGP协议对各节点的容器网络进行路由交换。Calico中使用的软件BGP方案是Bird&lt;/p&gt;

&lt;p&gt;BIRD（BIRD Internet Routing Daemon）是一款可运行在Linux和其他类Unix系统上的路由软件，它实现了多种路由协议，比如BGP、OSPF、RIP等。&lt;/p&gt;

&lt;p&gt;BIRD会在内存中维护许多路由表，路由表根据不同的协议，通过与各种“其他事物”交换路由信息，来更新路由规则。这里说的“其他事物”可能是其他的路由表，也可能是外部的路由器，还可以是内核的某些API&lt;/p&gt;

&lt;p&gt;demo架构&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/calico_demo.png&quot; alt=&quot;calico_bird&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;实现&quot;&gt;实现&lt;/h2&gt;
&lt;h3 id=&quot;模拟calico-cni创建和配置网卡的操作&quot;&gt;模拟calico cni创建和配置网卡的操作&lt;/h3&gt;
&lt;p&gt;node1节点&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# 创建namespace和虚拟网卡
ip netns add ns1
ip link add tap1 type veth peer name nsvth netns ns1
ip link set tap1 up
ip netns exec ns1 ip link set lo up
ip netns exec ns1 ip link set nsvth up


# 配置路由和IP地址
ip netns exec ns1 ip addr add 10.244.166.128/24 dev nsvth
ip r add 10.244.166.128/32 dev tap1
ip netns exec ns1 ip r add 169.254.1.1 dev nsvth
ip netns exec ns1 ip r add default via 169.254.1.1 dev nsvth


# 配置neigh
ip link set address ee:ee:ee:ee:ee:ee dev tap1
ip netns exec ns1 ip neigh add 169.254.1.1 dev nsvth lladdr ee:ee:ee:ee:ee:ee
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;node2节点&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# 创建namespace和虚拟网卡
ip netns add ns2
ip link add tap1 type veth peer name nsvth netns ns2
ip link set tap1 up
ip netns exec ns2 ip link set lo up
ip netns exec ns2 ip link set nsvth up


# 配置路由和IP地址
ip netns exec ns2 ip addr add 10.244.104.0/24 dev nsvth
ip r add 10.244.104.0/32 dev tap1
ip netns exec ns2 ip r add 169.254.1.1 dev nsvth
ip netns exec ns2 ip r add default via 169.254.1.1 dev nsvth


# 配置neigh
ip link set address ee:ee:ee:ee:ee:ee dev tap1
ip netns exec ns2 ip neigh add 169.254.1.1 dev nsvth lladdr ee:ee:ee:ee:ee:ee
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;每个节点启动bird
启动一个容器并获取内部的bird二进制文件，镜像使用calico/node:v3.11.1&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;docker run --name calico-temp -d calico/node:v3.11.1 sleep 200
docker cp calico-temp:/usr/bin/bird /usr/bin
docker rm -f calico-temp
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建bird.cfg配置&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;function apply_communities ()
{
}

# Generated by confd
include &quot;bird_aggr.cfg&quot;;
include &quot;bird_ipam.cfg&quot;;

router id 10.20.30.30;

# Configure synchronization between routing tables and kernel.
protocol kernel {
  learn;             # Learn all alien routes from the kernel
  persist;           # Don&apos;t remove routes on bird shutdown
  scan time 2;       # Scan kernel routing table every 2 seconds
  import all;
  export filter calico_kernel_programming; # Default is export none
  graceful restart;  # Turn on graceful restart to reduce potential flaps in
                     # routes when reloading BIRD configuration.  With a full
                     # automatic mesh, there is no way to prevent BGP from
                     # flapping since multiple nodes update their BGP
                     # configuration at the same time, GR is not guaranteed to
                     # work correctly in this scenario.
  merge paths on;    # Allow export multipath routes (ECMP)
}

# Watch interface up/down events.
protocol device {
  debug { states };
  scan time 2;    # Scan interfaces every 2 seconds
}

protocol direct {
  debug { states };
  interface -&quot;cali*&quot;, -&quot;kube-ipvs*&quot;, &quot;*&quot;; # Exclude cali* and kube-ipvs* but
                                          # include everything else.  In
                                          # IPVS-mode, kube-proxy creates a
                                          # kube-ipvs0 interface. We exclude
                                          # kube-ipvs0 because this interface
                                          # gets an address for every in use
                                          # cluster IP. We use static routes
                                          # for when we legitimately want to
                                          # export cluster IPs.
}


# Template for all BGP clients
template bgp bgp_template {
  debug { states };
  description &quot;Connection to BGP peer&quot;;
  local as 64512;
  multihop;
  gateway recursive; # This should be the default, but just in case.
  import all;        # Import all routes, since we don&apos;t know what the upstream
                     # topology is and therefore have to trust the ToR/RR.
  export filter calico_export_to_bgp_peers;  # Only want to export routes for workloads.
  add paths on;
  graceful restart;  # See comment in kernel section about graceful restart.
  connect delay time 2;
  connect retry time 5;
  error wait time 5,30;
}

# ------------- Node-to-node mesh -------------





# For peer /host/node1/ip_addr_v4
# Skipping ourselves (10.20.30.30)




# For peer /host/node2/ip_addr_v4
protocol bgp Mesh_10_20_30_31 from bgp_template {
  neighbor 10.20.30.31 as 64512;
  source address 10.20.30.30;  # The local address we use for the TCP connection
  passive on; # Mesh is unidirectional, peer will connect to us.
}



# For peer /host/node3/ip_addr_v4
#protocol bgp Mesh_10_20_30_32 from bgp_template {
#  neighbor 10.20.30.32 as 64512;
#  source address 10.20.30.30;  # The local address we use for the TCP connection
#  passive on; # Mesh is unidirectional, peer will connect to us.
#}



# ------------- Global peers -------------
# No global peers configured.


# ------------- Node-specific peers -------------

# No node-specific peers configured.
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建bird_ipam.cfg配置&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# Generated by confd
filter calico_export_to_bgp_peers {
  # filter code terminates when it calls `accept;` or `reject;`, call apply_communities() before calico_aggr()
  apply_communities();
  calico_aggr();

  if ( net ~ 10.244.0.0/16 ) then {
    accept;
  }
  reject;
}


filter calico_kernel_programming {

  if ( net ~ 10.244.0.0/16 ) then {
    krt_tunnel = &quot;&quot;;
    accept;
  }

  accept;
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建bird_aggr.cfg配置&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# Generated by confd

protocol static {
   # IP blocks for this host.
   route 10.244.166.128/26 blackhole;
}


# Aggregation of routes on this host; export the block, nothing beneath it.
function calico_aggr ()
{
      # Block 10.244.166.128/26 is confirmed
      if ( net = 10.244.166.128/26 ) then { accept; }
      if ( net ~ 10.244.166.128/26 ) then { reject; }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;运行bird进程&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;bird -R -s ./bird.ctl -d -c ./bird.cfg
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此时在node1/node2节点会发现分别多了一条到对方的路由规则&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 bird]# ip r
default via 179.20.23.1 dev ens160 proto static metric 100 
10.20.30.0/24 dev ens192 proto kernel scope link src 10.20.30.30 metric 101 
10.244.104.0/26 via 10.20.30.31 dev ens192 proto bird 
10.244.166.128 dev tap1 scope link 
blackhole 10.244.166.128/26 proto bird 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
179.20.23.0/24 dev ens160 proto kernel scope link src 179.20.23.30 metric 100

[root@node2 ~]# ip r
default via 179.20.23.1 dev ens160 proto static metric 100 
10.20.30.0/24 dev ens192 proto kernel scope link src 10.20.30.31 metric 101 
10.244.104.0 dev tap1 scope link 
blackhole 10.244.104.0/26 proto bird 
10.244.104.1 dev cali6fa4fc0f157 scope link 
10.244.104.2 dev calif2ac964c43c scope link 
10.244.166.128/26 via 10.20.30.30 dev ens192 proto bird 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
179.20.23.0/24 dev ens160 proto kernel scope link src 179.20.23.31 metric 100
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;从node1的ns1中ping node2的ns1 ip&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 bird]# ip netns exec ns ip a 
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: nsvth@if9: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 2e:be:65:26:b3:0d brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 10.244.166.128/24 scope global nsvth
       valid_lft forever preferred_lft forever
    inet6 fe80::2cbe:65ff:fe26:b30d/64 scope link 
       valid_lft forever preferred_lft forever

[root@node1 bird]# ip netns exec ns ping 10.244.104.0
PING 10.244.104.0 (10.244.104.0) 56(84) bytes of data.
64 bytes from 10.244.104.0: icmp_seq=1 ttl=62 time=0.299 ms
64 bytes from 10.244.104.0: icmp_seq=2 ttl=62 time=0.356 ms
64 bytes from 10.244.104.0: icmp_seq=3 ttl=62 time=0.314 ms
^C
--- 10.244.104.0 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2033ms
rtt min/avg/max/mdev = 0.299/0.323/0.356/0.024 ms
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;bird手册：The BIRD Internet Routing Daemon Project (network.cz)&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 16 Sep 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/09/16/calico-bird/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/09/16/calico-bird/</guid>
        
        <category>calico</category>
        
        <category>bgp</category>
        
        
      </item>
    
      <item>
        <title>Neuvector源码分析之 dp引流的实现</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;在neuvector中通过监听runtime事件来动态维护节点上容器基础信息，在界面支持策略配置、模式管理都对容器流量产生影响。用户从学习模式调整成保护模式时可以对容器流量进行阻断操作，那么agent
中是如何实现阻断的？
这里我们将核心流程抽离出来，通过demo的方式来介绍具体的实现细节&lt;/p&gt;

&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;
&lt;h3 id=&quot;默认形态&quot;&gt;默认形态&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_dp1.png&quot; alt=&quot;neuvector_pcap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;开始之前先看下默认情况下容器的网络形态（以calico为例）:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;容器网卡使用veth设备，一端在容器内部，一端在host上&lt;/li&gt;
  &lt;li&gt;在host上通过路由规则的方式将流量引到host上的veth设备，最终到达容器内部&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;引流形态&quot;&gt;引流形态&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_dp2.png&quot; alt=&quot;neuvector_pcap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;引流形态下流量会优先经过agent容器，根据策略规则过滤后转发到具体的容器内部。本次我们需要从host上直接ping container-ns中的网卡ip 10.10.10.88,&lt;/p&gt;

&lt;p&gt;首先创建两个network namespace&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ns1：引流实现位置&lt;/li&gt;
  &lt;li&gt;ns2：模拟普通容器的network namespace&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;命令&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;ip netns add agent-ns
ip netns add container-ns
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在host上创建三组veth&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;vex：流量入口&lt;/li&gt;
  &lt;li&gt;vin：跨agent-ns和container-ns，在agent中将流量转发到这个设备就可以到达容器内部&lt;/li&gt;
  &lt;li&gt;vbr：监控设备，也是dp工作的设备&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;命令：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# 创建veth
ip link add vex type veth peer name vex-peer
ip link add vin type veth peer name vin-peer
ip link add vbr type veth peer name vth
 
# 将vex放入agent-ns
ip link set vex netns agent-ns
ip netns exec agent-ns ip link set vex up
 
# 将vin放入agent-ns
ip link set vin netns agent-ns
ip netns exec agent-ns ip link set vin up
 
# 将vin-peer放入container-ns
ip link set vin-peer netns container-ns
 
# 在container-ns修改网卡名称为eth0
ip netns exec container-ns ip link set vin-peer name eth0
ip addr add 10.10.10.88/24 dev eth0
ip netns exec container-ns ip link set eth0 up
 
# 将vbr和vth都放入agent-ns
ip link set vbr netns agent-ns
ip link set vth netns agent-ns
ip netns exec agent-ns ip link set vbr up
ip netns exec agent-ns ip link set vth up

# 配置host上的vex-peer
ip addr add 10.10.10.66/24 dev vex-peer
ip link set vex-peer up
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;tc引流&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# 创建qdisc
tc qdisc add dev vin ingress
tc qdisc add dev vex ingress
tc qdisc add dev vbr ingress

# 创建filter
tc filter add dev vex pref 10001 parent ffff: protocol ip u32 match u8 0 1 at -14 match u16 0x1a27 0xffff at -14 match u32 0xf3873a27 0xffffffff at -12 action pedit munge offset -14 u16 set 0x4e65 munge offset -12 u32 set 0x755600b4 pipe action mirred egress mirror dev vbr
 
tc filter add dev vex pref 10002 parent ffff: protocol all u32 match u8 0 0 action mirred egress mirror dev vin
 
tc filter add dev vbr pref 5 parent ffff: protocol all u32 match u16 0x4e65 0xffff at -14 match u32 0x755600b4 0xffffffff at -12 action pedit munge offset -14 u16 set 0x1a27 munge offset -12 u32 set 0xf3873a27 pipe action mirred egress mirror dev vin
 
tc filter add dev vin pref 10002 parent ffff: protocol all u32 match u8 0 0 action mirred egress mirror dev vex
 
tc filter add dev vin pref 10001 parent ffff: protocol ip u32 match u8 0 1 at -14 match u32 0x1a27f387 0xffffffff at -8 match u16 0x3a27 0xffff at -4 action pedit munge offset -8 u32 set 0x4e657556 munge offset -4 u16 set 0x00b4 pipe action mirred egress mirror dev vbr
 
tc filter add dev vbr pref 172 parent ffff: protocol all u32 match u32 0x4e657556 0xffffffff at -8 match u16 0x00b4 0xffff at -4 action pedit munge offset -8 u32 set 0x1a27f387 munge offset -4 u16 set 0x3a27 pipe action mirred egress mirror dev vex
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此时我们从host上ping 10.10.10.88，同时在agent-ns的vex和vbr抓包会看到数据包&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这里从抓包结果会看到目标mac变了，这个是通过tc完成的&lt;/li&gt;
  &lt;li&gt;但是在vin上是抓不到包的（可以抓到广播包），因为dp没有开始工作&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;抓包结果：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;sh-4.2# tcpdump -enpli vex
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on vex, link-type EN10MB (Ethernet), capture size 262144 bytes
17:31:40.761531 06:82:9c:02:54:91 &amp;gt; 1a:27:f3:87:3a:27, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 214, length 64
17:31:41.761533 06:82:9c:02:54:91 &amp;gt; 1a:27:f3:87:3a:27, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 215, length 64
17:31:42.761516 06:82:9c:02:54:91 &amp;gt; 1a:27:f3:87:3a:27, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 216, length 64
^C
3 packets captured
3 packets received by filter
0 packets dropped by kernel
sh-4.2# tcpdump -enpli vbr
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on vbr, link-type EN10MB (Ethernet), capture size 262144 bytes
17:31:45.761528 06:82:9c:02:54:91 &amp;gt; 4e:65:75:56:00:b4, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 219, length 64
17:31:46.761515 06:82:9c:02:54:91 &amp;gt; 4e:65:75:56:00:b4, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 220, length 64
17:31:47.761531 06:82:9c:02:54:91 &amp;gt; 4e:65:75:56:00:b4, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 221, length 64
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;运行dp&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;ip netns exec agent-ns dp -n 1
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里需要重新编译dp，对dp做一些改造，保证可以在host运行，主要是mmap那部分逻辑&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;调用dp接口&lt;/p&gt;

&lt;p&gt;分别调用dp接口：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ctrl_add_srvc_port： 配置引流设备名称等参数&lt;/li&gt;
  &lt;li&gt;ctrl_cfg_internal_net：配置当前节点设备ip和类型&lt;/li&gt;
  &lt;li&gt;ctrl_add_mac：在引流设备中添加需要引流的mac&lt;/li&gt;
  &lt;li&gt;ctrl_cfg_mac：配置mac参数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;调用脚本&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;import socket
import json
 
DP_SERVER_PATH = &apos;/tmp/dp_listen.sock&apos;
SOCK = None

def connect_dp():
    global SOCK
    if SOCK:
        return SOCK
    socket_family = socket.AF_UNIX
    socket_type = socket.SOCK_DGRAM
 
    sock = socket.socket(socket_family, socket_type)
    sock.connect(DP_SERVER_PATH)
    SOCK = sock
    print(&quot;dp connected&quot;)
    return sock
 
 
def send_msg(msg):
    sock = connect_dp()
    sock.sendall(json.dumps(msg).encode())
 
    # data = sock.recv(1024)
    # print(&quot;receive data:&quot;, data)
    print(&apos;send msg: %s success&apos; % msg)
 
 
def add_srvc_port():
    data = {
        &quot;iface&quot;: &quot;vth&quot;,
        &quot;jumboframe&quot;: False
    }
    send_msg({&apos;ctrl_add_srvc_port&apos;: data})
 
 
def add_internal_net():
    data = {
        &quot;flag&quot;: 3,
        &quot;subnet_addr&quot;: [
            {&quot;ip&quot;: &quot;172.17.0.0&quot;, &quot;mask&quot;: &quot;255.255.0.0&quot;},
            {&quot;ip&quot;: &quot;179.20.23.0&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;},
            {&quot;ip&quot;: &quot;10.10.10.0&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;},
            {&quot;ip&quot;: &quot;172.20.166.0&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;},
            {&quot;ip&quot;: &quot;10.10.10.66&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;, &quot;iptype&quot;: &quot;devip&quot;},
            {&quot;ip&quot;: &quot;10.10.10.88&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;, &quot;iptype&quot;: &quot;devip&quot;},
 
        ]
    }
    send_msg({&apos;ctrl_cfg_internal_net&apos;: data})
 
 
def add_mac():
    data = {
        &quot;iface&quot;: &quot;vth&quot;,
        &quot;mac&quot;: &quot;1a:27:f3:87:3a:27&quot;,
        &quot;ucmac&quot;: &quot;4e:65:75:56:00:b4&quot;,
        &quot;bcmac&quot;: &quot;ff:ff:ff:00:00:b4&quot;,
        &quot;oldmac&quot;: &quot;&quot;,
        &quot;pmac&quot;: &quot;&quot;,
        &quot;pips&quot;: None,
    }
    send_msg({&apos;ctrl_add_mac&apos;: data})
 
 
def cfg_mac():
    data = {
        &quot;tap&quot;: False,
        &quot;macs&quot;: [&quot;1a:27:f3:87:3a:27&quot;],
    }
    send_msg({&apos;ctrl_cfg_mac&apos;: data})
 
add_internal_net()
add_srvc_port()
add_mac()
cfg_mac()
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;可以看到neuvector的引流方式和容器使用的cni无关&lt;/li&gt;
  &lt;li&gt;引流的准备操作实际是agent执行的，dp只是对经过vth的数据包根据策略规则进行过滤，并转发&lt;/li&gt;
  &lt;li&gt;后期可以探索这种使用方式是否可以应用到虚拟机状态下&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里只是调用dp接口，dp内部实现将在后面详细分析&lt;/p&gt;
</description>
        <pubDate>Tue, 23 Aug 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/08/23/neuvector-dp/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/08/23/neuvector-dp/</guid>
        
        <category>neuvector</category>
        
        <category>deep packet inspection</category>
        
        <category>dpi</category>
        
        <category>tc</category>
        
        
      </item>
    
      <item>
        <title>Neuvector源码分析之 网络抓包</title>
        <description>&lt;h2 id=&quot;功能介绍&quot;&gt;功能介绍&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_tcpdump.png&quot; alt=&quot;neuvector_pcap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;抓包功能是针对容器的功能，用户在界面选择某个容器点击抓包功能，可以控制抓包开始和结束，可以选择抓包时间；完成后可以下载对应的pcap格式的文件，
在本地的wireshark中直接打开进行分析。底层实际还是通过进入容器的网络namespace，执行tcpdump命令来实现。&lt;/p&gt;

&lt;p&gt;说明下：hostnetwork的容器暂不支持抓包功能&lt;/p&gt;

&lt;p&gt;API接口：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;neuvector\controller\rest\rest.go:1517

r.GET(&quot;/v1/sniffer&quot;, handlerSnifferList)
r.GET(&quot;/v1/sniffer/:id&quot;, handlerSnifferShow)
r.POST(&quot;/v1/sniffer&quot;, handlerSnifferStart)
r.PATCH(&quot;/v1/sniffer/stop/:id&quot;, handlerSnifferStop)
r.DELETE(&quot;/v1/sniffer/:id&quot;, handlerSnifferDelete)
r.GET(&quot;/v1/sniffer/:id/pcap&quot;, handlerSnifferGetFile)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;源码分析&quot;&gt;源码分析&lt;/h2&gt;

&lt;p&gt;这里我们重点看下创建，也就是handlerSnifferStart的代码流程：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func handlerSnifferStart(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {
  ...
  # 从request中获取对应的参数，这里是workloadid，也就是对应的pause容器的container id
  query := restParseQuery(r)

  # 获取容器id参数，并根据容器id获取对应的agentid
  agentID, wlID, err := getAgentWorkloadFromFilter(query.filters, acc)
  if err != nil {
      restRespNotFoundLogAccessDenied(w, login, err)
      return
  }

  // Check if we can config workload
  wl, err := cacher.GetWorkloadBrief(wlID, &quot;&quot;, acc)
  if wl == nil {
      restRespNotFoundLogAccessDenied(w, login, err)
      return
  } else if !acc.Authorize(&amp;amp;share.CLUSSnifferDummy{WorkloadDomain: wl.Domain}, nil) {
      restRespAccessDenied(w, login)
      return
  }
  ...

  args := proc.Sniffer
  req := &amp;amp;share.CLUSSnifferRequest{WorkloadID: wlID, Cmd: share.SnifferCmd_StartSniffer}
  ...

  res, err := rpc.SnifferCmd(agentID, req)
  ...
  restRespSuccess(w, r, &amp;amp;resp, acc, login, &amp;amp;proc, &quot;Start sniffer&quot;)
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;代码会从request中获取需要抓包的容器id&lt;/li&gt;
  &lt;li&gt;getAgentWorkloadFromFilter中获取容器id并查询对应的agent id&lt;/li&gt;
  &lt;li&gt;GetWorkloadBrief 获取指定容器的详细信息，并校验容器是否允许抓包&lt;/li&gt;
  &lt;li&gt;SnifferCmd 通过grpc调用对应agent的抓包接口，这里会提前配置一些抓包的参数，包括文件名称、文件大小（默认2M）、抓包时间等等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们在agent中查看对应的调用接口SnifferCmd，文件位置：neuvector\agent\service.go:830&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (rs *RPCService) SnifferCmd(ctx context.Context, req *share.CLUSSnifferRequest) (*share.CLUSSnifferResponse, error) {
    if req.Cmd == share.SnifferCmd_StartSniffer {
        id, err := startSniffer(req)
        return &amp;amp;share.CLUSSnifferResponse{ID: id}, err
    } else if req.Cmd == share.SnifferCmd_StopSniffer {
        return &amp;amp;share.CLUSSnifferResponse{}, stopSniffer(req.ID)
    } else if req.Cmd == share.SnifferCmd_RemoveSniffer {
        return &amp;amp;share.CLUSSnifferResponse{}, removeSniffer(req.ID)
    }
    return &amp;amp;share.CLUSSnifferResponse{}, grpc.Errorf(codes.InvalidArgument, &quot;Invalid sniffer command&quot;)
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;继续查看对应的startSniffer方法：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func startSniffer(info *share.CLUSSnifferRequest) (string, error) {
    var pid int

    gInfoRLock()
    c, ok := gInfo.activeContainers[info.WorkloadID]
    ...

    proc := &amp;amp;procInfo{
        workload:   info.WorkloadID,
        fileNumber: uint(info.FileNumber),
        duration:   uint(info.DurationInSecond),
    }

    key := generateSnifferID()

    proc.fileName, proc.args = parseArgs(info, key[:share.SnifferIdAgentField])
    _, err := startSnifferProc(key, proc, pid)
    if err != nil {
        return &quot;&quot;, grpc.Errorf(codes.Internal, err.Error())
    } else {
        return key, nil
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里根据容器id或者内存中容器对象，这个对象实际是通过独立线程监听节点的runtime维护的信息&lt;/li&gt;
  &lt;li&gt;generateSnifferID 这个是根据agent id生成一个id作为文件名称的一部分&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;生成tcpdump命令代码&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func parseArgs(info *share.CLUSSnifferRequest, keyname string) (string, []string) {
    ...
    filename = defaultPcapDir + keyname + &quot;_&quot;
    filenumber = fmt.Sprintf(&quot;%d&quot;, info.FileNumber)
    filesize = fmt.Sprintf(&quot;%d&quot;, info.FileSizeInMB)
    ...

    tcpdumpCmd := []string{&quot;-i&quot;, &quot;any&quot;, &quot;-U&quot;, &quot;-C&quot;}
    cmdStr = append(tcpdumpCmd, filesize, &quot;-w&quot;, filename, &quot;-W&quot;, filenumber)
    ...
    return filename, cmdStr
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;parseArgs用来生成完整的文件名称，并准备具体的tcpdump命令，完整的命令类似： tcpdump -i any -U -C 2 -w /var/neuvector/pcap/0a5bdf2c_0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面就是进入容器的network namespace然后执行tcpdump命令&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func startSnifferProc(key string, proc *procInfo, pid int) (string, error) {
    ...

    var script string
    if proc.duration &amp;gt; 0 {
        script = fmt.Sprintf(&quot;timeout %d &quot;, proc.duration)
    }
    script += &quot;tcpdump &quot; + strings.Join(proc.args, &quot; &quot;)
    log.WithFields(log.Fields{&quot;key&quot;: key, &quot;cmd&quot;: script}).Debug()

    proc.cmd = exec.Command(system.ExecNSTool, system.NSActRun, &quot;-i&quot;, &quot;-n&quot;, global.SYS.GetNetNamespacePath(pid))
    proc.cmd.SysProcAttr = &amp;amp;syscall.SysProcAttr{Setsid: true}
    proc.cmd.Stderr = &amp;amp;proc.errb
    stdin, err := proc.cmd.StdinPipe()
    if err != nil {
        e := fmt.Errorf(&quot;Open nsrun stdin error&quot;)
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(e)
        return &quot;&quot;, e
    }

    err = proc.cmd.Start()
    if err != nil {
        e := fmt.Errorf(&quot;Failed to start sniffer&quot;)
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(e)
        return &quot;&quot;, e
    }

    pgid := proc.cmd.Process.Pid
    global.SYS.AddToolProcess(pgid, pid, &quot;sniffer&quot;, script)

    io.WriteString(stdin, script)
    stdin.Close()

    ...
    return status, err
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里就是通过nstool工具进入容器network namespace, 将tcpdump命令作为stdin在namespace中执行&lt;/li&gt;
  &lt;li&gt;完整的命令类似：echo “tcpdump -i any -U -C 2 -w /var/neuvector/pcap/xxx  -W 5” | ./nstools run -i -n /proc/2271/ns/net&lt;/li&gt;
  &lt;li&gt;nstools这个工具类似nsenter，为了安全工具内部会校验调用方必须是neuvector agent服务，所以一般情况下执行这个命令是会失败的&lt;/li&gt;
  &lt;li&gt;监听tcpdump进程状态并返回状态信息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其他方法比如stop、下载抓包文件的调用路径是类似的&lt;/p&gt;

&lt;p&gt;nstools工具使用（移除父进程校验后）：
&lt;img src=&quot;/blog/img/neuvector_nstools.png&quot; alt=&quot;neuvector_pcap&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 10 Aug 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/08/10/neuvector-tcpdump/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/08/10/neuvector-tcpdump/</guid>
        
        <category>tcpdump</category>
        
        <category>neuvector</category>
        
        <category>抓包</category>
        
        
      </item>
    
      <item>
        <title>Neuvector 初探</title>
        <description>&lt;h2 id=&quot;介绍&quot;&gt;介绍&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_arch1.png&quot; alt=&quot;neuvector_arch&quot; /&gt;&lt;/p&gt;

&lt;p&gt;NeuVector 是业界首个端到端的开源容器安全平台，唯一为容器化工作负载提供企业级零信任安全的解决方案。
NeuVector 可以提供实时深入的容器网络可视化、东西向容器网络监控、主动隔离和保护、容器主机安全以及
容器内部安全，容器管理平台无缝集成并且实现应用级容器安全的自动化，适用于各种云环境、跨云或者本地部署等容器生产环境。&lt;/p&gt;

&lt;p&gt;我们重点看neuvector的网络功能。 neuvector的网络架构中分为controller和agent端&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;controller：控制服务，提供api接口，启动并watch consul数据库&lt;/li&gt;
  &lt;li&gt;agent：节点服务，负责监控节点上容器资源，根据用户规则执行响应操作&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;控制服务在提供统一的接口服务的同时，还运行consul服务，用来提供数据持久化功能，用户在调用neuvector接口后会将数据保存到key/value数据库consul中
控制服务和agent的通信有两种方式：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;watch consul:由于每个节点上的agent服务会watch consul的数据变动（类似etcd），其实是watch指定的key；在控制服务往consul中增加新的记录后，
agent在watch到后根据对应key调用对应的方法处理。&lt;/li&gt;
  &lt;li&gt;grpc：controller在某些功能中会直接通过grpc的方式调用agent，比如容器网络抓包功能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;agent服务除了响应controller的grpc调用以外，在启动时会创建一个独立的协程来监听当前节点容器资源的变化，会获取当前节点使用的runtime来调用对应的monitor方法
runtime支持docker/containerd/crio，支持获取容器的事件包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;start&lt;/li&gt;
  &lt;li&gt;stop&lt;/li&gt;
  &lt;li&gt;delete&lt;/li&gt;
  &lt;li&gt;copyin&lt;/li&gt;
  &lt;li&gt;copyout&lt;/li&gt;
  &lt;li&gt;network create&lt;/li&gt;
  &lt;li&gt;network delete&lt;/li&gt;
  &lt;li&gt;socket error&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;dp是一个内核模块，在agent中维护，通过socket和agent进行通信，用来具体执行用户的网络规则，对容器网卡的in/out/status流量进行处理，详细的会在网络策略时讲&lt;/p&gt;

&lt;p&gt;后面会重点从源码角度对neuvector的网络抓包、进程管理、文件管理和网络策略进行分析&lt;/p&gt;

&lt;h2 id=&quot;部署&quot;&gt;部署&lt;/h2&gt;

&lt;p&gt;这里我们通过helm快速部署&lt;/p&gt;

&lt;p&gt;安装helm&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;curl -fsSL -o get_helm.sh     https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
chmod 700 get_helm.sh
./get_helm.sh
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;添加repo&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;helm repo add neuvector https://neuvector.github.io/neuvector-helm/
helm search repo neuvector/core
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;开始部署&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl create namespace neuvector
kubectl create serviceaccount neuvector -n neuvector

helm install neuvector --namespace neuvector neuvector/core  \
--set registry=harbor.archeros.cn/dev  --set tag=5.0.1 \
--set=controller.image.repository=neuvector/controller \
--set=enforcer.image.repository=neuvector/enforcer \
--set manager.image.repository=neuvector/manager \
--set cve.scanner.image.repository=neuvector/scanner \
--set cve.updater.image.repository=neuvector/updater
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;访问webui&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 ~]# kubectl get svc -n neuvector  |grep webui
neuvector-service-webui           NodePort    10.68.204.173   &amp;lt;none&amp;gt;        8443:30080/TCP                  5d

浏览器访问： https://&amp;lt;管理ip&amp;gt;:30080
默认用户密码都是: admin
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;后面我们将从源码级别来逐个分析neuvector的网络功能&lt;/p&gt;

</description>
        <pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/08/09/neuvector-introduce/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/08/09/neuvector-introduce/</guid>
        
        <category>neuvector</category>
        
        
      </item>
    
      <item>
        <title>5分钟快速部署Kubernetes集群</title>
        <description>&lt;h2 id=&quot;环境信息&quot;&gt;环境信息&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;操作系统：centos7.6 4C8G&lt;/li&gt;
  &lt;li&gt;节点个数：1&lt;em&gt;master+2&lt;/em&gt;node&lt;/li&gt;
  &lt;li&gt;内核版本：3.10.0-1127.el7.x86_64&lt;/li&gt;
  &lt;li&gt;网络信息：1&lt;em&gt;管理 1&lt;/em&gt;业务&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;准备masternode&quot;&gt;准备（master+node）&lt;/h2&gt;

&lt;p&gt;每个节点修改hostname&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;hostnamectl set-hostname nodex
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;配置/etc/hosts&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cat /etc/hosts
179.20.23.30 node1
179.20.23.31 node2
179.20.23.32 node3
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;配置免密登录&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;ssh-keygen
ssh-copy-id node1
ssh-copy-id node2
ssh-copy-id node3
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;同步hosts文件&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;scp /etc/hosts node2:/etc
scp /etc/hosts node3:/etc
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;配置内核参数&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;vi /etc/sysctl.conf
net.ipv4.conf.all.forwarding=1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-arptables = 1
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.send_redirects = 0

sysctl -p
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关闭防火墙&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;systemctl stop firewalld
systemctl disable firewalld
setenforce 0

vi /etc/selinux/config
SELINUX=disabled
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关闭swap&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;swapoff -a
vi /etc/sysctl.d/k8s.conf 添加下面一行：
vm.swappiness=0
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装docker-ce&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;yum install -y yum-utils device-mapper-persistent-data lvm2 wget
wget -O /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo
sudo sed -i &apos;s+download.docker.com+mirrors.tuna.tsinghua.edu.cn/docker-ce+&apos; /etc/yum.repos.d/docker-ce.repo
yum install docker-ce -y
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装kubectl kubeadm kubelet(版本自定义)&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
EOF

yum install kubelet-1.18.15 kubeadm-1.18.15 kubectl-1.18.15 -y
systemctl enable kubelet &amp;amp;&amp;amp; sudo systemctl start kubelet
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;预下载镜像（master节点即可）&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubeadm config images list --kubernetes-version=v1.18.15

cat images.sh 
#!/bin/bash
images=(kube-proxy:v1.18.15 kube-scheduler:v1.18.15 kube-controller-manager:v1.18.15 kube-apiserver:v1.18.15 etcd:3.4.3-0 pause:3.2 coredns:1.6.7)
for imageName in ${images[@]} ; do
docker pull harbor.archeros.cn/huayun-kubernetes/amd64/$imageName
docker tag harbor.archeros.cn/huayun-kubernetes/amd64/$imageName k8s.gcr.io/$imageName
docker rmi harbor.archeros.cn/huayun-kubernetes/amd64/$imageName
done
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;部署master节点&quot;&gt;部署master节点&lt;/h2&gt;

&lt;p&gt;创建配置文件&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;vi kubeadm.yaml 
apiVersion: kubeadm.k8s.io/v1beta2
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: &quot;179.20.23.33&quot;
  bindPort: 6443
nodeRegistration:
  taints:
  - effect: PreferNoSchedule
    key: node-role.kubernetes.io/master
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.18.15
networking:
  podSubnet: 10.244.0.0/16
  serviceSubnet: 10.96.0.0/16
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;配置k8s集群master节点的管理ip和端口
配置k8s集群版本
设置pod/service cidr&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;开始部署&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubeadm init --config=kubeadm.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;post deploy配置&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;允许master节点作为node节点使用&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl taint node node1 node-role.kubernetes.io/master-
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;部署node节点&quot;&gt;部署node节点&lt;/h2&gt;

&lt;p&gt;在master节点获取token&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubeadm token list |grep &quot;system:bootstrappers:kubeadm:default-node-token&quot; |awk &apos;{print $1}&apos;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;join集群&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubeadm join --token &amp;lt;mastertoken&amp;gt; --discovery-token-unsafe-skip-ca-verification &amp;lt;k8s_master_ip&amp;gt;:6443
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;部署cni&quot;&gt;部署cni&lt;/h2&gt;

&lt;p&gt;此时k8s集群实际已经可以运行，只是无法创建pod资源，这里我们来部署cni组件，以calico为例&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;curl https://docs.projectcalico.org/v3.18/manifests/calico.yaml -O
kubectl apply -f calico.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里如果需要管理和业务分离部署，可以修改配置文件指定业务网卡&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;我们这里的大部分准备操作，可以通过制作模板的方式提高效率，在实际的开发验证或者学习中可以极大节省我们的环境部署时间&lt;/p&gt;
</description>
        <pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/08/09/k8s-deploy/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/08/09/k8s-deploy/</guid>
        
        <category>kubernetes</category>
        
        <category>部署</category>
        
        <category>kubeadm</category>
        
        
      </item>
    
  </channel>
</rss>
