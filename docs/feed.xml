<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hujin Blog</title>
    <description>Hujin，Openstack &amp; SDN &amp; Kubernetes Lover，Software Engineer，| 与你一起发现更大的世界</description>
    <link>http://0.0.0.0:4000/blog/</link>
    <atom:link href="http://0.0.0.0:4000/blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 21 Sep 2022 08:17:50 +0000</pubDate>
    <lastBuildDate>Wed, 21 Sep 2022 08:17:50 +0000</lastBuildDate>
    <generator>Jekyll v4.2.2</generator>
    
      <item>
        <title>Neuvector源码分析之 合规性检测</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;Neuvector安全基线支持 CIS Benchmark 标准，可对容器、镜像、Register、主机、kubernetes 进行安全标准检查，多维度展现容器资产的基线合规情况并帮助建立容器运行环境下的最佳基线配置，减少攻击面
NeuVector 的合规性审核包括 CIS 基线测试、自定义检查、机密审核以及 PCI、GDPR 和其他法规的行业标准模板扫描。本文将通过源码的方式分析合规性检测的具体实现&lt;/p&gt;

&lt;h2 id=&quot;架构图&quot;&gt;架构图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_bench.png&quot; alt=&quot;neuvector bench&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从架构图中我们可以看到涉及两个模块，分别是:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;controller:负责提供API接口，保存业务数据&lt;/li&gt;
  &lt;li&gt;agent（enforce）：具体执行合规性检测的模块&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;源码&quot;&gt;源码&lt;/h2&gt;

&lt;p&gt;首先在rest.go中查看bench相关的接口，我们主要看下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;r.GET(&quot;/v1/bench/host/:id/docker&quot;, handlerDockerBench)
r.POST(&quot;/v1/bench/host/:id/docker&quot;, handlerDockerBenchRun)
r.GET(&quot;/v1/bench/host/:id/kubernetes&quot;, handlerKubeBench)
r.POST(&quot;/v1/bench/host/:id/kubernetes&quot;, handlerKubeBenchRun)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里我们通过docker合规性检测来了解具体的实现细节，在handlerDockerBenchRun方法中获取node id，并查询到这个node节点的agent信息，
方便后面的rpc调用&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func RunDockerBench(agentID string) error {
    client, err := findEnforcerServiceClient(agentID)
    if err != nil {
        return err
    }

    ctx, cancel := context.WithTimeout(context.Background(), defaultReqTimeout)
    defer cancel()

    _, err = client.RunDockerBench(ctx, &amp;amp;share.RPCVoid{})
    return err
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;切换到agent的代码中，我们看到RunDockerBench方法实际做的事情是调用了RerunDocker方法，在RerunDocker方法中执行的逻辑非常简单，就是reset
host timer和container timer, 同时设置下数据库中当前节点bench任务的状态为scheduled&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) RerunDocker() {
    log.Info(&quot;&quot;)

    if err := b.dockerCheckPrerequisites(); err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Cannot run Docker CIS benchmark&quot;)
        b.logBenchFailure(benchPlatDocker, share.BenchStatusNotSupport)
        b.putBenchReport(Host.ID, share.BenchDockerHost, nil, share.BenchStatusNotSupport)
    } else {
        b.hostTimer.Reset(hostTimerStart)
        b.conTimer.Reset(containerTimerStart)
        b.putBenchReport(Host.ID, share.BenchDockerHost, nil, share.BenchStatusScheduled)
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_bench2.png&quot; alt=&quot;neuvector bench&quot; /&gt;
通过上图我们发现，在agent启动时会启动一个后台任务BenchLoop，用来定时指定容器、host、k8s平台、自定义的合规性检测&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) BenchLoop() {
    var masterScript, workerScript, remediation string
    b.taskScanner = newTaskScanner(b, scanWorkerMax)
    //after the host bench, it will schedule a container bench automaticly even if no container
    for {
        select {
        case &amp;lt;-b.hostTimer.C:
            b.doDockerHostBench()

        case &amp;lt;-b.kubeTimer.C:
            ...

            b.doKubeBench(masterScript, workerScript, remediation)
        case &amp;lt;-b.conTimer.C:
            containers := b.cloneAllNewContainers()
            if Host.CapDockerBench {
                b.doDockerContainerBench(containers)
            } else {
                b.putBenchReport(Host.ID, share.BenchDockerContainer, nil, share.BenchStatusFinished)
            }

            ...
        case &amp;lt;-b.customConTimer.C:
            ...

            b.doContainerCustomCheck(wls)
        case &amp;lt;-b.customHostTimer.C:
            b.doHostCustomCheck()
        }
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里在reset container timer后，会立即触发定时任务的执行，也就是这里的doDockerContainerBench方法&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) doDockerContainerBench(containers map[string]string) error {
    b.putBenchReport(Host.ID, share.BenchDockerContainer, nil, share.BenchStatusRunning)
    if out, err := b.runDockerContainerBench(containers); err != nil {
        b.logBenchFailure(benchPlatDocker, share.BenchStatusDockerContainerFail)
        b.putBenchReport(Host.ID, share.BenchDockerContainer, nil, share.BenchStatusDockerContainerFail)
        return err
    } else {
        log.Info(&quot;Running benchmark checks done&quot;)

        list := b.getBenchMsg(out)
        b.assignDockerBenchMeta(list)

        b.putBenchReport(Host.ID, share.BenchDockerContainer, list, share.BenchStatusFinished)

        // Going through each container, write report and log
        ...
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里我们重点关注几个方法，分别是&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;runDockerContainerBench： 具体执行容器合规性检测，后面重点介绍&lt;/li&gt;
  &lt;li&gt;getBenchMsg：将执行结果格式化&lt;/li&gt;
  &lt;li&gt;assignDockerBenchMeta：执行结果格式化，主要是格式化合规项名称和profile&lt;/li&gt;
  &lt;li&gt;putBenchReport：将格式化后的结果保存到数据库中，等待获取结果的api调用时从数据库中获取&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面我们看看runDockerContainerBench方法：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) runDockerContainerBench(containers map[string]string) ([]byte, error) {
    ...

    if err := b.replaceDockerDaemonCmdline(srcContainerBenchSh, dstContainerBenchSh, cs); err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Replace container docker daemon cmdline error&quot;)
        return nil, fmt.Errorf(&quot;Replace container docker daemon cmdline error, error=%v&quot;, err)
    }

    args := []string{system.NSActRun, &quot;-f&quot;, dstContainerBenchSh, &quot;-m&quot;, global.SYS.GetMountNamespacePath(1)}
    var errb, outb bytes.Buffer

    log.WithFields(log.Fields{&quot;args&quot;: args}).Debug(&quot;Running bench script&quot;)
    cmd := exec.Command(system.ExecNSTool, args...)
    cmd.SysProcAttr = &amp;amp;syscall.SysProcAttr{Setsid: true}
    cmd.Stdout = &amp;amp;outb
    cmd.Stderr = &amp;amp;errb
    b.childCmd = cmd
    err := cmd.Start()
    ...
    return out, nil
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;该方法首先根据模板生成目标的cis检测脚本&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;模板位置：/usr/local/bin/container.tmpl，生成文件位置：/tmp/container.sh&lt;/li&gt;
  &lt;li&gt;根据模板生成脚本时传入当前节点所有容器的信息，脚本中会遍历$containers参数，执行检测任务&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;replaceDockerDaemonCmdline&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (b *Bench) replaceDockerDaemonCmdline(srcPath, dstPath string, containers []string) error {
    dat, err := ioutil.ReadFile(srcPath)
    if err != nil {
        return err
    }
    f, err := os.Create(dstPath)
    if err != nil {
        return err
    }
    defer f.Close()

    //containers only apply to container.sh, no effect to host.sh, because no &amp;lt;&amp;lt;&amp;lt;Containers&amp;gt;&amp;gt;&amp;gt; in it
    var containerLines string
    if len(containers) &amp;gt; 0 {
        containerLines = &quot;containers=\&quot;\n&quot; + strings.Join(containers, &quot;\n&quot;) + &quot;\&quot;\n&quot;
    } else {
        containerLines = &quot;containers=\&quot;\&quot;\n&quot;
    }
    r := DockerReplaceOpts{
        Replace_docker_daemon_opts: strings.Join(b.daemonOpts, &quot; &quot;),
        Replace_container_list:     containerLines,
    }
    t := template.New(&quot;bench&quot;)
    t.Delims(&quot;&amp;lt;&amp;lt;&amp;lt;&quot;, &quot;&amp;gt;&amp;gt;&amp;gt;&quot;)
    t.Parse(string(dat))

    if err = t.Execute(f, r); err != nil {
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(&quot;Executing template error&quot;)
        return err
    }
    return nil
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;生成玩cis检测脚本后，会调用nstool命令在host上执行检测命令：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;nstools run -f host.sh -m  /proc/1/ns/mnt -n /proc/1/ns/net
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里因为脚本会遍历节点上所有容器，通过docker命令执行检测操作，我们并不需要在容器内部执行，所以也不一定使用nstool工具，可以直接执行shell脚本&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;到了这里已经完成了某个节点上容器的合规性检测任务，我们看看执行返回的信息：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;...
[WARN] 4.1 - Ensure that a user for the container has been created (Automated)
[WARN]      * Running as root: k8s_busybox_busybox-hujin_default_7191a3da-4c51-467a-a004-db178d79e92a_1158

[WARN] 5.1 - Ensure that, if applicable, an AppArmor Profile is enabled (Automated)
[WARN]      * No AppArmorProfile Found: k8s_busybox_busybox-hujin_default_7191a3da-4c51-467a-a004-db178d79e92a_1158
[PASS] 5.2 - Ensure that, if applicable, SELinux security options are set (Automated)
[PASS] 5.3 - Ensure that Linux kernel capabilities are restricted within containers (Automated)
[PASS] 5.4 - Ensure that privileged containers are not used (Automated)
[PASS] 5.5 - Ensure sensitive host system directories are not mounted on containers (Automated)
[PASS] 5.6 - Ensure sshd is not run within containers (Automated)
[PASS] 5.7 - Ensure privileged ports are not mapped within containers (Automated)
[PASS] 5.8 - Ensure that only needed ports are open on the container (Manual)
[PASS] 5.9 - Ensure that the host&apos;s network namespace is not shared (Automated)
...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;容器的合规性检测功能，neuvector是集成了docker-bench-security项目，将该项目的检测脚本整理成了一个container.tmpl模板&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;后面会将执行结果进行格式化并保存到数据库，代码流程就讲了&lt;/p&gt;

&lt;p&gt;这里还需要稍微提一下法规和cis的关系，我们在获取合规性检测结果的时候，handlerDockerBench - getCISReportFromCluster - _getCISReportFromCluster - 
bench2REST - GetComplianceMeta方法会将合规项添加法规对应的tag标识，方便进行过滤&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func GetComplianceMeta() ([]api.RESTBenchMeta, map[string]api.RESTBenchMeta) {
    if complianceMetas == nil || complianceMetaMap == nil {
        ...
        for _, item := range docker_image_cis_items {
            all = append(all, api.RESTBenchMeta{RESTBenchCheck: item})
        }

        for i, _ := range all {
            item := &amp;amp;all[i]
            item.Tags = make([]string, 0)
            if compliancePCI.Contains(item.TestNum) {
                item.Tags = append(item.Tags, api.ComplianceTemplatePCI)
            }
            if complianceGDPR.Contains(item.TestNum) {
                item.Tags = append(item.Tags, api.ComplianceTemplateGDPR)
            }
            if complianceHIPAA.Contains(item.TestNum) {
                item.Tags = append(item.Tags, api.ComplianceTemplateHIPAA)
            }
            if complianceNIST.Contains(item.TestNum) {
                item.Tags = append(item.Tags, api.ComplianceTemplateNIST)
            }
            ...
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;支持的法规包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;PCI&lt;/li&gt;
  &lt;li&gt;GDPR&lt;/li&gt;
  &lt;li&gt;HIPAA&lt;/li&gt;
  &lt;li&gt;NIST&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;从上面的代码分析，我们看到neuvector支持对host/container/kubernetes平台的合规性检测，同时支持一些常见的法规，可以输出非常清晰的格式化结果并提供下载；
但我们也可以发现一些不足的地方，包括不支持其他runtime、不支持国内的法规等问题&lt;/p&gt;
</description>
        <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/09/21/neuvector-bench/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/09/21/neuvector-bench/</guid>
        
        <category>neuvector</category>
        
        <category>合规性检测</category>
        
        <category>compliance</category>
        
        
      </item>
    
      <item>
        <title>Calico BGP - Bird</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;Calico支持多种网络模式，包括vxlan/ipip/bgp，其中vxlan和ipip属于overlay类型，在嵌套部署模式比较通用，但网络性能相对bgp会低一些。这主要是由于bgp模式下没有数据报文的封包和解包操作&lt;/p&gt;

&lt;p&gt;本文会将calico中bgp相关的操作流程抽离，通过demo的方式来介绍calico中bgp网络的实现&lt;/p&gt;

&lt;h2 id=&quot;架构&quot;&gt;架构&lt;/h2&gt;
&lt;p&gt;calico架构
&lt;img src=&quot;/blog/img/calico.png&quot; alt=&quot;calico_bird&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Calico作为一种常用的Kubernetes网络插件，使用BGP协议对各节点的容器网络进行路由交换。Calico中使用的软件BGP方案是Bird&lt;/p&gt;

&lt;p&gt;BIRD（BIRD Internet Routing Daemon）是一款可运行在Linux和其他类Unix系统上的路由软件，它实现了多种路由协议，比如BGP、OSPF、RIP等。&lt;/p&gt;

&lt;p&gt;BIRD会在内存中维护许多路由表，路由表根据不同的协议，通过与各种“其他事物”交换路由信息，来更新路由规则。这里说的“其他事物”可能是其他的路由表，也可能是外部的路由器，还可以是内核的某些API&lt;/p&gt;

&lt;p&gt;demo架构&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/calico_demo.png&quot; alt=&quot;calico_bird&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;实现&quot;&gt;实现&lt;/h2&gt;
&lt;h3 id=&quot;模拟calico-cni创建和配置网卡的操作&quot;&gt;模拟calico cni创建和配置网卡的操作&lt;/h3&gt;
&lt;p&gt;node1节点&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# 创建namespace和虚拟网卡
ip netns add ns1
ip link add tap1 type veth peer name nsvth netns ns1
ip link set tap1 up
ip netns exec ns1 ip link set lo up
ip netns exec ns1 ip link set nsvth up


# 配置路由和IP地址
ip netns exec ns1 ip addr add 10.244.166.128/24 dev nsvth
ip r add 10.244.166.128/32 dev tap1
ip netns exec ns1 ip r add 169.254.1.1 dev nsvth
ip netns exec ns1 ip r add default via 169.254.1.1 dev nsvth


# 配置neigh
ip link set address ee:ee:ee:ee:ee:ee dev tap1
ip netns exec ns1 ip neigh add 169.254.1.1 dev nsvth lladdr ee:ee:ee:ee:ee:ee
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;node2节点&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# 创建namespace和虚拟网卡
ip netns add ns2
ip link add tap1 type veth peer name nsvth netns ns2
ip link set tap1 up
ip netns exec ns2 ip link set lo up
ip netns exec ns2 ip link set nsvth up


# 配置路由和IP地址
ip netns exec ns2 ip addr add 10.244.104.0/24 dev nsvth
ip r add 10.244.104.0/32 dev tap1
ip netns exec ns2 ip r add 169.254.1.1 dev nsvth
ip netns exec ns2 ip r add default via 169.254.1.1 dev nsvth


# 配置neigh
ip link set address ee:ee:ee:ee:ee:ee dev tap1
ip netns exec ns2 ip neigh add 169.254.1.1 dev nsvth lladdr ee:ee:ee:ee:ee:ee
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;每个节点启动bird
启动一个容器并获取内部的bird二进制文件，镜像使用calico/node:v3.11.1&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;docker run --name calico-temp -d calico/node:v3.11.1 sleep 200
docker cp calico-temp:/usr/bin/bird /usr/bin
docker rm -f calico-temp
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建bird.cfg配置&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;function apply_communities ()
{
}

# Generated by confd
include &quot;bird_aggr.cfg&quot;;
include &quot;bird_ipam.cfg&quot;;

router id 10.20.30.30;

# Configure synchronization between routing tables and kernel.
protocol kernel {
  learn;             # Learn all alien routes from the kernel
  persist;           # Don&apos;t remove routes on bird shutdown
  scan time 2;       # Scan kernel routing table every 2 seconds
  import all;
  export filter calico_kernel_programming; # Default is export none
  graceful restart;  # Turn on graceful restart to reduce potential flaps in
                     # routes when reloading BIRD configuration.  With a full
                     # automatic mesh, there is no way to prevent BGP from
                     # flapping since multiple nodes update their BGP
                     # configuration at the same time, GR is not guaranteed to
                     # work correctly in this scenario.
  merge paths on;    # Allow export multipath routes (ECMP)
}

# Watch interface up/down events.
protocol device {
  debug { states };
  scan time 2;    # Scan interfaces every 2 seconds
}

protocol direct {
  debug { states };
  interface -&quot;cali*&quot;, -&quot;kube-ipvs*&quot;, &quot;*&quot;; # Exclude cali* and kube-ipvs* but
                                          # include everything else.  In
                                          # IPVS-mode, kube-proxy creates a
                                          # kube-ipvs0 interface. We exclude
                                          # kube-ipvs0 because this interface
                                          # gets an address for every in use
                                          # cluster IP. We use static routes
                                          # for when we legitimately want to
                                          # export cluster IPs.
}


# Template for all BGP clients
template bgp bgp_template {
  debug { states };
  description &quot;Connection to BGP peer&quot;;
  local as 64512;
  multihop;
  gateway recursive; # This should be the default, but just in case.
  import all;        # Import all routes, since we don&apos;t know what the upstream
                     # topology is and therefore have to trust the ToR/RR.
  export filter calico_export_to_bgp_peers;  # Only want to export routes for workloads.
  add paths on;
  graceful restart;  # See comment in kernel section about graceful restart.
  connect delay time 2;
  connect retry time 5;
  error wait time 5,30;
}

# ------------- Node-to-node mesh -------------





# For peer /host/node1/ip_addr_v4
# Skipping ourselves (10.20.30.30)




# For peer /host/node2/ip_addr_v4
protocol bgp Mesh_10_20_30_31 from bgp_template {
  neighbor 10.20.30.31 as 64512;
  source address 10.20.30.30;  # The local address we use for the TCP connection
  passive on; # Mesh is unidirectional, peer will connect to us.
}



# For peer /host/node3/ip_addr_v4
#protocol bgp Mesh_10_20_30_32 from bgp_template {
#  neighbor 10.20.30.32 as 64512;
#  source address 10.20.30.30;  # The local address we use for the TCP connection
#  passive on; # Mesh is unidirectional, peer will connect to us.
#}



# ------------- Global peers -------------
# No global peers configured.


# ------------- Node-specific peers -------------

# No node-specific peers configured.
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建bird_ipam.cfg配置&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# Generated by confd
filter calico_export_to_bgp_peers {
  # filter code terminates when it calls `accept;` or `reject;`, call apply_communities() before calico_aggr()
  apply_communities();
  calico_aggr();

  if ( net ~ 10.244.0.0/16 ) then {
    accept;
  }
  reject;
}


filter calico_kernel_programming {

  if ( net ~ 10.244.0.0/16 ) then {
    krt_tunnel = &quot;&quot;;
    accept;
  }

  accept;
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建bird_aggr.cfg配置&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# Generated by confd

protocol static {
   # IP blocks for this host.
   route 10.244.166.128/26 blackhole;
}


# Aggregation of routes on this host; export the block, nothing beneath it.
function calico_aggr ()
{
      # Block 10.244.166.128/26 is confirmed
      if ( net = 10.244.166.128/26 ) then { accept; }
      if ( net ~ 10.244.166.128/26 ) then { reject; }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;运行bird进程&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;bird -R -s ./bird.ctl -d -c ./bird.cfg
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此时在node1/node2节点会发现分别多了一条到对方的路由规则&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 bird]# ip r
default via 179.20.23.1 dev ens160 proto static metric 100 
10.20.30.0/24 dev ens192 proto kernel scope link src 10.20.30.30 metric 101 
10.244.104.0/26 via 10.20.30.31 dev ens192 proto bird 
10.244.166.128 dev tap1 scope link 
blackhole 10.244.166.128/26 proto bird 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
179.20.23.0/24 dev ens160 proto kernel scope link src 179.20.23.30 metric 100

[root@node2 ~]# ip r
default via 179.20.23.1 dev ens160 proto static metric 100 
10.20.30.0/24 dev ens192 proto kernel scope link src 10.20.30.31 metric 101 
10.244.104.0 dev tap1 scope link 
blackhole 10.244.104.0/26 proto bird 
10.244.104.1 dev cali6fa4fc0f157 scope link 
10.244.104.2 dev calif2ac964c43c scope link 
10.244.166.128/26 via 10.20.30.30 dev ens192 proto bird 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
179.20.23.0/24 dev ens160 proto kernel scope link src 179.20.23.31 metric 100
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;从node1的ns1中ping node2的ns1 ip&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 bird]# ip netns exec ns ip a 
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: nsvth@if9: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 2e:be:65:26:b3:0d brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 10.244.166.128/24 scope global nsvth
       valid_lft forever preferred_lft forever
    inet6 fe80::2cbe:65ff:fe26:b30d/64 scope link 
       valid_lft forever preferred_lft forever

[root@node1 bird]# ip netns exec ns ping 10.244.104.0
PING 10.244.104.0 (10.244.104.0) 56(84) bytes of data.
64 bytes from 10.244.104.0: icmp_seq=1 ttl=62 time=0.299 ms
64 bytes from 10.244.104.0: icmp_seq=2 ttl=62 time=0.356 ms
64 bytes from 10.244.104.0: icmp_seq=3 ttl=62 time=0.314 ms
^C
--- 10.244.104.0 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2033ms
rtt min/avg/max/mdev = 0.299/0.323/0.356/0.024 ms
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;bird手册：The BIRD Internet Routing Daemon Project (network.cz)&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 16 Sep 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/09/16/calico-bird/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/09/16/calico-bird/</guid>
        
        <category>calico</category>
        
        <category>bgp</category>
        
        
      </item>
    
      <item>
        <title>Neuvector源码分析之 dp引流的实现</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;在secvector中通过监听runtime事件来动态维护节点上容器基础信息，在界面支持策略配置、模式管理都对容器流量产生影响。用户从学习模式调整成保护模式时可以对容器流量进行阻断操作，那么agent
中是如何实现阻断的？
这里我们将核心流程抽离出来，通过demo的方式来介绍具体的实现细节&lt;/p&gt;

&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;
&lt;h3 id=&quot;默认形态&quot;&gt;默认形态&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_dp1.png&quot; alt=&quot;neuvector_pcap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;开始之前先看下默认情况下容器的网络形态（以calico为例）:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;容器网卡使用veth设备，一端在容器内部，一端在host上&lt;/li&gt;
  &lt;li&gt;在host上通过路由规则的方式将流量引到host上的veth设备，最终到达容器内部&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;引流形态&quot;&gt;引流形态&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_dp2.png&quot; alt=&quot;neuvector_pcap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;引流形态下流量会优先经过agent容器，根据策略规则过滤后转发到具体的容器内部。本次我们需要从host上直接ping container-ns中的网卡ip 10.10.10.88,&lt;/p&gt;

&lt;p&gt;首先创建两个network namespace&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ns1：引流实现位置&lt;/li&gt;
  &lt;li&gt;ns2：模拟普通容器的network namespace&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;命令&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;ip netns add agent-ns
ip netns add container-ns
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在host上创建三组veth&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;vex：流量入口&lt;/li&gt;
  &lt;li&gt;vin：跨agent-ns和container-ns，在agent中将流量转发到这个设备就可以到达容器内部&lt;/li&gt;
  &lt;li&gt;vbr：监控设备，也是dp工作的设备&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;命令：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# 创建veth
ip link add vex type veth peer name vex-peer
ip link add vin type veth peer name vin-peer
ip link add vbr type veth peer name vth
 
# 将vex放入agent-ns
ip link set vex netns agent-ns
ip netns exec agent-ns ip link set vex up
 
# 将vin放入agent-ns
ip link set vin netns agent-ns
ip netns exec agent-ns ip link set vin up
 
# 将vin-peer放入container-ns
ip link set vin-peer netns container-ns
 
# 在container-ns修改网卡名称为eth0
ip netns exec container-ns ip link set vin-peer name eth0
ip addr add 10.10.10.88/24 dev eth0
ip netns exec container-ns ip link set eth0 up
 
# 将vbr和vth都放入agent-ns
ip link set vbr netns agent-ns
ip link set vth netns agent-ns
ip netns exec agent-ns ip link set vbr up
ip netns exec agent-ns ip link set vth up

# 配置host上的vex-peer
ip addr add 10.10.10.66/24 dev vex-peer
ip link set vex-peer up
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;tc引流&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# 创建qdisc
tc qdisc add dev vin ingress
tc qdisc add dev vex ingress
tc qdisc add dev vbr ingress

# 创建filter
tc filter add dev vex pref 10001 parent ffff: protocol ip u32 match u8 0 1 at -14 match u16 0x1a27 0xffff at -14 match u32 0xf3873a27 0xffffffff at -12 action pedit munge offset -14 u16 set 0x4e65 munge offset -12 u32 set 0x755600b4 pipe action mirred egress mirror dev vbr
 
tc filter add dev vex pref 10002 parent ffff: protocol all u32 match u8 0 0 action mirred egress mirror dev vin
 
tc filter add dev vbr pref 5 parent ffff: protocol all u32 match u16 0x4e65 0xffff at -14 match u32 0x755600b4 0xffffffff at -12 action pedit munge offset -14 u16 set 0x1a27 munge offset -12 u32 set 0xf3873a27 pipe action mirred egress mirror dev vin
 
tc filter add dev vin pref 10002 parent ffff: protocol all u32 match u8 0 0 action mirred egress mirror dev vex
 
tc filter add dev vin pref 10001 parent ffff: protocol ip u32 match u8 0 1 at -14 match u32 0x1a27f387 0xffffffff at -8 match u16 0x3a27 0xffff at -4 action pedit munge offset -8 u32 set 0x4e657556 munge offset -4 u16 set 0x00b4 pipe action mirred egress mirror dev vbr
 
tc filter add dev vbr pref 172 parent ffff: protocol all u32 match u32 0x4e657556 0xffffffff at -8 match u16 0x00b4 0xffff at -4 action pedit munge offset -8 u32 set 0x1a27f387 munge offset -4 u16 set 0x3a27 pipe action mirred egress mirror dev vex
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此时我们从host上ping 10.10.10.88，同时在agent-ns的vex和vbr抓包会看到数据包&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这里从抓包结果会看到目标mac变了，这个是通过tc完成的&lt;/li&gt;
  &lt;li&gt;但是在vin上是抓不到包的（可以抓到广播包），因为dp没有开始工作&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;抓包结果：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;sh-4.2# tcpdump -enpli vex
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on vex, link-type EN10MB (Ethernet), capture size 262144 bytes
17:31:40.761531 06:82:9c:02:54:91 &amp;gt; 1a:27:f3:87:3a:27, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 214, length 64
17:31:41.761533 06:82:9c:02:54:91 &amp;gt; 1a:27:f3:87:3a:27, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 215, length 64
17:31:42.761516 06:82:9c:02:54:91 &amp;gt; 1a:27:f3:87:3a:27, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 216, length 64
^C
3 packets captured
3 packets received by filter
0 packets dropped by kernel
sh-4.2# tcpdump -enpli vbr
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on vbr, link-type EN10MB (Ethernet), capture size 262144 bytes
17:31:45.761528 06:82:9c:02:54:91 &amp;gt; 4e:65:75:56:00:b4, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 219, length 64
17:31:46.761515 06:82:9c:02:54:91 &amp;gt; 4e:65:75:56:00:b4, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 220, length 64
17:31:47.761531 06:82:9c:02:54:91 &amp;gt; 4e:65:75:56:00:b4, ethertype IPv4 (0x0800), length 98: 10.10.10.66 &amp;gt; 10.10.10.88: ICMP echo request, id 32052, seq 221, length 64
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;运行dp&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;ip netns exec agent-ns dp -n 1
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里需要重新编译dp，对dp做一些改造，保证可以在host运行，主要是mmap那部分逻辑&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;调用dp接口&lt;/p&gt;

&lt;p&gt;分别调用dp接口：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ctrl_add_srvc_port： 配置引流设备名称等参数&lt;/li&gt;
  &lt;li&gt;ctrl_cfg_internal_net：配置当前节点设备ip和类型&lt;/li&gt;
  &lt;li&gt;ctrl_add_mac：在引流设备中添加需要引流的mac&lt;/li&gt;
  &lt;li&gt;ctrl_cfg_mac：配置mac参数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;调用脚本&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;import socket
import json
 
DP_SERVER_PATH = &apos;/tmp/dp_listen.sock&apos;
SOCK = None

def connect_dp():
    global SOCK
    if SOCK:
        return SOCK
    socket_family = socket.AF_UNIX
    socket_type = socket.SOCK_DGRAM
 
    sock = socket.socket(socket_family, socket_type)
    sock.connect(DP_SERVER_PATH)
    SOCK = sock
    print(&quot;dp connected&quot;)
    return sock
 
 
def send_msg(msg):
    sock = connect_dp()
    sock.sendall(json.dumps(msg).encode())
 
    # data = sock.recv(1024)
    # print(&quot;receive data:&quot;, data)
    print(&apos;send msg: %s success&apos; % msg)
 
 
def add_srvc_port():
    data = {
        &quot;iface&quot;: &quot;vth&quot;,
        &quot;jumboframe&quot;: False
    }
    send_msg({&apos;ctrl_add_srvc_port&apos;: data})
 
 
def add_internal_net():
    data = {
        &quot;flag&quot;: 3,
        &quot;subnet_addr&quot;: [
            {&quot;ip&quot;: &quot;172.17.0.0&quot;, &quot;mask&quot;: &quot;255.255.0.0&quot;},
            {&quot;ip&quot;: &quot;179.20.23.0&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;},
            {&quot;ip&quot;: &quot;10.10.10.0&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;},
            {&quot;ip&quot;: &quot;172.20.166.0&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;},
            {&quot;ip&quot;: &quot;10.10.10.66&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;, &quot;iptype&quot;: &quot;devip&quot;},
            {&quot;ip&quot;: &quot;10.10.10.88&quot;, &quot;mask&quot;: &quot;255.255.255.0&quot;, &quot;iptype&quot;: &quot;devip&quot;},
 
        ]
    }
    send_msg({&apos;ctrl_cfg_internal_net&apos;: data})
 
 
def add_mac():
    data = {
        &quot;iface&quot;: &quot;vth&quot;,
        &quot;mac&quot;: &quot;1a:27:f3:87:3a:27&quot;,
        &quot;ucmac&quot;: &quot;4e:65:75:56:00:b4&quot;,
        &quot;bcmac&quot;: &quot;ff:ff:ff:00:00:b4&quot;,
        &quot;oldmac&quot;: &quot;&quot;,
        &quot;pmac&quot;: &quot;&quot;,
        &quot;pips&quot;: None,
    }
    send_msg({&apos;ctrl_add_mac&apos;: data})
 
 
def cfg_mac():
    data = {
        &quot;tap&quot;: False,
        &quot;macs&quot;: [&quot;1a:27:f3:87:3a:27&quot;],
    }
    send_msg({&apos;ctrl_cfg_mac&apos;: data})
 
add_internal_net()
add_srvc_port()
add_mac()
cfg_mac()
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;可以看到neuvector的引流方式和容器使用的cni无关&lt;/li&gt;
  &lt;li&gt;引流的准备操作实际是agent执行的，dp只是对经过vth的数据包根据策略规则进行过滤，并转发&lt;/li&gt;
  &lt;li&gt;后期可以探索这种使用方式是否可以应用到虚拟机状态下&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里只是调用dp接口，dp内部实现将在后面详细分析&lt;/p&gt;
</description>
        <pubDate>Tue, 23 Aug 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/08/23/neuvector-dp/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/08/23/neuvector-dp/</guid>
        
        <category>neuvector</category>
        
        <category>deep packet inspection</category>
        
        <category>dpi</category>
        
        <category>tc</category>
        
        
      </item>
    
      <item>
        <title>Neuvector源码分析之 网络抓包</title>
        <description>&lt;h2 id=&quot;功能介绍&quot;&gt;功能介绍&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_tcpdump.png&quot; alt=&quot;neuvector_pcap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;抓包功能是针对容器的功能，用户在界面选择某个容器点击抓包功能，可以控制抓包开始和结束，可以选择抓包时间；完成后可以下载对应的pcap格式的文件，
在本地的wireshark中直接打开进行分析。底层实际还是通过进入容器的网络namespace，执行tcpdump命令来实现。&lt;/p&gt;

&lt;p&gt;说明下：hostnetwork的容器暂不支持抓包功能&lt;/p&gt;

&lt;p&gt;API接口：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;neuvector\controller\rest\rest.go:1517

r.GET(&quot;/v1/sniffer&quot;, handlerSnifferList)
r.GET(&quot;/v1/sniffer/:id&quot;, handlerSnifferShow)
r.POST(&quot;/v1/sniffer&quot;, handlerSnifferStart)
r.PATCH(&quot;/v1/sniffer/stop/:id&quot;, handlerSnifferStop)
r.DELETE(&quot;/v1/sniffer/:id&quot;, handlerSnifferDelete)
r.GET(&quot;/v1/sniffer/:id/pcap&quot;, handlerSnifferGetFile)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;源码分析&quot;&gt;源码分析&lt;/h2&gt;

&lt;p&gt;这里我们重点看下创建，也就是handlerSnifferStart的代码流程：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func handlerSnifferStart(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {
  ...
  # 从request中获取对应的参数，这里是workloadid，也就是对应的pause容器的container id
  query := restParseQuery(r)

  # 获取容器id参数，并根据容器id获取对应的agentid
  agentID, wlID, err := getAgentWorkloadFromFilter(query.filters, acc)
  if err != nil {
      restRespNotFoundLogAccessDenied(w, login, err)
      return
  }

  // Check if we can config workload
  wl, err := cacher.GetWorkloadBrief(wlID, &quot;&quot;, acc)
  if wl == nil {
      restRespNotFoundLogAccessDenied(w, login, err)
      return
  } else if !acc.Authorize(&amp;amp;share.CLUSSnifferDummy{WorkloadDomain: wl.Domain}, nil) {
      restRespAccessDenied(w, login)
      return
  }
  ...

  args := proc.Sniffer
  req := &amp;amp;share.CLUSSnifferRequest{WorkloadID: wlID, Cmd: share.SnifferCmd_StartSniffer}
  ...

  res, err := rpc.SnifferCmd(agentID, req)
  ...
  restRespSuccess(w, r, &amp;amp;resp, acc, login, &amp;amp;proc, &quot;Start sniffer&quot;)
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;代码会从request中获取需要抓包的容器id&lt;/li&gt;
  &lt;li&gt;getAgentWorkloadFromFilter中获取容器id并查询对应的agent id&lt;/li&gt;
  &lt;li&gt;GetWorkloadBrief 获取指定容器的详细信息，并校验容器是否允许抓包&lt;/li&gt;
  &lt;li&gt;SnifferCmd 通过grpc调用对应agent的抓包接口，这里会提前配置一些抓包的参数，包括文件名称、文件大小（默认2M）、抓包时间等等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们在agent中查看对应的调用接口SnifferCmd，文件位置：neuvector\agent\service.go:830&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func (rs *RPCService) SnifferCmd(ctx context.Context, req *share.CLUSSnifferRequest) (*share.CLUSSnifferResponse, error) {
    if req.Cmd == share.SnifferCmd_StartSniffer {
        id, err := startSniffer(req)
        return &amp;amp;share.CLUSSnifferResponse{ID: id}, err
    } else if req.Cmd == share.SnifferCmd_StopSniffer {
        return &amp;amp;share.CLUSSnifferResponse{}, stopSniffer(req.ID)
    } else if req.Cmd == share.SnifferCmd_RemoveSniffer {
        return &amp;amp;share.CLUSSnifferResponse{}, removeSniffer(req.ID)
    }
    return &amp;amp;share.CLUSSnifferResponse{}, grpc.Errorf(codes.InvalidArgument, &quot;Invalid sniffer command&quot;)
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;继续查看对应的startSniffer方法：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func startSniffer(info *share.CLUSSnifferRequest) (string, error) {
    var pid int

    gInfoRLock()
    c, ok := gInfo.activeContainers[info.WorkloadID]
    ...

    proc := &amp;amp;procInfo{
        workload:   info.WorkloadID,
        fileNumber: uint(info.FileNumber),
        duration:   uint(info.DurationInSecond),
    }

    key := generateSnifferID()

    proc.fileName, proc.args = parseArgs(info, key[:share.SnifferIdAgentField])
    _, err := startSnifferProc(key, proc, pid)
    if err != nil {
        return &quot;&quot;, grpc.Errorf(codes.Internal, err.Error())
    } else {
        return key, nil
    }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里根据容器id或者内存中容器对象，这个对象实际是通过独立线程监听节点的runtime维护的信息&lt;/li&gt;
  &lt;li&gt;generateSnifferID 这个是根据agent id生成一个id作为文件名称的一部分&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;生成tcpdump命令代码&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func parseArgs(info *share.CLUSSnifferRequest, keyname string) (string, []string) {
    ...
    filename = defaultPcapDir + keyname + &quot;_&quot;
    filenumber = fmt.Sprintf(&quot;%d&quot;, info.FileNumber)
    filesize = fmt.Sprintf(&quot;%d&quot;, info.FileSizeInMB)
    ...

    tcpdumpCmd := []string{&quot;-i&quot;, &quot;any&quot;, &quot;-U&quot;, &quot;-C&quot;}
    cmdStr = append(tcpdumpCmd, filesize, &quot;-w&quot;, filename, &quot;-W&quot;, filenumber)
    ...
    return filename, cmdStr
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;parseArgs用来生成完整的文件名称，并准备具体的tcpdump命令，完整的命令类似： tcpdump -i any -U -C 2 -w /var/neuvector/pcap/0a5bdf2c_0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面就是进入容器的network namespace然后执行tcpdump命令&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;func startSnifferProc(key string, proc *procInfo, pid int) (string, error) {
    ...

    var script string
    if proc.duration &amp;gt; 0 {
        script = fmt.Sprintf(&quot;timeout %d &quot;, proc.duration)
    }
    script += &quot;tcpdump &quot; + strings.Join(proc.args, &quot; &quot;)
    log.WithFields(log.Fields{&quot;key&quot;: key, &quot;cmd&quot;: script}).Debug()

    proc.cmd = exec.Command(system.ExecNSTool, system.NSActRun, &quot;-i&quot;, &quot;-n&quot;, global.SYS.GetNetNamespacePath(pid))
    proc.cmd.SysProcAttr = &amp;amp;syscall.SysProcAttr{Setsid: true}
    proc.cmd.Stderr = &amp;amp;proc.errb
    stdin, err := proc.cmd.StdinPipe()
    if err != nil {
        e := fmt.Errorf(&quot;Open nsrun stdin error&quot;)
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(e)
        return &quot;&quot;, e
    }

    err = proc.cmd.Start()
    if err != nil {
        e := fmt.Errorf(&quot;Failed to start sniffer&quot;)
        log.WithFields(log.Fields{&quot;error&quot;: err}).Error(e)
        return &quot;&quot;, e
    }

    pgid := proc.cmd.Process.Pid
    global.SYS.AddToolProcess(pgid, pid, &quot;sniffer&quot;, script)

    io.WriteString(stdin, script)
    stdin.Close()

    ...
    return status, err
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里就是通过nstool工具进入容器network namespace, 将tcpdump命令作为stdin在namespace中执行&lt;/li&gt;
  &lt;li&gt;完整的命令类似：echo “tcpdump -i any -U -C 2 -w /var/neuvector/pcap/xxx  -W 5” | ./nstools run -i -n /proc/2271/ns/net&lt;/li&gt;
  &lt;li&gt;nstools这个工具类似nsenter，为了安全工具内部会校验调用方必须是neuvector agent服务，所以一般情况下执行这个命令是会失败的&lt;/li&gt;
  &lt;li&gt;监听tcpdump进程状态并返回状态信息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其他方法比如stop、下载抓包文件的调用路径是类似的&lt;/p&gt;

&lt;p&gt;nstools工具使用（移除父进程校验后）：
&lt;img src=&quot;/blog/img/neuvector_nstools.png&quot; alt=&quot;neuvector_pcap&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 10 Aug 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/08/10/neuvector-tcpdump/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/08/10/neuvector-tcpdump/</guid>
        
        <category>tcpdump</category>
        
        <category>neuvector</category>
        
        <category>抓包</category>
        
        
      </item>
    
      <item>
        <title>Neuvector 初探</title>
        <description>&lt;h2 id=&quot;介绍&quot;&gt;介绍&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/neuvector_arch1.png&quot; alt=&quot;neuvector_arch&quot; /&gt;&lt;/p&gt;

&lt;p&gt;NeuVector 是业界首个端到端的开源容器安全平台，唯一为容器化工作负载提供企业级零信任安全的解决方案。
NeuVector 可以提供实时深入的容器网络可视化、东西向容器网络监控、主动隔离和保护、容器主机安全以及
容器内部安全，容器管理平台无缝集成并且实现应用级容器安全的自动化，适用于各种云环境、跨云或者本地部署等容器生产环境。&lt;/p&gt;

&lt;p&gt;我们重点看neuvector的网络功能。 neuvector的网络架构中分为controller和agent端&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;controller：控制服务，提供api接口，启动并watch consul数据库&lt;/li&gt;
  &lt;li&gt;agent：节点服务，负责监控节点上容器资源，根据用户规则执行响应操作&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;控制服务在提供统一的接口服务的同时，还运行consul服务，用来提供数据持久化功能，用户在调用neuvector接口后会将数据保存到key/value数据库consul中
控制服务和agent的通信有两种方式：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;watch consul:由于每个节点上的agent服务会watch consul的数据变动（类似etcd），其实是watch指定的key；在控制服务往consul中增加新的记录后，
agent在watch到后根据对应key调用对应的方法处理。&lt;/li&gt;
  &lt;li&gt;grpc：controller在某些功能中会直接通过grpc的方式调用agent，比如容器网络抓包功能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;agent服务除了响应controller的grpc调用以外，在启动时会创建一个独立的协程来监听当前节点容器资源的变化，会获取当前节点使用的runtime来调用对应的monitor方法
runtime支持docker/containerd/crio，支持获取容器的事件包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;start&lt;/li&gt;
  &lt;li&gt;stop&lt;/li&gt;
  &lt;li&gt;delete&lt;/li&gt;
  &lt;li&gt;copyin&lt;/li&gt;
  &lt;li&gt;copyout&lt;/li&gt;
  &lt;li&gt;network create&lt;/li&gt;
  &lt;li&gt;network delete&lt;/li&gt;
  &lt;li&gt;socket error&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;dp是一个内核模块，在agent中维护，通过socket和agent进行通信，用来具体执行用户的网络规则，对容器网卡的in/out/status流量进行处理，详细的会在网络策略时讲&lt;/p&gt;

&lt;p&gt;后面会重点从源码角度对neuvector的网络抓包、进程管理、文件管理和网络策略进行分析&lt;/p&gt;

&lt;h2 id=&quot;部署&quot;&gt;部署&lt;/h2&gt;

&lt;p&gt;这里我们通过helm快速部署&lt;/p&gt;

&lt;p&gt;安装helm&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;curl -fsSL -o get_helm.sh     https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
chmod 700 get_helm.sh
./get_helm.sh
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;添加repo&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;helm repo add neuvector https://neuvector.github.io/neuvector-helm/
helm search repo neuvector/core
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;开始部署&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl create namespace neuvector
kubectl create serviceaccount neuvector -n neuvector

helm install neuvector --namespace neuvector neuvector/core  \
--set registry=harbor.archeros.cn/dev  --set tag=5.0.1 \
--set=controller.image.repository=neuvector/controller \
--set=enforcer.image.repository=neuvector/enforcer \
--set manager.image.repository=neuvector/manager \
--set cve.scanner.image.repository=neuvector/scanner \
--set cve.updater.image.repository=neuvector/updater
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;访问webui&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@node1 ~]# kubectl get svc -n neuvector  |grep webui
neuvector-service-webui           NodePort    10.68.204.173   &amp;lt;none&amp;gt;        8443:30080/TCP                  5d

浏览器访问： https://&amp;lt;管理ip&amp;gt;:30080
默认用户密码都是: admin
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;后面我们将从源码级别来逐个分析neuvector的网络功能&lt;/p&gt;

</description>
        <pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/08/09/neuvector-introduce/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/08/09/neuvector-introduce/</guid>
        
        <category>neuvector</category>
        
        
      </item>
    
      <item>
        <title>5分钟快速部署Kubernetes集群</title>
        <description>&lt;h2 id=&quot;环境信息&quot;&gt;环境信息&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;操作系统：centos7.6 4C8G&lt;/li&gt;
  &lt;li&gt;节点个数：1&lt;em&gt;master+2&lt;/em&gt;node&lt;/li&gt;
  &lt;li&gt;内核版本：3.10.0-1127.el7.x86_64&lt;/li&gt;
  &lt;li&gt;网络信息：1&lt;em&gt;管理 1&lt;/em&gt;业务&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;准备masternode&quot;&gt;准备（master+node）&lt;/h2&gt;

&lt;p&gt;每个节点修改hostname&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;hostnamectl set-hostname nodex
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;配置/etc/hosts&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cat /etc/hosts
179.20.23.30 node1
179.20.23.31 node2
179.20.23.32 node3
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;配置免密登录&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;ssh-keygen
ssh-copy-id node1
ssh-copy-id node2
ssh-copy-id node3
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;同步hosts文件&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;scp /etc/hosts node2:/etc
scp /etc/hosts node3:/etc
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;配置内核参数&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;vi /etc/sysctl.conf
net.ipv4.conf.all.forwarding=1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-arptables = 1
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.send_redirects = 0

sysctl -p
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关闭防火墙&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;systemctl stop firewalld
systemctl disable firewalld
setenforce 0

vi /etc/selinux/config
SELINUX=disabled
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关闭swap&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;swapoff -a
vi /etc/sysctl.d/k8s.conf 添加下面一行：
vm.swappiness=0
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装docker-ce&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;yum install -y yum-utils device-mapper-persistent-data lvm2 wget
wget -O /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo
sudo sed -i &apos;s+download.docker.com+mirrors.tuna.tsinghua.edu.cn/docker-ce+&apos; /etc/yum.repos.d/docker-ce.repo
yum install docker-ce -y
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装kubectl kubeadm kubelet(版本自定义)&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
EOF

yum install kubelet-1.18.15 kubeadm-1.18.15 kubectl-1.18.15 -y
systemctl enable kubelet &amp;amp;&amp;amp; sudo systemctl start kubelet
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;预下载镜像（master节点即可）&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubeadm config images list --kubernetes-version=v1.18.15

cat images.sh 
#!/bin/bash
images=(kube-proxy:v1.18.15 kube-scheduler:v1.18.15 kube-controller-manager:v1.18.15 kube-apiserver:v1.18.15 etcd:3.4.3-0 pause:3.2 coredns:1.6.7)
for imageName in ${images[@]} ; do
docker pull harbor.archeros.cn/huayun-kubernetes/amd64/$imageName
docker tag harbor.archeros.cn/huayun-kubernetes/amd64/$imageName k8s.gcr.io/$imageName
docker rmi harbor.archeros.cn/huayun-kubernetes/amd64/$imageName
done
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;部署master节点&quot;&gt;部署master节点&lt;/h2&gt;

&lt;p&gt;创建配置文件&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;vi kubeadm.yaml 
apiVersion: kubeadm.k8s.io/v1beta2
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: &quot;179.20.23.33&quot;
  bindPort: 6443
nodeRegistration:
  taints:
  - effect: PreferNoSchedule
    key: node-role.kubernetes.io/master
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.18.15
networking:
  podSubnet: 10.244.0.0/16
  serviceSubnet: 10.96.0.0/16
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;配置k8s集群master节点的管理ip和端口
配置k8s集群版本
设置pod/service cidr&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;开始部署&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubeadm init --config=kubeadm.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;post deploy配置&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;允许master节点作为node节点使用&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl taint node node1 node-role.kubernetes.io/master-
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;部署node节点&quot;&gt;部署node节点&lt;/h2&gt;

&lt;p&gt;在master节点获取token&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubeadm token list |grep &quot;system:bootstrappers:kubeadm:default-node-token&quot; |awk &apos;{print $1}&apos;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;join集群&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubeadm join --token &amp;lt;mastertoken&amp;gt; --discovery-token-unsafe-skip-ca-verification &amp;lt;k8s_master_ip&amp;gt;:6443
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;部署cni&quot;&gt;部署cni&lt;/h2&gt;

&lt;p&gt;此时k8s集群实际已经可以运行，只是无法创建pod资源，这里我们来部署cni组件，以calico为例&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;curl https://docs.projectcalico.org/v3.18/manifests/calico.yaml -O
kubectl apply -f calico.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里如果需要管理和业务分离部署，可以修改配置文件指定业务网卡&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;我们这里的大部分准备操作，可以通过制作模板的方式提高效率，在实际的开发验证或者学习中可以极大节省我们的环境部署时间&lt;/p&gt;
</description>
        <pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/08/09/k8s-deploy/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/08/09/k8s-deploy/</guid>
        
        <category>kubernetes</category>
        
        <category>部署</category>
        
        <category>kubeadm</category>
        
        
      </item>
    
      <item>
        <title>Istio Bookinfo</title>
        <description>&lt;h2 id=&quot;架构图&quot;&gt;架构图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://istio.io/latest/zh/docs/examples/bookinfo/noistio.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在k8s中通过deployment安装一些微服务并通过service暴露出来，包括&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;productpage: python编写，服务主界面，或者叫index页面，页面中会访问其他微服务&lt;/li&gt;
  &lt;li&gt;reviews： java编写，书籍评价微服务&lt;/li&gt;
  &lt;li&gt;details： ruby编写，书籍详情信息微服务&lt;/li&gt;
  &lt;li&gt;ratings： nodejs编写，数据推荐指数微服务，rating service的后端pod有三个，分别对应三个version&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;部署&quot;&gt;部署&lt;/h2&gt;

&lt;h3 id=&quot;部署原始应用deploymentservice等&quot;&gt;部署原始应用（deployment/service等）&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看安装结果&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@controller01 ~]# kubectl get svc
NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
details       ClusterIP   10.96.192.251   &amp;lt;none&amp;gt;        9080/TCP   87s
kubernetes    ClusterIP   10.96.0.1       &amp;lt;none&amp;gt;        443/TCP    119d
productpage   ClusterIP   10.96.93.53     &amp;lt;none&amp;gt;        9080/TCP   86s
ratings       ClusterIP   10.96.137.195   &amp;lt;none&amp;gt;        9080/TCP   87s
reviews       ClusterIP   10.96.146.191   &amp;lt;none&amp;gt;        9080/TCP   86s

[root@controller01 ~]# kubectl get pods -owide
NAME                              READY   STATUS    RESTARTS   AGE   IP               NODE           NOMINATED NODE   READINESS GATES
details-v1-66b6955995-n4rwz       2/2     Running   0          92s   10.244.114.172   controller01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
productpage-v1-5d9b4c9849-mjrcf   2/2     Running   0          91s   10.244.114.141   controller01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ratings-v1-fd78f799f-ckf66        2/2     Running   0          92s   10.244.114.187   controller01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
reviews-v1-6549ddccc5-gtstf       2/2     Running   0          92s   10.244.114.175   controller01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
reviews-v2-76c4865449-sz5dr       2/2     Running   0          92s   10.244.114.188   controller01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
reviews-v3-6b554c875-jdpn6        2/2     Running   0          92s   10.244.114.143   controller01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;此时服务可以通过k8s原生的service访问成功且rating-service有三个后端pod所以平均切换&quot;&gt;此时服务可以通过k8s原生的service访问成功，且rating service有三个后端pod，所以平均切换&lt;/h3&gt;
&lt;p&gt;修改productpage service类型，改成nodeport（之前是clusterip）&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl edit svc productpage
apiVersion: v1
kind: Service
metadata:
  labels:
    app: productpage
    service: productpage
  name: productpage
spec:
  clusterIP: 112.96.53.21
  clusterIPs:
  - 112.96.53.21
  ports:
  - name: http
    nodePort: 30607
    port: 9080
    protocol: TCP
    targetPort: 9080
  selector:
    app: productpage
  type: NodePort
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过http://[管理IP]:[svc-nodeport]/productpage来访问productpage服务&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;上面演示的是原生k8s的service功能，通过管理IP和nodeport的方式访问productpage服务，下面我们将通过istio的方式来访问微服务&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;启用istio-注入功能&quot;&gt;启用istio 注入功能&lt;/h3&gt;

&lt;p&gt;允许default namespace自动注入istio sidecar&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl label namespace default istio-injection=enabled
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;重新部署所有微服务，注入istio sidecar&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl delete -f samples/bookinfo/platform/kube/bookinfo.yaml
kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建gateway&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里创建gateway，保证流量可以进入ingressgateway，并进行转发&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@controller01 ~]# kubectl apply -f istio-1.11.2/samples/bookinfo/networking/bookinfo-gateway.yaml 
gateway.networking.istio.io/bookinfo-gateway created
virtualservice.networking.istio.io/bookinfo created


[root@controller01 ~]# kubectl get gateway
NAME               AGE
bookinfo-gateway   109s
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;获取Istio Ingress Gateway的外部端口：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意这里的31460 nodeport，需要通过这个访问bookinfo入口服务&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@controller01 ~]# kubectl get svc -n istio-system |grep gateway
istio-egressgateway    ClusterIP      10.96.188.75    &amp;lt;none&amp;gt;        80/TCP,443/TCP                                                               4m8s
istio-ingressgateway   LoadBalancer   10.96.156.24    &amp;lt;pending&amp;gt;     15021:31717/TCP,80:31460/TCP,443:30052/TCP,31400:32767/TCP,15443:30069/TCP   4m8s
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建destination rules, 配置路由访问规则：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f samples/bookinfo/networking/destination-rule-all.yaml

[root@nested-istio-node1 networking]# kubectl get destinationrule 
NAME          HOST          AGE
details       details       15h
productpage   productpage   15h
ratings       ratings       15h
reviews       reviews       15h
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;此时bookinfo的virtualservice只是将流量转发到productpage这个destination v1上，其他destination只是创建，未被引用&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;此时访问页面，页面中review微服务还是会三个版本平均切换的&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;智能路由&quot;&gt;智能路由&lt;/h2&gt;

&lt;h3 id=&quot;根据版本路由&quot;&gt;根据版本路由&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f samples/bookinfo/networking/virtual-service-all-v1.yaml

cat samples/bookinfo/networking/virtual-service-all-v1.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: productpage
spec:
  hosts:
  - productpage
  http:
  - route:
    - destination:
        host: productpage
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
  - reviews
  http:
  - route:
    - destination:
        host: reviews
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ratings
spec:
  hosts:
  - ratings
  http:
  - route:
    - destination:
        host: ratings
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: details
spec:
  hosts:
  - details
  http:
  - route:
    - destination:
        host: details
        subset: v1
---
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里创建了几个service，并将流量都转发到各自的v1 destinationrule上（demo中只有rating有多版本），访问服务，发现不管怎么刷页面，都看不到星星，因为v1版本没星星&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;根据用户路由&quot;&gt;根据用户路由&lt;/h3&gt;

&lt;p&gt;在vs中定义转发规则，如果发现header中有个jason用户信息，转发到v2，否则转发到v1后端pod&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl delete -f samples/bookinfo/networking/virtual-service-all-v1.yaml
kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-test-v2.yaml

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
    - reviews
  http:
  - match:
    - headers:
        end-user:
          exact: jason
    route:
    - destination:
        host: reviews
        subset: v2
  - route:
    - destination:
        host: reviews
        subset: v1
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;再次访问，用jason用户登录就能看到黑星星，而其它方式看到的页面都是无星星&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;故障注入&quot;&gt;故障注入&lt;/h3&gt;

&lt;p&gt;注入错误让jason用户有个7s的延迟:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-test-delay.yaml

cat samples/bookinfo/networking/virtual-service-reviews-test-delay.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
  - reviews
  http:
  - match:
    - headers:
        end-user:
          exact: jason
    fault:
      delay:
        percentage:
          value: 100.0
        fixedDelay: 7s
    route:
    - destination:
        host: reviews
        subset: v2
  - route:
    - destination:
        host: reviews
        subset: v3
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;使用jason用户访问页面会有7s延迟，其他用户则转发到v3版本的reviews&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;链路切换&quot;&gt;链路切换&lt;/h3&gt;
&lt;p&gt;把100%流量切到v1&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f samples/bookinfo/networking/virtual-service-all-v1.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;页面不论刷几遍，都没有星星&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;v1 v3各50%流量&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-50-v3.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;刷新页面, 一会有红星，一会没星，50%的概率&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;把100%流量切到v3&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-v3.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;刷新页面，我们看到的都是红心了&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        <pubDate>Fri, 15 Apr 2022 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2022/04/15/istio-bookinfo/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2022/04/15/istio-bookinfo/</guid>
        
        <category>istio</category>
        
        <category>bookinfo</category>
        
        
      </item>
    
      <item>
        <title>Istio集成测试</title>
        <description>&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;istio集成测试使用go test，会自动读取源码目录下面名为 *_test.go 的文件，生成并运行测试用的可执行文件。istio集成测试脚本中根据case定义一般会先部署istio集群，再部署对应的echo instance，最后执行具体的case。&lt;/p&gt;

&lt;h2 id=&quot;准备&quot;&gt;准备&lt;/h2&gt;
&lt;p&gt;修改master节点apiserver参数
这里需要支持第三方token(third-party-token)，默认k8s使用first-party-jwt&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cat /etc/kubernetes/manifests/kube-apiserver.yaml
...
- --service-account-signing-key-file=/etc/kubernetes/ssl/sa.key
- --service-account-key-file=/etc/kubernetes/ssl/sa.pub
- --service-account-issuer=api
- --service-account-api-audiences=api,vault,factors
...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装metallb组件&lt;/p&gt;

&lt;p&gt;由于istio集成测试时会部署loadbalancer类型的service，在独立的k8s环境中没有上有的LB提供服务，因此需要引入metallb组件&lt;/p&gt;

&lt;p&gt;metallb分为l2模式和bgp模式，这里我们使用l2模式&lt;/p&gt;

&lt;p&gt;开启strictARP&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;# see what changes would be made, returns nonzero returncode if different
kubectl get configmap kube-proxy -n kube-system -o yaml | \
sed -e &quot;s/strictARP: false/strictARP: true/&quot; | \
kubectl diff -f - -n kube-system

# actually apply the changes, returns nonzero returncode on errors only
kubectl get configmap kube-proxy -n kube-system -o yaml | \
sed -e &quot;s/strictARP: false/strictARP: true/&quot; | \
kubectl apply -f - -n kube-system
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建metallb-system namespace&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/namespace.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;下载configmap，并修改address参数，预留一段k8s管理网络IP段给Loadbalancer类型的service使用&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;wget https://github.com/metallb/metallb/blob/v0.11.0/manifests/example-layer2-config.yaml
vi example-layer2-config.yaml
mv example-layer2-config.yaml l2-config.yaml
kubectl apply -f l2-config.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装metallb speaker和controller等资源&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/metallb.yaml
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;提前下载的镜像&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;gcr.io/istio-testing/app:1.12-dev
gcr.io/istio-testing/operator:1.12-dev
gcr.io/istio-testing/proxyv2:1.12-dev
gcr.io/istio-testing/pilot:1.12-dev
gcr.io/istio-testing/app_sidecar_ubuntu_bionic:1.12-dev
gcr.io/istio-testing/fake-gce-metadata:1.0
gcr.io/istio-testing/ext-authz:0.7

jimmidyson/configmap-reload:v0.5.0
envoyproxy/ratelimit:6f5de117
openzipkin/zipkin-slim:2.23.0
gcr.io/istio-release/pilot:1.6.11
gcr.io/istio-release/pilot:1.7.6
gcr.io/istio-release/pilot:1.8.6
gcr.io/istio-release/pilot:1.9.5
gcr.io/istio-release/pilot:1.10.0
gcr.io/istio-release/proxyv2:1.11.3
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;下载istio源码，当前测试的版本是release-1.12&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;git clone https://github.com/istio/istio.git -b release-1.12
cd istio
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;集成测试&quot;&gt;集成测试&lt;/h2&gt;
&lt;p&gt;go test命令行参数介绍&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;-p 允许并行执行通过调用 t.Parallel 的测试函数的最大次数&lt;/li&gt;
  &lt;li&gt;-vet 在 “go test “期间对 “go vet ” 的调用，以使用逗号分隔的vet检查列表, off表示不执行go vet&lt;/li&gt;
  &lt;li&gt;-v 显示测试的详细命令&lt;/li&gt;
  &lt;li&gt;-count 运行每个测试和基准测试的次数（默认 1）&lt;/li&gt;
  &lt;li&gt;-timeout 执行二进制文件超时时间，超过会报panic&lt;/li&gt;
  &lt;li&gt;-tags&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;telemetry集成测试&quot;&gt;telemetry集成测试&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;go test -p 1 -vet=off -v -count=1 -tags=integ ./tests/integration/telemetry/... -timeout 30m \
--istio.test.istio.istiodlessRemotes --istio.test.ci --istio.test.work_dir=/logs/artifacts \
--istio.test.tag=1.12-dev --istio.test.pullpolicy=IfNotPresent
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;telemetry失败case:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;TestVMTelemetry: 依赖谷歌的GCP项目 &lt;a href=&quot;https://github.com/istio/istio/issues/35923&quot;&gt;https://github.com/istio/istio/issues/35923&lt;/a&gt;，需要临时删除这个case： git rm -r tests/integration/telemetry/stackdriver/vm/&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;security集成测试&quot;&gt;security集成测试&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;go test -p 1 -vet=off -v -count=1 -tags=integ ./tests/integration/security/... -timeout 30m \
--istio.test.work_dir=/logs/artifacts --istio.test.tag=1.12-dev \
--istio.test.pullpolicy=IfNotPresent --istio.test.skip TestAuthorization_JWT \
--istio.test.skip TestAuthorization_EgressGateway \
--istio.test.skip TestRequestAuthentication \
--istio.test.skip TestIngressRequestAuthentication
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;security失败case:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;TestAuthorization_JWT:&lt;/li&gt;
  &lt;li&gt;TestAuthorization_EgressGateway:&lt;/li&gt;
  &lt;li&gt;TestRequestAuthentication:&lt;/li&gt;
  &lt;li&gt;TestIngressRequestAuthentication:&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pilot集成测试&quot;&gt;pilot集成测试&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;go test -p 1 -vet=off -v -count=1 -tags=integ ./tests/integration/pilot/... -timeout 30m \
--istio.test.work_dir=/logs/artifacts --istio.test.tag=1.12-dev \
--istio.test.pullpolicy=IfNotPresent --istio.test.skip TestCustomGateway \
--istio.test.skip TestTproxy \
--istio.test.skip TestTraffic
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;pilot失败case&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;TestCustomGateway&lt;/li&gt;
  &lt;li&gt;TestTproxy&lt;/li&gt;
  &lt;li&gt;TestTraffic&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;helm集成测试&quot;&gt;helm集成测试&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;go test -p 1 -vet=off -v -count=1 -tags=integ ./tests/integration/helm/... -timeout 30m \
--istio.test.work_dir=/logs/artifacts --istio.test.tag=1.12-dev \
--istio.test.pullpolicy=IfNotPresent
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;operator集成测试&quot;&gt;operator集成测试&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;go test -p 1 -vet=off -v -count=1 -tags=integ ./tests/integration/operator/... -timeout 30m \
--istio.test.work_dir=/logs/artifacts --istio.test.tag=1.12-dev \
--istio.test.pullpolicy=IfNotPresent
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;组件&lt;/th&gt;
      &lt;th&gt;case数量(total:nopass)&lt;/th&gt;
      &lt;th&gt;执行时间（m）&lt;/th&gt;
      &lt;th&gt;备注&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;helm&lt;/td&gt;
      &lt;td&gt;7:7&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;operator&lt;/td&gt;
      &lt;td&gt;3:0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pilot&lt;/td&gt;
      &lt;td&gt;60:3&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security&lt;/td&gt;
      &lt;td&gt;48:4&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;都和jwt相关&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;telemetry&lt;/td&gt;
      &lt;td&gt;32:1&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;依赖谷歌的GCP项目，无法执行通过&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;总计&lt;/td&gt;
      &lt;td&gt;150：15&lt;/td&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;注意：执行完成后需要执行清理操作，防止残留&lt;/p&gt;

&lt;h2 id=&quot;清理脚本&quot;&gt;清理脚本&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;for ns in default ingress-nginx metallb-system;
do
kubectl delete cm istio-ca-root-cert -n $ns;
done

for ns in 1- service- se- app- istio- gce-metadata default- stable- external- echo- test-ns canary;
do
for i in `kubectl get ns |grep $ns |awk &apos;{print $1}&apos;`;do kubectl delete all --all -n $i --force &amp;amp;&amp;amp; kubectl delete cm -n $i istio-ca-root-cert &amp;amp; done;
done

for ns in 1- service- se- app- istio- gce-metadata default- stable- external- echo- test-ns canary;
do
for i in `kubectl get ns |grep $ns |awk &apos;{print $1}&apos;`;do kubectl delete namespace $i --force;done;
done
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;集成测试官方文档：https://github.com/istio/istio/tree/master/tests/integration&lt;/li&gt;
  &lt;li&gt;metallb部署：https://metallb.universe.tf/installation/&lt;/li&gt;
  &lt;li&gt;jwt配置：https://imroc.cc/istio/troubleshooting/istio-token-setup-failed-for-volume-istio-token/&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2021/12/24/istio-integration-test/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2021/12/24/istio-integration-test/</guid>
        
        <category>istio</category>
        
        <category>integration-test</category>
        
        
      </item>
    
      <item>
        <title>DockerCE20.10版本打包流程</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;Docker-CE分支在v20.10版本之后将会停止更新，原先的docker-ce将拆分成docker/cli和moby/moby两个项目，其中docker/cli就是docker的客户端，也就是我们常用的docker命令行工具所属的项目；moby/moby项目就是原先docker engine的部分&lt;/p&gt;

&lt;h2 id=&quot;环境准备&quot;&gt;环境准备&lt;/h2&gt;

&lt;p&gt;在编译docker源码之前，需要安装docker-ce&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;yum install docker-ce -y
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;获取项目代码&quot;&gt;获取项目代码&lt;/h2&gt;

&lt;p&gt;根据需求获取最新的docker/cli和moby/moby项目代码和切换版本&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cd /root
git clone https://github.com/docker/cli.git
cd cli &amp;amp;&amp;amp; git checkout v20.10.7
git clone https://github.com/moby/moby.git
cd moby &amp;amp;&amp;amp; git checkout v20.10.7
git clone https://github.com/docker/scan-cli-plugin.git
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;根据实际情况适当翻墙或者使用国内加速优化方式&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;可选编译二进制文件&quot;&gt;【可选】编译二进制文件&lt;/h3&gt;

&lt;p&gt;切换分支&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cd cli
git chekout 20.10

cd moby
git checkout 20.10
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;编译cli&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;make -f docker.Makefile binary
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;在build目录下是编译好的文件&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;编译moby&lt;/p&gt;

&lt;p&gt;在git clone之前添加代理&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;hack/dockerfile/install/containerd.installer
hack/dockerfile/install/dockercli.installer
hack/dockerfile/install/proxy.installer
hack/dockerfile/install/rootlesskit.installer
hack/dockerfile/install/runc.installer
hack/dockerfile/install/shfmt.installer
hack/dockerfile/install/tini.installer
hack/dockerfile/install/tomlv.installer
hack/dockerfile/install/vndr.installe
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;编译&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;make binary
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;在bundles/binary-daemon/目录下是编译好的文件&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;验证，停止节点上的docker&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;systemctl stop docker.service
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将之前编译的docker和dockerd替换&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;mv /usr/bin/docker /home/backup
cp cli/build/docker /usr/bin/docker
chmod +x /usr/bin/docker

mv /usr/bin/dockerd /home/backup
cp moby/bundles/binary-daemon/dockerd /usr/bin/dockerd
chmod +x /usr/bin/dockerd
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;启动docker&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;systemctl start docker.service

docker version
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;启动测试容器&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;docker pull alpine
docker run alpine echo &quot;hello from alpine&quot;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;编译rpm包&quot;&gt;编译RPM包&lt;/h3&gt;

&lt;p&gt;获取打包项目代码&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;git clone https://github.com/docker/docker-ce-packaging.git
cd docker-ce-packaging
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;【可选】根据需求切换分支&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;git checkout v20.10.0-beta1
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意：这里的版本建议和docker/cli等项目逇版本保持一致&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;创建代码目录&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;mkdir -p src/github.com/docker/
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将上面git clone下来的代码放到对应目录&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cp -r /root/cli src/github.com/docker/
cp -r /root/moby src/github.com/docker/docker # 这里一定要改成docker名称，否则会出现一系列错误
cp -r /root/scan-cli-plugin src/github.com/docker/
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在对应项目里根据需求切换分支或者修改代码&lt;/p&gt;

&lt;p&gt;【可选】设置docker项目https代理&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;vi ./src/github.com/docker/docker/hack/dockerfile/install/runc.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/containerd.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/dockercli.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/proxy.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/rootlesskit.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/runc.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/shfmt.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/tini.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/tomlv.installer
vi ./src/github.com/docker/docker/hack/dockerfile/install/vndr.installer
vi ./src/github.com/docker/docker/vendor/github.com/docker/libnetwork/network.go

vi rpm/SPECS/docker-ce-cli.spec
...
%build
export https_proxy=http://10.51.30.48:1080
...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;开始编译(根据需求选择对应的版本和系统)&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cd rpm
VERSION=20.10.7 make centos-7
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;生成的文件在&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[root@localhost rpm]# pwd
/root/docker-ce-packaging/rpm
[root@localhost rpm]# ll rpmbuild/centos-7/RPMS/x86_64
total 65428
-rw-r--r-- 1 root root 23793492 Oct 20 18:47 docker-ce-20.10.7.chinac-3.el7.x86_64.rpm
-rw-r--r-- 1 root root 31183248 Oct 20 18:51 docker-ce-cli-20.10.7.chinac-3.el7.x86_64.rpm
-rw-r--r-- 1 root root  8424840 Oct 20 18:52 docker-ce-rootless-extras-20.10.7.chinac-3.el7.x86_64.rpm
-rw-r--r-- 1 root root  3591600 Oct 20 18:53 docker-scan-plugin-0.8.0-3.el7.x86_64.rpm  
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;troubleshooting&quot;&gt;Troubleshooting&lt;/h2&gt;

&lt;h3 id=&quot;clicomposeschemaschemago42-cannot-find-package-embed-in-any-of&quot;&gt;cli/compose/schema/schema.go:4:2: cannot find package “embed” in any of:&lt;/h3&gt;
&lt;p&gt;低版本的golang会有这个问题，需要修改编译时指定的golang版本&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;vi common.tk
...
GO_VERSION=1.16.9 &amp;gt; 注意：不是升级本地的golang，是容器中的，所以只需要改下这个文件
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://openpower.ic.unicamp.br/post/building-docker-for-power/&lt;/li&gt;
  &lt;li&gt;https://www.fatalerrors.org/a/pull-and-compile-docker-ce.html&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 21 Oct 2021 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2021/10/21/docker-package/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2021/10/21/docker-package/</guid>
        
        <category>docker</category>
        
        <category>docker-ce</category>
        
        
      </item>
    
      <item>
        <title>Tungstenfabric CNI源码 -- NetworkPolicy</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;tungstenfabric cni通过watch kubernetes apiserver中指定的资源，并在sdn中创建对应的网络设备来实现对应功能。本文重点介绍cni针对networkpolicy的处理，根据源码逐步分析。&lt;/p&gt;

&lt;h2 id=&quot;架构流程图&quot;&gt;架构&amp;amp;流程图&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://hujin.dynv6.net:50008/index.php?user/publicLink&amp;amp;fid=826f91FDc9_ivLXP-2TgqvVlTnWAWUUm5hE6qr_ef-KVP_3RWxuNClqp0L86chmPdHcV9GGK4fY5BLr3ualYY8IkFXQI_OHUoI2btmUla-PRxN494bUH8DsY7FAajC-fCOHFQHOBwYVnU8BSRZOxaVGZsp2WPTQ&amp;amp;file_name=/arch_network_policy.png&quot; alt=&quot;arch_network_policy&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;源码解析&quot;&gt;源码解析&lt;/h2&gt;

&lt;p&gt;在process方法中会处理networkpolicy的创建、更新和删除。这里我们先看下创建和更新&lt;/p&gt;

&lt;p&gt;创建和更新方法中有两个步骤：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;_add_labels： 获取networkpolicy中selector相关的lable，并在sdn中创建或更新对应的tag资源&lt;/li&gt;
  &lt;li&gt;vnc_network_policy_add：在sdn中创建对应的aps（application policy set）policy资源&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在_add_labels中：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;def _get_np_pod_selector(self, spec):
    pod_selector = spec.get(&apos;podSelector&apos;)
    if not pod_selector or &apos;matchLabels&apos; not in pod_selector:
        labels = {}
    else:
        labels = pod_selector.get(&apos;matchLabels&apos;)
    return labels

def _add_labels(self, event, namespace, np_uuid):
    all_labels = []
    spec = event[&apos;object&apos;][&apos;spec&apos;]
    if spec:
        # Get pod selector labels.
        all_labels.append(self._get_np_pod_selector(spec))

        # Get ingress podSelector labels
        ingress_spec_list = spec.get(&quot;ingress&quot;, [])
        for ingress_spec in ingress_spec_list:
            from_rules = ingress_spec.get(&apos;from&apos;, [])
            for from_rule in from_rules:
                if &apos;namespaceSelector&apos; in from_rule:
                    all_labels.append(
                        from_rule.get(&apos;namespaceSelector&apos;).get(
                            &apos;matchLabels&apos;, {}))
                if &apos;podSelector&apos; in from_rule:
                    all_labels.append(
                        from_rule.get(&apos;podSelector&apos;).get(&apos;matchLabels&apos;, {}))

        # Call label mgmt API.
        self._labels.process(np_uuid, list_curr_labels_dict=all_labels)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里可以看到程序从networkpolicy的spec中获取了podSelector，从ingress中获取了namespaceSelector和podSelector对应的labels，最终在labels资源的process方法中进行处理&lt;/p&gt;

&lt;p&gt;我们在label_cache.py的process中可以看到：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;def process(self, obj_uuid, curr_labels={}, list_curr_labels_dict=[]):
    ...
    all_labels = set()

    if list_curr_labels_dict:
        for labels_dict in list_curr_labels_dict:
            for key, value in labels_dict.items():
                key, value = self._validate_key_value(key, value)
                # Construct the label key.
                label_key = self._update_label_to_guid_cache(key, value, obj_uuid)
                # Construct a set of all input label keys.
                all_labels.add(label_key)
    ... 针对从networkpolicy中传入的labels，在这里做了validate，然后做了_update_label_to_guid_cache：

def _update_label_to_guid_cache(self, key, value, obj_uuid):

    # Construct the label key.
    label_key = self.get_key(key, value)

    # If an entry exists for this label, add guid to the existing entry.
    # If not, create one.
    ltg_cache = XLabelCache.k8s_label_to_guid_cache[self.resource_type]
    if label_key in ltg_cache:
        ltg_cache[label_key].add(obj_uuid)
    else:
        ltg_cache[label_key] = {obj_uuid}
        XLabelCache.label_add_cb(key, value)

    return label_key
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里将key和value先转换成sdn的tag格式，再调用XLabelCache.label_add_cb方法处理，这里的label_add_cb方法处理实际是一个callback方法，是在初始化时传入的，具体看下：&lt;/p&gt;

&lt;p&gt;vnc_kubernetes.py中初始化VncKubernetes时：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;def __init_():
    ...
    # Register label add and delete callbacks with label management entity.
    label_cache.XLabelCache.register_label_add_callback(VncKubernetes.create_tags)
    label_cache.XLabelCache.register_label_delete_callback(VncKubernetes.delete_tags)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;label_cache.py中&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;@classmethod
def register_label_add_callback(cls, cb_func):
    cls.label_add_cb = cb_func
    
@classmethod
def register_label_delete_callback(cls, cb_func):
    cls.label_delete_cb = cb_func
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里在初始化VncKubernetes是，调用label_cache.py中的register_label_add_callback，注册了两个方法，分别是创建和删除tag&lt;/p&gt;

&lt;p&gt;我们在vnc_tag.py最终找到实际调用vnc创建和删除tag的方法：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;def create(self, type, value):
    tag_name = &quot;=&quot;.join([type, value])
    tag = Tag(name=tag_name,
              parent_obj=self.proj_obj,
              tag_type_name=type,
              tag_value=value)
    try:
        TagKM.add_annotations(self, tag, &quot;default&quot;, tag_name)
        self._vnc_lib.tag_create(tag)
    except RefsExistError:
        # Tags cannot be updated.
        pass

    try:
        tag_obj = self._vnc_lib.tag_read(fq_name=tag.get_fq_name())
    except NoIdError as e:
        self._logger.error(
            &quot;Unable to create tag [%s]. Error [%s]&quot; %
            (tag.get_fq_name(), str(e)))
        return
    # Cache the object in local db.
    TagKM.locate(tag_obj.uuid)

def delete(self, type, value):
    tag_uuid = TagKM.get_fq_name_to_uuid(
        self._construct_tag_fq_name(type, value))
    try:
        self._vnc_lib.tag_delete(id=tag_uuid)

        TagKM.delete(tag_uuid)
        self._logger.debug(&quot;Tag (%s) deleted successfully.&quot;
                           % (self._construct_tag_fq_name(type, value)))
    except RefsExistError:
        self._logger.debug(&quot;Tag (%s) deletion failed. Tag is in use.&quot;
                           % (self._construct_tag_fq_name(type, value)))
    except NoIdError:
        self._logger.debug(&quot;Tag delete failed. Tag [%s] not found.&quot;
                           % (self._construct_tag_fq_name(type, value)))

    return
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里我们可以得到一个结论，当存在多个k8s集群的时候，实际tag是共享的。也就是说当多个k8s集群有同名的labels时，实际在sdn中是复用的&lt;/p&gt;

&lt;p&gt;看完labels的操作后，我们看下networkpolicy在sdn中的处理吧，在看之前我们需要知道一个前提条件：&lt;/p&gt;

&lt;p&gt;vnc_kubernetes.py中：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;def _provision_cluster(self):
    ...
    # Create application policy set for the cluster project.
    VncSecurityPolicy.create_application_policy_set(
        vnc_kube_config.application_policy_set_name(), namespace=proj_obj.name)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们发现kube-manager实际会为每个接入tungstenfabric的k8s集群创建一个aps，也就是一个防火墙。然后初始化三个policy，分别是：denyall/allowall/ingress，然后创建一些初始化规则，这里不展开讲了。&lt;/p&gt;

&lt;p&gt;了解这个前提后，我们看下面的代码就容易理解了：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;def vnc_network_policy_add(self, event, namespace, name, uid):
    spec = event[&apos;object&apos;][&apos;spec&apos;]
    if not spec:
        self._logger.error(
            &quot;%s - %s:%s Spec Not Found&quot;
            % (self._name, name, uid))
        return

    fw_policy_uuid = VncSecurityPolicy.create_firewall_policy(name, namespace,
                                                              spec, k8s_uuid=uid)
    VncSecurityPolicy.add_firewall_policy(fw_policy_uuid)

    # Update kube config db entry for the network policy.
    np = NetworkPolicyKM.find_by_name_or_uuid(uid)
    if np:
        fw_policy_obj = self._vnc_lib.firewall_policy_read(id=fw_policy_uuid)
        np.set_vnc_fq_name(&quot;:&quot;.join(fw_policy_obj.get_fq_name()))
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;实际k8s中的networkpolicy对应sdn的资源就是aps policy资源。上面可以看到会在create_firewall_policy中创建一个policy，然后将policy绑定到aps中，也就是add_firewall_policy的动作。这里我们重点看下create_firewall_policy：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;@classmethod
def create_firewall_policy(cls, name, namespace, spec, tag_last=False,
                           tag_after_tail=False, is_global=False,
                           k8s_uuid=None):
    ...
    policy_name = cls.get_firewall_policy_name(name, namespace, is_global)
    fw_policy_obj = FirewallPolicy(policy_name, pm_obj)

    custom_ann_kwargs = {}
    custom_ann_kwargs[&apos;k8s_uuid&apos;] = k8s_uuid
    curr_fw_policy = None
    fw_rules_del_candidates = set()

    # If this firewall policy already exists, get its uuid.
    fw_policy_uuid = VncSecurityPolicy.get_firewall_policy_uuid(
        name, namespace, is_global)
    ...

    # Parse input spec and construct the list of rules for this FW policy.
    fw_rules = []
    deny_all_rule_uuid = None
    egress_deny_all_rule_uuid = None

    if spec is not None:
        fw_rules, deny_all_rule_uuid, egress_deny_all_rule_uuid =\
            FWRule.parser(name, namespace, pm_obj, spec)

    for rule in fw_rules:
        try:
            FirewallRuleKM.add_annotations(cls, rule, namespace, rule.name)
            rule_uuid = cls.vnc_lib.firewall_rule_create(rule)
        except RefsExistError:
            cls.vnc_lib.firewall_rule_update(rule)
            rule_uuid = rule.get_uuid()

            # The rule is in use and needs to stay.
            # Remove it from delete candidate collection.
            if fw_rules_del_candidates and\
               rule_uuid in fw_rules_del_candidates:
                fw_rules_del_candidates.remove(rule_uuid)

        rule_obj = cls.vnc_lib.firewall_rule_read(id=rule_uuid)
        FirewallRuleKM.locate(rule_uuid)

        fw_policy_obj.add_firewall_rule(
            rule_obj,
            cls.construct_sequence_number(fw_rules.index(rule)))

    if deny_all_rule_uuid:
        VncSecurityPolicy.add_firewall_rule(
            VncSecurityPolicy.deny_all_fw_policy_uuid, deny_all_rule_uuid)
        custom_ann_kwargs[&apos;deny_all_rule_uuid&apos;] = deny_all_rule_uuid

    if egress_deny_all_rule_uuid:
        VncSecurityPolicy.add_firewall_rule(
            VncSecurityPolicy.deny_all_fw_policy_uuid,
            egress_deny_all_rule_uuid)
        custom_ann_kwargs[&apos;egress_deny_all_rule_uuid&apos;] =\
            egress_deny_all_rule_uuid

    FirewallPolicyKM.add_annotations(
        VncSecurityPolicy.vnc_security_policy_instance,
        fw_policy_obj, namespace, name, None, **custom_ann_kwargs)

    try:
        fw_policy_uuid = cls.vnc_lib.firewall_policy_create(fw_policy_obj)
    except RefsExistError:
    ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里是创建aps policy，并提取spec中的数据生成policy rule并创建，然后将rule绑定到policy中，这里需要重点看下FWRule.parser，看看如何转化policy rule的：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;@classmethod
def parser(cls, name, namespace, pobj, spec):

    fw_rules = []

    # Get pod selectors.
    podSelector_dict = cls._get_np_pod_selector(spec, namespace)
    tags = VncSecurityPolicy.get_tags_fn(podSelector_dict, True)

    deny_all_rule_uuid = None
    egress_deny_all_rule_uuid = None
    policy_types = spec.get(&apos;policyTypes&apos;, [&apos;Ingress&apos;])
    for policy_type in policy_types:
        if policy_type == &apos;Ingress&apos;:
            # Get ingress spec.
            ingress_spec_list = spec.get(&quot;ingress&quot;, [])
            for ingress_spec in ingress_spec_list:
                fw_rules +=\
                    cls.ingress_parser(
                        name, namespace, pobj, tags,
                        ingress_spec, ingress_spec_list.index(ingress_spec))

            # Add ingress deny-all for all other non-explicit traffic.
            deny_all_rule_name = namespace + &quot;-ingress-&quot; + name + &quot;-denyall&quot;
            deny_all_rule_uuid =\
                VncSecurityPolicy.create_firewall_rule_deny_all(
                    deny_all_rule_name, tags, namespace)

        if policy_type == &apos;Egress&apos;:
            # Get egress spec.
            egress_spec_list = spec.get(&quot;egress&quot;, [])
            for egress_spec in egress_spec_list:
                fw_rules +=\
                    cls.egress_parser(name, namespace, pobj, tags,
                                      egress_spec)
            # Add egress deny-all for all other non-explicit traffic.
            egress_deny_all_rule_uuid =\
                VncSecurityPolicy.create_firewall_rule_egress_deny_all(
                    name, namespace, tags)

    return fw_rules, deny_all_rule_uuid, egress_deny_all_rule_uuid
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;_get_np_pod_selector会获取spec中podSelector和namespace两个label的数据，然后通过get_tags_fn查询sdn中已经创建的tag数据，这里的tag数据有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;podselector: matchLabels: xxx:xxx&lt;/li&gt;
  &lt;li&gt;namespace:xxx&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;然后会获取spec中ingress和egress对应的规则，通过ingress_parser和egress_parser做转换，转换成具体的sdn policy rule格式，这里需要注意：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;会优先根据spec中ingress和egress添加的规则创建policy rule&lt;/li&gt;
  &lt;li&gt;ingress末尾会添加一条默认规则，一条ingress deny规则到此集群对应的deny-all的policy中&lt;/li&gt;
  &lt;li&gt;如果指定了egress规则，会在末尾添加一条deny规则到此集群的deny-all的policy中，即绑定此tag的资源无法访问任意其他资源&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;至此，我们基本分析完了networkpolicy的工作流程，但是我们似乎漏了点什么，policy和rule都创建了，但是如何生效的？ 资源和tag的绑定关系发生在什么时候？这里我们通过pod的创建流程来分析下&lt;/p&gt;

&lt;p&gt;在pod创建过程中，我们看到有涉及labels的处理流程(vnc_pod.py process):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;def process(self, event):
    ...
    # Add implicit namespace labels on this pod.
    labels.update(self._get_namespace_labels(pod_namespace))
    self._labels.process(pod_id, labels) 和之前的流程类似，这里会获取pod中metadata的label，并创建出对应的tag资源

def vnc_pod_add(self, pod_id, pod_name, pod_namespace, pod_node, node_ip,
                labels, vm_vmi, fixed_ip=None, annotations_bandwidth_str=None):
    vm = VirtualMachineKM.get(pod_id)
    if vm:
        vm.pod_namespace = pod_namespace
        if not vm.virtual_router:
            self._link_vm_to_node(vm, pod_node, node_ip)
        self._set_label_to_pod_cache(labels, vm)

        # Update tags.
        self._set_tags_on_pod_vmi(pod_id)

        return vm 我们在创建pod的流程中发现，_set_tags_on_pod_vmi会将tag绑定到具体的资源中

def _set_tags_on_pod_vmi(self, pod_id, old_lables=None):
    vmi_obj_list = []
    vm = VirtualMachineKM.get(pod_id)
    if vm:
        for vmi_id in list(vm.virtual_machine_interfaces):
            vmi_obj_list.append(
                self._vnc_lib.virtual_machine_interface_read(id=vmi_id))

    for vmi_obj in vmi_obj_list:
        labels = self._labels.get_labels_dict(pod_id)
        self._vnc_lib.set_tags(vmi_obj, labels)
        if old_lables:
            diff_labels = {k:old_lables[k] for k in old_lables if k not in labels.keys()}
            for k, v in diff_labels.items():
                self._vnc_lib.unset_tag(vmi_obj, k)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;代码中先从VirtualMachineKM中查询出vm对象，此时vm对象已经在上面的_set_label_to_pod_cache方法中将laables设置进去了；
先从数据库中查询出对应的vmi列表，然后依次调用vnc的set_tags方法，将tag和vmi进行绑定&lt;/p&gt;

&lt;p&gt;这样整个流程就完成了。创建sdn资源的时候，创建tag并绑定到资源中；创建networkpolicy时，管理绑定不同tag的资源的行为&lt;/p&gt;
</description>
        <pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate>
        <link>http://0.0.0.0:4000/blog/2021/09/28/tf-cni-networkpolicy/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/2021/09/28/tf-cni-networkpolicy/</guid>
        
        <category>k8s</category>
        
        <category>tungstenfabric</category>
        
        <category>cni</category>
        
        <category>networkpolicy</category>
        
        
      </item>
    
  </channel>
</rss>
